2025-10-04 00:36:34,469 - api_server - INFO - Initializing MedTech Pipeline...
2025-10-04 00:36:34,475 - main - INFO - Loaded config: segmentation_config.yaml
2025-10-04 00:36:34,494 - main - INFO - Loaded config: vector_store_config.yaml
2025-10-04 00:36:34,518 - main - INFO - Loaded config: llm_config.yaml
2025-10-04 00:36:34,548 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-10-04 00:36:34,566 - main - INFO - Loaded config: deployment_config.yaml
2025-10-04 00:36:34,566 - main - INFO - MedTech Pipeline initialized
2025-10-04 00:36:34,566 - main - INFO - Initializing pipeline components...
2025-10-04 00:36:34,573 - api_server - ERROR - Failed to initialize pipeline: SwinUNETR.__init__() got an unexpected keyword argument 'img_size'
2025-10-04 00:39:12,073 - api_server - INFO - Shutting down API server...
2025-10-04 00:40:46,332 - api_server - INFO - Initializing MedTech Pipeline...
2025-10-04 00:40:46,354 - main - INFO - Loaded config: segmentation_config.yaml
2025-10-04 00:40:46,379 - main - INFO - Loaded config: vector_store_config.yaml
2025-10-04 00:40:46,408 - main - INFO - Loaded config: llm_config.yaml
2025-10-04 00:40:46,445 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-10-04 00:40:46,467 - main - INFO - Loaded config: deployment_config.yaml
2025-10-04 00:40:46,467 - main - INFO - MedTech Pipeline initialized
2025-10-04 00:40:46,468 - main - INFO - Initializing pipeline components...
2025-10-04 00:40:46,480 - api_server - ERROR - Failed to initialize pipeline: SwinUNETR.__init__() got an unexpected keyword argument 'image_size'
2025-10-04 00:46:24,111 - api_server - INFO - Initializing MedTech Pipeline...
2025-10-04 00:46:24,117 - main - INFO - Loaded config: segmentation_config.yaml
2025-10-04 00:46:24,136 - main - INFO - Loaded config: vector_store_config.yaml
2025-10-04 00:46:24,157 - main - INFO - Loaded config: llm_config.yaml
2025-10-04 00:46:24,187 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-10-04 00:46:24,216 - main - INFO - Loaded config: deployment_config.yaml
2025-10-04 00:46:24,216 - main - INFO - MedTech Pipeline initialized
2025-10-04 00:46:24,216 - main - INFO - Initializing pipeline components...
2025-10-04 00:46:24,476 - segmentation.swin_unetr_model - WARNING - Failed to load pretrained weights: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
2025-10-04 00:46:24,483 - api_server - ERROR - Failed to initialize pipeline: Torch not compiled with CUDA enabled
2025-10-04 00:47:51,105 - api_server - INFO - Shutting down API server...
2025-10-04 00:48:53,386 - api_server - INFO - Initializing MedTech Pipeline...
2025-10-04 00:48:53,398 - main - INFO - Loaded config: segmentation_config.yaml
2025-10-04 00:48:53,406 - main - INFO - Loaded config: vector_store_config.yaml
2025-10-04 00:48:53,416 - main - INFO - Loaded config: llm_config.yaml
2025-10-04 00:48:53,427 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-10-04 00:48:53,443 - main - INFO - Loaded config: deployment_config.yaml
2025-10-04 00:48:53,443 - main - INFO - MedTech Pipeline initialized
2025-10-04 00:48:53,444 - main - INFO - Initializing pipeline components...
2025-10-04 00:48:53,671 - segmentation.swin_unetr_model - WARNING - Failed to load pretrained weights: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
2025-10-04 00:48:53,679 - api_server - ERROR - Failed to initialize pipeline: Torch not compiled with CUDA enabled
2025-10-04 00:50:07,299 - api_server - INFO - Shutting down API server...
2025-10-04 00:53:01,405 - api_server - INFO - Initializing MedTech Pipeline...
2025-10-04 00:53:01,412 - main - INFO - Loaded config: segmentation_config.yaml
2025-10-04 00:53:01,419 - main - INFO - Loaded config: vector_store_config.yaml
2025-10-04 00:53:01,427 - main - INFO - Loaded config: llm_config.yaml
2025-10-04 00:53:01,437 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-10-04 00:53:01,451 - main - INFO - Loaded config: deployment_config.yaml
2025-10-04 00:53:01,452 - main - INFO - MedTech Pipeline initialized
2025-10-04 00:53:01,452 - main - INFO - Initializing pipeline components...
2025-10-04 00:53:01,826 - segmentation.swin_unetr_model - WARNING - Failed to load pretrained weights: Error(s) in loading state_dict for SwinUNETR:
	Missing key(s) in state_dict: "swinViT.patch_embed.proj.weight", "swinViT.patch_embed.proj.bias", "swinViT.layers1.0.blocks.0.norm1.weight", "swinViT.layers1.0.blocks.0.norm1.bias", "swinViT.layers1.0.blocks.0.attn.relative_position_bias_table", "swinViT.layers1.0.blocks.0.attn.relative_position_index", "swinViT.layers1.0.blocks.0.attn.qkv.weight", "swinViT.layers1.0.blocks.0.attn.qkv.bias", "swinViT.layers1.0.blocks.0.attn.proj.weight", "swinViT.layers1.0.blocks.0.attn.proj.bias", "swinViT.layers1.0.blocks.0.norm2.weight", "swinViT.layers1.0.blocks.0.norm2.bias", "swinViT.layers1.0.blocks.0.mlp.linear1.weight", "swinViT.layers1.0.blocks.0.mlp.linear1.bias", "swinViT.layers1.0.blocks.0.mlp.linear2.weight", "swinViT.layers1.0.blocks.0.mlp.linear2.bias", "swinViT.layers1.0.blocks.1.norm1.weight", "swinViT.layers1.0.blocks.1.norm1.bias", "swinViT.layers1.0.blocks.1.attn.relative_position_bias_table", "swinViT.layers1.0.blocks.1.attn.relative_position_index", "swinViT.layers1.0.blocks.1.attn.qkv.weight", "swinViT.layers1.0.blocks.1.attn.qkv.bias", "swinViT.layers1.0.blocks.1.attn.proj.weight", "swinViT.layers1.0.blocks.1.attn.proj.bias", "swinViT.layers1.0.blocks.1.norm2.weight", "swinViT.layers1.0.blocks.1.norm2.bias", "swinViT.layers1.0.blocks.1.mlp.linear1.weight", "swinViT.layers1.0.blocks.1.mlp.linear1.bias", "swinViT.layers1.0.blocks.1.mlp.linear2.weight", "swinViT.layers1.0.blocks.1.mlp.linear2.bias", "swinViT.layers1.0.downsample.reduction.weight", "swinViT.layers1.0.downsample.norm.weight", "swinViT.layers1.0.downsample.norm.bias", "swinViT.layers2.0.blocks.0.norm1.weight", "swinViT.layers2.0.blocks.0.norm1.bias", "swinViT.layers2.0.blocks.0.attn.relative_position_bias_table", "swinViT.layers2.0.blocks.0.attn.relative_position_index", "swinViT.layers2.0.blocks.0.attn.qkv.weight", "swinViT.layers2.0.blocks.0.attn.qkv.bias", "swinViT.layers2.0.blocks.0.attn.proj.weight", "swinViT.layers2.0.blocks.0.attn.proj.bias", "swinViT.layers2.0.blocks.0.norm2.weight", "swinViT.layers2.0.blocks.0.norm2.bias", "swinViT.layers2.0.blocks.0.mlp.linear1.weight", "swinViT.layers2.0.blocks.0.mlp.linear1.bias", "swinViT.layers2.0.blocks.0.mlp.linear2.weight", "swinViT.layers2.0.blocks.0.mlp.linear2.bias", "swinViT.layers2.0.blocks.1.norm1.weight", "swinViT.layers2.0.blocks.1.norm1.bias", "swinViT.layers2.0.blocks.1.attn.relative_position_bias_table", "swinViT.layers2.0.blocks.1.attn.relative_position_index", "swinViT.layers2.0.blocks.1.attn.qkv.weight", "swinViT.layers2.0.blocks.1.attn.qkv.bias", "swinViT.layers2.0.blocks.1.attn.proj.weight", "swinViT.layers2.0.blocks.1.attn.proj.bias", "swinViT.layers2.0.blocks.1.norm2.weight", "swinViT.layers2.0.blocks.1.norm2.bias", "swinViT.layers2.0.blocks.1.mlp.linear1.weight", "swinViT.layers2.0.blocks.1.mlp.linear1.bias", "swinViT.layers2.0.blocks.1.mlp.linear2.weight", "swinViT.layers2.0.blocks.1.mlp.linear2.bias", "swinViT.layers2.0.downsample.reduction.weight", "swinViT.layers2.0.downsample.norm.weight", "swinViT.layers2.0.downsample.norm.bias", "swinViT.layers3.0.blocks.0.norm1.weight", "swinViT.layers3.0.blocks.0.norm1.bias", "swinViT.layers3.0.blocks.0.attn.relative_position_bias_table", "swinViT.layers3.0.blocks.0.attn.relative_position_index", "swinViT.layers3.0.blocks.0.attn.qkv.weight", "swinViT.layers3.0.blocks.0.attn.qkv.bias", "swinViT.layers3.0.blocks.0.attn.proj.weight", "swinViT.layers3.0.blocks.0.attn.proj.bias", "swinViT.layers3.0.blocks.0.norm2.weight", "swinViT.layers3.0.blocks.0.norm2.bias", "swinViT.layers3.0.blocks.0.mlp.linear1.weight", "swinViT.layers3.0.blocks.0.mlp.linear1.bias", "swinViT.layers3.0.blocks.0.mlp.linear2.weight", "swinViT.layers3.0.blocks.0.mlp.linear2.bias", "swinViT.layers3.0.blocks.1.norm1.weight", "swinViT.layers3.0.blocks.1.norm1.bias", "swinViT.layers3.0.blocks.1.attn.relative_position_bias_table", "swinViT.layers3.0.blocks.1.attn.relative_position_index", "swinViT.layers3.0.blocks.1.attn.qkv.weight", "swinViT.layers3.0.blocks.1.attn.qkv.bias", "swinViT.layers3.0.blocks.1.attn.proj.weight", "swinViT.layers3.0.blocks.1.attn.proj.bias", "swinViT.layers3.0.blocks.1.norm2.weight", "swinViT.layers3.0.blocks.1.norm2.bias", "swinViT.layers3.0.blocks.1.mlp.linear1.weight", "swinViT.layers3.0.blocks.1.mlp.linear1.bias", "swinViT.layers3.0.blocks.1.mlp.linear2.weight", "swinViT.layers3.0.blocks.1.mlp.linear2.bias", "swinViT.layers3.0.downsample.reduction.weight", "swinViT.layers3.0.downsample.norm.weight", "swinViT.layers3.0.downsample.norm.bias", "swinViT.layers4.0.blocks.0.norm1.weight", "swinViT.layers4.0.blocks.0.norm1.bias", "swinViT.layers4.0.blocks.0.attn.relative_position_bias_table", "swinViT.layers4.0.blocks.0.attn.relative_position_index", "swinViT.layers4.0.blocks.0.attn.qkv.weight", "swinViT.layers4.0.blocks.0.attn.qkv.bias", "swinViT.layers4.0.blocks.0.attn.proj.weight", "swinViT.layers4.0.blocks.0.attn.proj.bias", "swinViT.layers4.0.blocks.0.norm2.weight", "swinViT.layers4.0.blocks.0.norm2.bias", "swinViT.layers4.0.blocks.0.mlp.linear1.weight", "swinViT.layers4.0.blocks.0.mlp.linear1.bias", "swinViT.layers4.0.blocks.0.mlp.linear2.weight", "swinViT.layers4.0.blocks.0.mlp.linear2.bias", "swinViT.layers4.0.blocks.1.norm1.weight", "swinViT.layers4.0.blocks.1.norm1.bias", "swinViT.layers4.0.blocks.1.attn.relative_position_bias_table", "swinViT.layers4.0.blocks.1.attn.relative_position_index", "swinViT.layers4.0.blocks.1.attn.qkv.weight", "swinViT.layers4.0.blocks.1.attn.qkv.bias", "swinViT.layers4.0.blocks.1.attn.proj.weight", "swinViT.layers4.0.blocks.1.attn.proj.bias", "swinViT.layers4.0.blocks.1.norm2.weight", "swinViT.layers4.0.blocks.1.norm2.bias", "swinViT.layers4.0.blocks.1.mlp.linear1.weight", "swinViT.layers4.0.blocks.1.mlp.linear1.bias", "swinViT.layers4.0.blocks.1.mlp.linear2.weight", "swinViT.layers4.0.blocks.1.mlp.linear2.bias", "swinViT.layers4.0.downsample.reduction.weight", "swinViT.layers4.0.downsample.norm.weight", "swinViT.layers4.0.downsample.norm.bias", "encoder1.layer.conv1.conv.weight", "encoder1.layer.conv2.conv.weight", "encoder1.layer.conv3.conv.weight", "encoder2.layer.conv1.conv.weight", "encoder2.layer.conv2.conv.weight", "encoder3.layer.conv1.conv.weight", "encoder3.layer.conv2.conv.weight", "encoder4.layer.conv1.conv.weight", "encoder4.layer.conv2.conv.weight", "encoder10.layer.conv1.conv.weight", "encoder10.layer.conv2.conv.weight", "decoder5.transp_conv.conv.weight", "decoder5.conv_block.conv1.conv.weight", "decoder5.conv_block.conv2.conv.weight", "decoder5.conv_block.conv3.conv.weight", "decoder4.transp_conv.conv.weight", "decoder4.conv_block.conv1.conv.weight", "decoder4.conv_block.conv2.conv.weight", "decoder4.conv_block.conv3.conv.weight", "decoder3.transp_conv.conv.weight", "decoder3.conv_block.conv1.conv.weight", "decoder3.conv_block.conv2.conv.weight", "decoder3.conv_block.conv3.conv.weight", "decoder2.transp_conv.conv.weight", "decoder2.conv_block.conv1.conv.weight", "decoder2.conv_block.conv2.conv.weight", "decoder2.conv_block.conv3.conv.weight", "decoder1.transp_conv.conv.weight", "decoder1.conv_block.conv1.conv.weight", "decoder1.conv_block.conv2.conv.weight", "decoder1.conv_block.conv3.conv.weight", "out.conv.conv.weight", "out.conv.conv.bias". 
	Unexpected key(s) in state_dict: "module.patch_embed.proj.weight", "module.patch_embed.proj.bias", "module.layers1.0.blocks.0.norm1.weight", "module.layers1.0.blocks.0.norm1.bias", "module.layers1.0.blocks.0.attn.relative_position_bias_table", "module.layers1.0.blocks.0.attn.relative_position_index", "module.layers1.0.blocks.0.attn.qkv.weight", "module.layers1.0.blocks.0.attn.qkv.bias", "module.layers1.0.blocks.0.attn.proj.weight", "module.layers1.0.blocks.0.attn.proj.bias", "module.layers1.0.blocks.0.norm2.weight", "module.layers1.0.blocks.0.norm2.bias", "module.layers1.0.blocks.0.mlp.fc1.weight", "module.layers1.0.blocks.0.mlp.fc1.bias", "module.layers1.0.blocks.0.mlp.fc2.weight", "module.layers1.0.blocks.0.mlp.fc2.bias", "module.layers1.0.blocks.1.norm1.weight", "module.layers1.0.blocks.1.norm1.bias", "module.layers1.0.blocks.1.attn.relative_position_bias_table", "module.layers1.0.blocks.1.attn.relative_position_index", "module.layers1.0.blocks.1.attn.qkv.weight", "module.layers1.0.blocks.1.attn.qkv.bias", "module.layers1.0.blocks.1.attn.proj.weight", "module.layers1.0.blocks.1.attn.proj.bias", "module.layers1.0.blocks.1.norm2.weight", "module.layers1.0.blocks.1.norm2.bias", "module.layers1.0.blocks.1.mlp.fc1.weight", "module.layers1.0.blocks.1.mlp.fc1.bias", "module.layers1.0.blocks.1.mlp.fc2.weight", "module.layers1.0.blocks.1.mlp.fc2.bias", "module.layers1.0.downsample.reduction.weight", "module.layers1.0.downsample.norm.weight", "module.layers1.0.downsample.norm.bias", "module.layers2.0.blocks.0.norm1.weight", "module.layers2.0.blocks.0.norm1.bias", "module.layers2.0.blocks.0.attn.relative_position_bias_table", "module.layers2.0.blocks.0.attn.relative_position_index", "module.layers2.0.blocks.0.attn.qkv.weight", "module.layers2.0.blocks.0.attn.qkv.bias", "module.layers2.0.blocks.0.attn.proj.weight", "module.layers2.0.blocks.0.attn.proj.bias", "module.layers2.0.blocks.0.norm2.weight", "module.layers2.0.blocks.0.norm2.bias", "module.layers2.0.blocks.0.mlp.fc1.weight", "module.layers2.0.blocks.0.mlp.fc1.bias", "module.layers2.0.blocks.0.mlp.fc2.weight", "module.layers2.0.blocks.0.mlp.fc2.bias", "module.layers2.0.blocks.1.norm1.weight", "module.layers2.0.blocks.1.norm1.bias", "module.layers2.0.blocks.1.attn.relative_position_bias_table", "module.layers2.0.blocks.1.attn.relative_position_index", "module.layers2.0.blocks.1.attn.qkv.weight", "module.layers2.0.blocks.1.attn.qkv.bias", "module.layers2.0.blocks.1.attn.proj.weight", "module.layers2.0.blocks.1.attn.proj.bias", "module.layers2.0.blocks.1.norm2.weight", "module.layers2.0.blocks.1.norm2.bias", "module.layers2.0.blocks.1.mlp.fc1.weight", "module.layers2.0.blocks.1.mlp.fc1.bias", "module.layers2.0.blocks.1.mlp.fc2.weight", "module.layers2.0.blocks.1.mlp.fc2.bias", "module.layers2.0.downsample.reduction.weight", "module.layers2.0.downsample.norm.weight", "module.layers2.0.downsample.norm.bias", "module.layers3.0.blocks.0.norm1.weight", "module.layers3.0.blocks.0.norm1.bias", "module.layers3.0.blocks.0.attn.relative_position_bias_table", "module.layers3.0.blocks.0.attn.relative_position_index", "module.layers3.0.blocks.0.attn.qkv.weight", "module.layers3.0.blocks.0.attn.qkv.bias", "module.layers3.0.blocks.0.attn.proj.weight", "module.layers3.0.blocks.0.attn.proj.bias", "module.layers3.0.blocks.0.norm2.weight", "module.layers3.0.blocks.0.norm2.bias", "module.layers3.0.blocks.0.mlp.fc1.weight", "module.layers3.0.blocks.0.mlp.fc1.bias", "module.layers3.0.blocks.0.mlp.fc2.weight", "module.layers3.0.blocks.0.mlp.fc2.bias", "module.layers3.0.blocks.1.norm1.weight", "module.layers3.0.blocks.1.norm1.bias", "module.layers3.0.blocks.1.attn.relative_position_bias_table", "module.layers3.0.blocks.1.attn.relative_position_index", "module.layers3.0.blocks.1.attn.qkv.weight", "module.layers3.0.blocks.1.attn.qkv.bias", "module.layers3.0.blocks.1.attn.proj.weight", "module.layers3.0.blocks.1.attn.proj.bias", "module.layers3.0.blocks.1.norm2.weight", "module.layers3.0.blocks.1.norm2.bias", "module.layers3.0.blocks.1.mlp.fc1.weight", "module.layers3.0.blocks.1.mlp.fc1.bias", "module.layers3.0.blocks.1.mlp.fc2.weight", "module.layers3.0.blocks.1.mlp.fc2.bias", "module.layers3.0.downsample.reduction.weight", "module.layers3.0.downsample.norm.weight", "module.layers3.0.downsample.norm.bias", "module.layers4.0.blocks.0.norm1.weight", "module.layers4.0.blocks.0.norm1.bias", "module.layers4.0.blocks.0.attn.relative_position_bias_table", "module.layers4.0.blocks.0.attn.relative_position_index", "module.layers4.0.blocks.0.attn.qkv.weight", "module.layers4.0.blocks.0.attn.qkv.bias", "module.layers4.0.blocks.0.attn.proj.weight", "module.layers4.0.blocks.0.attn.proj.bias", "module.layers4.0.blocks.0.norm2.weight", "module.layers4.0.blocks.0.norm2.bias", "module.layers4.0.blocks.0.mlp.fc1.weight", "module.layers4.0.blocks.0.mlp.fc1.bias", "module.layers4.0.blocks.0.mlp.fc2.weight", "module.layers4.0.blocks.0.mlp.fc2.bias", "module.layers4.0.blocks.1.norm1.weight", "module.layers4.0.blocks.1.norm1.bias", "module.layers4.0.blocks.1.attn.relative_position_bias_table", "module.layers4.0.blocks.1.attn.relative_position_index", "module.layers4.0.blocks.1.attn.qkv.weight", "module.layers4.0.blocks.1.attn.qkv.bias", "module.layers4.0.blocks.1.attn.proj.weight", "module.layers4.0.blocks.1.attn.proj.bias", "module.layers4.0.blocks.1.norm2.weight", "module.layers4.0.blocks.1.norm2.bias", "module.layers4.0.blocks.1.mlp.fc1.weight", "module.layers4.0.blocks.1.mlp.fc1.bias", "module.layers4.0.blocks.1.mlp.fc2.weight", "module.layers4.0.blocks.1.mlp.fc2.bias", "module.layers4.0.downsample.reduction.weight", "module.layers4.0.downsample.norm.weight", "module.layers4.0.downsample.norm.bias", "module.norm.weight", "module.norm.bias", "module.convTrans3d.weight", "module.convTrans3d.bias", "module.rotation_head.weight", "module.rotation_head.bias", "module.contrastive_head.weight", "module.contrastive_head.bias". 
2025-10-04 00:53:01,837 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-10-04 00:53:01,837 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-10-04 00:53:01,837 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-10-04 00:53:01,838 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-10-04 00:53:01,838 - main - INFO - Segmentation pipeline initialized
2025-10-04 00:53:01,839 - api_server - ERROR - Failed to initialize pipeline: 'index'
2025-10-04 00:54:00,094 - api_server - INFO - Shutting down API server...
2025-10-04 00:54:12,676 - main - INFO - Loaded config: segmentation_config.yaml
2025-10-04 00:54:12,683 - main - INFO - Loaded config: vector_store_config.yaml
2025-10-04 00:54:12,689 - main - INFO - Loaded config: llm_config.yaml
2025-10-04 00:54:12,696 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-10-04 00:54:12,707 - main - INFO - Loaded config: deployment_config.yaml
2025-10-04 00:54:12,708 - main - INFO - MedTech Pipeline initialized
2025-10-04 00:54:12,708 - main - INFO - Initializing pipeline components...
2025-10-04 00:54:12,809 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-10-04 00:54:12,809 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-10-04 00:54:12,809 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-10-04 00:54:12,810 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-10-04 00:54:12,810 - main - INFO - Segmentation pipeline initialized
2025-11-08 01:08:30,391 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-08 01:08:30,396 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-08 01:08:30,399 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-08 01:08:30,405 - main - INFO - Loaded config: llm_config.yaml
2025-11-08 01:08:30,412 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-08 01:08:30,422 - main - INFO - Loaded config: deployment_config.yaml
2025-11-08 01:08:30,422 - main - INFO - MedTech Pipeline initialized
2025-11-08 01:08:30,422 - main - INFO - Initializing pipeline components...
2025-11-08 01:08:30,599 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-08 01:08:30,599 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-08 01:08:30,599 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-08 01:08:30,599 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-08 01:08:30,599 - main - INFO - Segmentation pipeline initialized
2025-11-08 01:08:30,599 - api_server - ERROR - Failed to initialize pipeline: 'index'
2025-11-08 08:39:48,594 - api_server - INFO - Shutting down API server...
2025-11-08 09:12:16,690 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-08 09:12:16,694 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-08 09:12:16,698 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-08 09:12:16,703 - main - INFO - Loaded config: llm_config.yaml
2025-11-08 09:12:16,711 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-08 09:12:16,721 - main - INFO - Loaded config: deployment_config.yaml
2025-11-08 09:12:16,721 - main - INFO - MedTech Pipeline initialized
2025-11-08 09:12:16,721 - main - INFO - Initializing pipeline components...
2025-11-08 09:12:16,873 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-08 09:12:16,873 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-08 09:12:16,873 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-08 09:12:16,873 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-08 09:12:16,874 - main - INFO - Segmentation pipeline initialized
2025-11-08 09:12:16,874 - api_server - ERROR - Failed to initialize pipeline: 'index'
2025-11-08 10:58:35,732 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-08 10:58:35,747 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-08 10:58:35,758 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-08 10:58:35,773 - main - INFO - Loaded config: llm_config.yaml
2025-11-08 10:58:35,788 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-08 10:58:35,808 - main - INFO - Loaded config: deployment_config.yaml
2025-11-08 10:58:35,809 - main - INFO - MedTech Pipeline initialized
2025-11-08 10:58:35,809 - main - INFO - Initializing pipeline components...
2025-11-08 10:58:36,026 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-08 10:58:36,026 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-08 10:58:36,026 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-08 10:58:36,027 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-08 10:58:36,027 - main - INFO - Segmentation pipeline initialized
2025-11-08 10:58:36,027 - api_server - ERROR - Failed to initialize pipeline: 'index'
2025-11-08 11:08:46,086 - api_server - INFO - Shutting down API server...
2025-11-08 11:09:21,466 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-08 11:09:21,474 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-08 11:09:21,483 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-08 11:09:21,496 - main - INFO - Loaded config: llm_config.yaml
2025-11-08 11:09:21,514 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-08 11:09:21,537 - main - INFO - Loaded config: deployment_config.yaml
2025-11-08 11:09:21,537 - main - INFO - MedTech Pipeline initialized
2025-11-08 11:09:21,537 - main - INFO - Initializing pipeline components...
2025-11-08 11:09:21,681 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-08 11:09:21,682 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-08 11:09:21,682 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-08 11:09:21,682 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-08 11:09:21,682 - main - INFO - Segmentation pipeline initialized
2025-11-08 11:09:21,682 - vector_store - INFO - Building new FAISS index from config
2025-11-08 11:09:21,695 - vector_store - INFO - Created IndexFlatL2
2025-11-08 11:09:21,697 - vector_store - INFO - Saved new FAISS index to data/faiss_index
2025-11-08 11:09:21,697 - main - INFO - Vector store initialized
2025-11-08 11:09:21,698 - llm.medical_llm - ERROR - Failed to initialize model: 'biomistral'
2025-11-08 11:09:21,698 - llm.medical_llm - WARNING - Using dummy model for testing
2025-11-08 11:09:21,698 - llm.medical_llm - INFO - Medical LLM initialized: biomistral
2025-11-08 11:09:21,698 - main - INFO - Medical LLM initialized
2025-11-08 11:09:21,698 - api_server - ERROR - Failed to initialize pipeline: 'fhir_server'
2025-11-08 11:18:13,961 - api_server - INFO - Shutting down API server...
2025-11-08 11:18:40,510 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-08 11:18:40,521 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-08 11:18:40,531 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-08 11:18:40,548 - main - INFO - Loaded config: llm_config.yaml
2025-11-08 11:18:40,564 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-08 11:18:40,587 - main - INFO - Loaded config: deployment_config.yaml
2025-11-08 11:18:40,587 - main - INFO - MedTech Pipeline initialized
2025-11-08 11:18:40,587 - main - INFO - Initializing pipeline components...
2025-11-08 11:18:40,723 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-08 11:18:40,723 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-08 11:18:40,723 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-08 11:18:40,723 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-08 11:18:40,724 - main - INFO - Segmentation pipeline initialized
2025-11-08 11:18:40,724 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-11-08 11:18:40,726 - vector_store - INFO - FAISS index loaded from disk
2025-11-08 11:18:40,728 - vector_store - INFO - Moving FAISS index to GPU 0
2025-11-08 11:38:20,421 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-08 11:38:20,429 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-08 11:38:20,436 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-08 11:38:20,446 - main - INFO - Loaded config: llm_config.yaml
2025-11-08 11:38:20,461 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-08 11:38:20,482 - main - INFO - Loaded config: deployment_config.yaml
2025-11-08 11:38:20,482 - main - INFO - MedTech Pipeline initialized
2025-11-08 11:38:20,483 - main - INFO - Initializing pipeline components...
2025-11-08 11:38:20,602 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-08 11:38:20,603 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-08 11:38:20,603 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-08 11:38:20,603 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-08 11:38:20,603 - main - INFO - Segmentation pipeline initialized
2025-11-08 11:38:20,604 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-11-08 11:38:20,604 - vector_store - INFO - FAISS index loaded from disk
2025-11-08 11:38:20,604 - vector_store - INFO - Moving FAISS index to GPU 0
2025-11-08 11:38:21,544 - vector_store - INFO - Index moved to GPU
2025-11-08 11:38:21,544 - main - INFO - Vector store initialized
2025-11-08 11:38:21,544 - llm.medical_llm - ERROR - Failed to initialize model: 'biomistral'
2025-11-08 11:38:21,545 - llm.medical_llm - WARNING - Using dummy model for testing
2025-11-08 11:38:21,545 - llm.medical_llm - INFO - Medical LLM initialized: biomistral
2025-11-08 11:38:21,545 - main - INFO - Medical LLM initialized
2025-11-08 11:38:21,545 - api_server - ERROR - Failed to initialize pipeline: 'fhir_server'
2025-11-08 11:51:06,855 - api_server - INFO - Shutting down API server...
2025-11-08 11:55:55,025 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-08 11:55:55,034 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-08 11:55:55,041 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-08 11:55:55,054 - main - INFO - Loaded config: llm_config.yaml
2025-11-08 11:55:55,070 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-08 11:55:55,091 - main - INFO - Loaded config: deployment_config.yaml
2025-11-08 11:55:55,092 - main - INFO - MedTech Pipeline initialized
2025-11-08 11:55:55,092 - main - INFO - Initializing pipeline components...
2025-11-08 11:55:55,222 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-08 11:55:55,223 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-08 11:55:55,223 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-08 11:55:55,224 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-08 11:55:55,224 - main - INFO - Segmentation pipeline initialized
2025-11-08 11:55:55,225 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-11-08 11:55:55,226 - vector_store - INFO - FAISS index loaded from disk
2025-11-08 11:55:55,226 - vector_store - INFO - Moving FAISS index to GPU 0
2025-11-08 11:55:55,868 - vector_store - INFO - Index moved to GPU
2025-11-08 11:55:55,869 - main - INFO - Vector store initialized
2025-11-08 11:55:55,869 - llm.medical_llm - ERROR - Failed to initialize model: 'biomistral'
2025-11-08 11:55:55,869 - llm.medical_llm - WARNING - Using dummy model for testing
2025-11-08 11:55:55,869 - llm.medical_llm - INFO - Medical LLM initialized: biomistral
2025-11-08 11:55:55,869 - main - INFO - Medical LLM initialized
2025-11-08 11:55:55,869 - api_server - ERROR - Failed to initialize pipeline: 'fhir_server'
2025-11-08 11:59:25,851 - api_server - INFO - Shutting down API server...
2025-11-08 12:03:34,747 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-08 12:03:34,757 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-08 12:03:34,765 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-08 12:03:34,781 - main - INFO - Loaded config: llm_config.yaml
2025-11-08 12:03:34,796 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-08 12:03:34,816 - main - INFO - Loaded config: deployment_config.yaml
2025-11-08 12:03:34,816 - main - INFO - MedTech Pipeline initialized
2025-11-08 12:03:34,816 - main - INFO - Initializing pipeline components...
2025-11-08 12:03:34,943 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-08 12:03:34,943 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-08 12:03:34,944 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-08 12:03:34,944 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-08 12:03:34,944 - main - INFO - Segmentation pipeline initialized
2025-11-08 12:03:34,945 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-11-08 12:03:34,945 - vector_store - INFO - FAISS index loaded from disk
2025-11-08 12:03:34,945 - vector_store - INFO - Moving FAISS index to GPU 0
2025-11-08 12:03:35,767 - vector_store - INFO - Index moved to GPU
2025-11-08 12:03:35,767 - main - INFO - Vector store initialized
2025-11-08 12:03:35,767 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: None
2025-11-08 12:03:36,076 - llm.medical_llm - ERROR - Failed to initialize model: None is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`
2025-11-08 12:03:36,077 - llm.medical_llm - WARNING - Using dummy model for testing
2025-11-08 12:03:36,077 - llm.medical_llm - INFO - Medical LLM initialized: biomistral
2025-11-08 12:03:36,077 - main - INFO - Medical LLM initialized
2025-11-08 12:03:36,077 - api_server - ERROR - Failed to initialize pipeline: 'fhir_server'
2025-11-08 12:08:12,931 - api_server - INFO - Shutting down API server...
2025-11-08 12:08:32,423 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-08 12:08:32,431 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-08 12:08:32,440 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-08 12:08:32,452 - main - INFO - Loaded config: llm_config.yaml
2025-11-08 12:08:32,474 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-08 12:08:32,499 - main - INFO - Loaded config: deployment_config.yaml
2025-11-08 12:08:32,500 - main - INFO - MedTech Pipeline initialized
2025-11-08 12:08:32,500 - main - INFO - Initializing pipeline components...
2025-11-08 12:08:32,616 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-08 12:08:32,616 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-08 12:08:32,616 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-08 12:08:32,616 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-08 12:08:32,616 - main - INFO - Segmentation pipeline initialized
2025-11-08 12:08:32,618 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-11-08 12:08:32,618 - vector_store - INFO - FAISS index loaded from disk
2025-11-08 12:08:32,618 - vector_store - INFO - Moving FAISS index to GPU 0
2025-11-08 12:08:33,368 - vector_store - INFO - Index moved to GPU
2025-11-08 12:08:33,368 - main - INFO - Vector store initialized
2025-11-08 12:08:33,369 - llm.medical_llm - INFO - Loading local model from /home/samba/projects/MedTech-Diagnostic-LLM-Pipeline/models/biomistral
2025-11-08 12:08:36,385 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-11-08 12:08:36,416 - llm.medical_llm - ERROR - Failed to initialize model: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. 
2025-11-08 12:08:36,416 - llm.medical_llm - WARNING - Using dummy model for testing
2025-11-08 12:08:36,428 - llm.medical_llm - INFO - Medical LLM initialized: biomistral
2025-11-08 12:08:36,428 - main - INFO - Medical LLM initialized
2025-11-08 12:08:36,429 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-08 12:08:36,429 - main - INFO - MCP-FHIR client initialized
2025-11-08 12:08:36,430 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-08 12:08:36,430 - main - INFO - Feedback collector initialized
2025-11-08 12:08:36,430 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-08 12:08:36,430 - main - INFO - Pipeline deployer initialized
2025-11-08 12:08:36,430 - api_server - INFO - Pipeline initialized successfully
2025-11-08 12:09:49,619 - api_server - INFO - Shutting down API server...
2025-11-08 12:12:04,327 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-08 12:12:04,338 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-08 12:12:04,346 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-08 12:12:04,361 - main - INFO - Loaded config: llm_config.yaml
2025-11-08 12:12:04,376 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-08 12:12:04,399 - main - INFO - Loaded config: deployment_config.yaml
2025-11-08 12:12:04,400 - main - INFO - MedTech Pipeline initialized
2025-11-08 12:12:04,400 - main - INFO - Initializing pipeline components...
2025-11-08 12:12:04,518 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-08 12:12:04,518 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-08 12:12:04,518 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-08 12:12:04,519 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-08 12:12:04,519 - main - INFO - Segmentation pipeline initialized
2025-11-08 12:12:04,520 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-11-08 12:12:04,520 - vector_store - INFO - FAISS index loaded from disk
2025-11-08 12:12:04,520 - vector_store - INFO - Moving FAISS index to GPU 0
2025-11-08 12:12:05,558 - vector_store - INFO - Index moved to GPU
2025-11-08 12:12:05,558 - main - INFO - Vector store initialized
2025-11-08 12:12:05,559 - llm.medical_llm - INFO - Loading local model from /home/samba/projects/MedTech-Diagnostic-LLM-Pipeline/models/biomistral
2025-11-08 12:12:05,708 - llm.medical_llm - INFO - Using BitsAndBytesConfig for 8-bit quantization with CPU offloading enabled
2025-11-08 12:12:05,902 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-11-08 12:12:05,936 - llm.medical_llm - ERROR - Failed to initialize model: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.
See the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434
2025-11-08 12:12:05,936 - llm.medical_llm - WARNING - Using dummy model for testing
2025-11-08 12:12:05,946 - llm.medical_llm - INFO - Medical LLM initialized: biomistral
2025-11-08 12:12:05,946 - main - INFO - Medical LLM initialized
2025-11-08 12:12:05,946 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-08 12:12:05,947 - main - INFO - MCP-FHIR client initialized
2025-11-08 12:12:05,947 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-08 12:12:05,947 - main - INFO - Feedback collector initialized
2025-11-08 12:12:05,947 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-08 12:12:05,947 - main - INFO - Pipeline deployer initialized
2025-11-08 12:12:05,947 - api_server - INFO - Pipeline initialized successfully
2025-11-08 12:12:11,270 - api_server - INFO - Shutting down API server...
2025-11-08 13:29:23,210 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-08 13:29:23,215 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-08 13:29:23,219 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-08 13:29:23,224 - main - INFO - Loaded config: llm_config.yaml
2025-11-08 13:29:23,235 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-08 13:29:23,247 - main - INFO - Loaded config: deployment_config.yaml
2025-11-08 13:29:23,247 - main - INFO - MedTech Pipeline initialized
2025-11-08 13:29:23,247 - main - INFO - Initializing pipeline components...
2025-11-08 13:29:23,396 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-08 13:29:23,396 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-08 13:29:23,396 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-08 13:29:23,396 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-08 13:29:23,396 - main - INFO - Segmentation pipeline initialized
2025-11-08 13:29:23,396 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-11-08 13:29:23,399 - vector_store - INFO - FAISS index loaded from disk
2025-11-08 13:29:23,400 - vector_store - INFO - Moving FAISS index to GPU 0
2025-11-08 13:29:23,728 - vector_store - INFO - Index moved to GPU
2025-11-08 13:29:23,729 - main - INFO - Vector store initialized
2025-11-08 13:29:23,729 - llm.medical_llm - INFO - Loading local model from /home/samba/projects/MedTech-Diagnostic-LLM-Pipeline/models/biomistral
2025-11-08 13:29:23,808 - llm.medical_llm - INFO - Using BitsAndBytesConfig for 8-bit quantization with CPU offloading enabled
2025-11-08 13:29:23,818 - llm.medical_llm - ERROR - Failed to initialize model: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory /home/samba/projects/MedTech-Diagnostic-LLM-Pipeline/models/biomistral.
2025-11-08 13:29:23,818 - llm.medical_llm - WARNING - Using dummy model for testing
2025-11-08 13:29:23,822 - llm.medical_llm - INFO - Medical LLM initialized: biomistral
2025-11-08 13:29:23,822 - main - INFO - Medical LLM initialized
2025-11-08 13:29:23,822 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-08 13:29:23,822 - main - INFO - MCP-FHIR client initialized
2025-11-08 13:29:23,822 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-08 13:29:23,822 - main - INFO - Feedback collector initialized
2025-11-08 13:29:23,822 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-08 13:29:23,822 - main - INFO - Pipeline deployer initialized
2025-11-08 13:29:23,823 - api_server - INFO - Pipeline initialized successfully
2025-11-08 13:29:37,457 - api_server - INFO - Shutting down API server...
2025-11-14 18:45:41,104 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 18:45:41,116 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 18:45:41,125 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 18:45:41,135 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 18:45:41,147 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 18:45:41,167 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 18:45:41,168 - main - INFO - MedTech Pipeline initialized
2025-11-14 18:45:41,169 - main - INFO - Initializing pipeline components...
2025-11-14 18:45:41,447 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 18:45:41,447 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 18:45:41,448 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 18:45:41,449 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 18:45:41,449 - main - INFO - Segmentation pipeline initialized
2025-11-14 18:45:41,452 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 18:45:41,453 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 18:45:41,453 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 18:45:41,453 - main - INFO - Vector store initialized
2025-11-14 18:45:41,453 - llm.medical_llm - WARNING - No HuggingFace token found. Some models may require authentication. Set HUGGINGFACE_HUB_TOKEN environment variable.
2025-11-14 18:45:41,454 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: BioMistral/BioMistral-7B
2025-11-14 18:45:43,309 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-11-14 18:45:45,602 - llm.medical_llm - INFO - Using BitsAndBytesConfig for 8-bit quantization with CPU offloading enabled
2025-11-14 18:45:46,886 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-11-14 19:09:53,002 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 19:09:53,011 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 19:09:53,016 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 19:09:53,025 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 19:09:53,036 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 19:09:53,056 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 19:09:53,057 - main - INFO - MedTech Pipeline initialized
2025-11-14 19:09:53,058 - main - INFO - Initializing pipeline components...
2025-11-14 19:09:53,257 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 19:09:53,257 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 19:09:53,258 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 19:09:53,259 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 19:09:53,259 - main - INFO - Segmentation pipeline initialized
2025-11-14 19:09:53,262 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 19:09:53,266 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 19:09:53,266 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 19:09:53,266 - main - INFO - Vector store initialized
2025-11-14 19:09:53,266 - llm.medical_llm - WARNING - No HuggingFace token found. Inference API requires authentication.
2025-11-14 19:09:53,268 - llm.medical_llm - WARNING - Falling back to local model loading...
2025-11-14 19:09:53,268 - llm.medical_llm - WARNING - No HuggingFace token found. Some models may require authentication. Set HUGGINGFACE_HUB_TOKEN environment variable.
2025-11-14 19:09:53,268 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: BioMistral/BioMistral-7B
2025-11-14 19:09:55,215 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-11-14 19:09:57,976 - llm.medical_llm - INFO - Using BitsAndBytesConfig for 8-bit quantization with CPU offloading enabled
2025-11-14 19:09:59,171 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-11-14 19:42:21,249 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 19:42:21,261 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 19:42:21,270 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 19:42:21,287 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 19:42:21,312 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 19:42:21,336 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 19:42:21,337 - main - INFO - MedTech Pipeline initialized
2025-11-14 19:42:21,338 - main - INFO - Initializing pipeline components...
2025-11-14 19:42:21,825 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 19:42:21,828 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 19:42:21,843 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 19:42:21,852 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 19:42:21,857 - main - INFO - Segmentation pipeline initialized
2025-11-14 19:42:21,870 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 19:42:21,879 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 19:42:21,881 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 19:42:21,882 - main - INFO - Vector store initialized
2025-11-14 19:42:21,885 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-11-14 19:42:22,734 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-11-14 19:42:22,734 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-11-14 19:42:22,734 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-11-14 19:42:22,736 - main - INFO - Medical LLM initialized
2025-11-14 19:42:22,736 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-14 19:42:22,736 - main - INFO - MCP-FHIR client initialized
2025-11-14 19:42:22,738 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-14 19:42:22,738 - main - INFO - Feedback collector initialized
2025-11-14 19:42:22,738 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-14 19:42:22,738 - main - INFO - Pipeline deployer initialized
2025-11-14 19:42:22,739 - api_server - INFO - Pipeline initialized successfully
2025-11-14 19:45:30,147 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 19:45:30,154 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 19:45:30,159 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 19:45:30,167 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 19:45:30,178 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 19:45:30,194 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 19:45:30,194 - main - INFO - MedTech Pipeline initialized
2025-11-14 19:45:30,194 - main - INFO - Initializing pipeline components...
2025-11-14 19:45:30,347 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 19:45:30,347 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 19:45:30,347 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 19:45:30,348 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 19:45:30,349 - main - INFO - Segmentation pipeline initialized
2025-11-14 19:45:30,350 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 19:45:30,353 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 19:45:30,353 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 19:45:30,354 - main - INFO - Vector store initialized
2025-11-14 19:45:30,354 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-11-14 19:45:30,354 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-11-14 19:45:30,356 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-11-14 19:45:30,357 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-11-14 19:45:30,357 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-11-14 19:45:30,357 - main - INFO - Medical LLM initialized
2025-11-14 19:45:30,358 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-14 19:45:30,361 - main - INFO - MCP-FHIR client initialized
2025-11-14 19:45:30,364 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-14 19:45:30,364 - main - INFO - Feedback collector initialized
2025-11-14 19:45:30,364 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-14 19:45:30,365 - main - INFO - Pipeline deployer initialized
2025-11-14 19:45:30,366 - api_server - INFO - Pipeline initialized successfully
2025-11-14 20:11:15,415 - api_server - INFO - Processing uploaded file: ID_00b115bfe.dcm
2025-11-14 20:11:15,428 - main - INFO - Processing medical image: data\uploads\ID_00b115bfe.dcm
2025-11-14 20:11:15,428 - main - INFO - Step 1: Performing segmentation...
2025-11-14 20:11:15,432 - segmentation.segmentation_pipeline - INFO - Processing image: data\uploads\ID_00b115bfe.dcm
2025-11-14 20:11:15,871 - segmentation.preprocessing - INFO - Loaded DICOM image: (1024, 1024)
2025-11-14 20:11:15,920 - pydicom - WARNING - Error while processing tag 00080018: Invalid value for VR UI: 'ID_00b115bfe'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.
2025-11-14 20:11:15,931 - pydicom - WARNING - Error while processing tag 00280030: Values for elements with a VR of 'DS' must be <= 16 characters long, but the float provided requires > 16 characters to be accurately represented. Use a smaller string, set 'config.settings.reading_validation_mode' to 'WARN' to override the length check, or explicitly construct a DS object with 'auto_format' set to True
2025-11-14 20:11:16,706 - main - ERROR - Pipeline processing failed: applying transform <monai.transforms.croppad.dictionary.SpatialPadd object at 0x000001E92B0C8690>
2025-11-14 20:17:48,324 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 20:17:48,331 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 20:17:48,336 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 20:17:48,345 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 20:17:48,352 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 20:17:48,365 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 20:17:48,366 - main - INFO - MedTech Pipeline initialized
2025-11-14 20:17:48,366 - main - INFO - Initializing pipeline components...
2025-11-14 20:17:48,574 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 20:17:48,574 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 20:17:48,575 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 20:17:48,576 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 20:17:48,576 - main - INFO - Segmentation pipeline initialized
2025-11-14 20:17:48,579 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 20:17:48,581 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 20:17:48,583 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 20:17:48,584 - main - INFO - Vector store initialized
2025-11-14 20:17:48,584 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-11-14 20:17:48,585 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-11-14 20:17:48,586 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-11-14 20:17:48,586 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-11-14 20:17:48,587 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-11-14 20:17:48,587 - main - INFO - Medical LLM initialized
2025-11-14 20:17:48,588 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-14 20:17:48,589 - main - INFO - MCP-FHIR client initialized
2025-11-14 20:17:48,590 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-14 20:17:48,590 - main - INFO - Feedback collector initialized
2025-11-14 20:17:48,591 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-14 20:17:48,591 - main - INFO - Pipeline deployer initialized
2025-11-14 20:17:48,591 - api_server - INFO - Pipeline initialized successfully
2025-11-14 20:19:00,366 - api_server - INFO - Processing uploaded file: ID_00b0e5a9f.dcm
2025-11-14 20:19:00,373 - main - INFO - Processing medical image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 20:19:00,373 - main - INFO - Step 1: Performing segmentation...
2025-11-14 20:19:00,378 - segmentation.segmentation_pipeline - INFO - Processing image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 20:19:00,389 - segmentation.preprocessing - ERROR - Failed to load DICOM file data\uploads\ID_00b0e5a9f.dcm: 'Settings' object has no attribute 'WARN'
2025-11-14 20:19:00,391 - segmentation.preprocessing - ERROR - Failed to load image data\uploads\ID_00b0e5a9f.dcm: 'Settings' object has no attribute 'WARN'
2025-11-14 20:19:00,391 - main - ERROR - Pipeline processing failed: 'Settings' object has no attribute 'WARN'
2025-11-14 20:40:25,806 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 20:40:25,820 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 20:40:25,831 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 20:40:25,846 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 20:40:25,859 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 20:40:25,886 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 20:40:25,887 - main - INFO - MedTech Pipeline initialized
2025-11-14 20:40:25,888 - main - INFO - Initializing pipeline components...
2025-11-14 20:40:26,355 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 20:40:26,356 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 20:40:26,356 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 20:40:26,359 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 20:40:26,360 - main - INFO - Segmentation pipeline initialized
2025-11-14 20:40:26,362 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 20:40:26,367 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 20:40:26,368 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 20:40:26,368 - main - INFO - Vector store initialized
2025-11-14 20:40:26,370 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-11-14 20:40:26,370 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-11-14 20:40:26,370 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-11-14 20:40:26,372 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-11-14 20:40:26,372 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-11-14 20:40:26,373 - main - INFO - Medical LLM initialized
2025-11-14 20:40:26,374 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-14 20:40:26,374 - main - INFO - MCP-FHIR client initialized
2025-11-14 20:40:26,376 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-14 20:40:26,376 - main - INFO - Feedback collector initialized
2025-11-14 20:40:26,378 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-14 20:40:26,378 - main - INFO - Pipeline deployer initialized
2025-11-14 20:40:26,378 - api_server - INFO - Pipeline initialized successfully
2025-11-14 20:41:25,960 - api_server - INFO - Processing uploaded file: ID_00b0e5a9f.dcm
2025-11-14 20:41:25,966 - main - INFO - Processing medical image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 20:41:25,966 - main - INFO - Step 1: Performing segmentation...
2025-11-14 20:41:25,971 - segmentation.segmentation_pipeline - INFO - Processing image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 20:41:25,977 - segmentation.preprocessing - ERROR - Failed to load DICOM file data\uploads\ID_00b0e5a9f.dcm: module 'pydicom.config' has no attribute 'ReadingValidationMode'
2025-11-14 20:41:25,979 - segmentation.preprocessing - ERROR - Failed to load image data\uploads\ID_00b0e5a9f.dcm: module 'pydicom.config' has no attribute 'ReadingValidationMode'
2025-11-14 20:41:25,979 - main - ERROR - Pipeline processing failed: module 'pydicom.config' has no attribute 'ReadingValidationMode'
2025-11-14 20:43:30,496 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 20:43:30,504 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 20:43:30,511 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 20:43:30,521 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 20:43:30,534 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 20:43:30,564 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 20:43:30,565 - main - INFO - MedTech Pipeline initialized
2025-11-14 20:43:30,566 - main - INFO - Initializing pipeline components...
2025-11-14 20:43:30,851 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 20:43:30,852 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 20:43:30,855 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 20:43:30,859 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 20:43:30,860 - main - INFO - Segmentation pipeline initialized
2025-11-14 20:43:30,866 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 20:43:30,870 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 20:43:30,870 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 20:43:30,871 - main - INFO - Vector store initialized
2025-11-14 20:43:30,871 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-11-14 20:43:30,871 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-11-14 20:43:30,874 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-11-14 20:43:30,874 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-11-14 20:43:30,875 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-11-14 20:43:30,875 - main - INFO - Medical LLM initialized
2025-11-14 20:43:30,876 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-14 20:43:30,877 - main - INFO - MCP-FHIR client initialized
2025-11-14 20:43:30,877 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-14 20:43:30,879 - main - INFO - Feedback collector initialized
2025-11-14 20:43:30,879 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-14 20:43:30,879 - main - INFO - Pipeline deployer initialized
2025-11-14 20:43:30,879 - api_server - INFO - Pipeline initialized successfully
2025-11-14 20:43:51,847 - api_server - INFO - Processing uploaded file: ID_00f715288.dcm
2025-11-14 20:43:51,847 - main - INFO - Processing medical image: data\uploads\ID_00f715288.dcm
2025-11-14 20:43:51,849 - main - INFO - Step 1: Performing segmentation...
2025-11-14 20:43:51,852 - segmentation.segmentation_pipeline - INFO - Processing image: data\uploads\ID_00f715288.dcm
2025-11-14 20:43:51,991 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 20:43:51,993 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 20:43:52,011 - pydicom - WARNING - Error while processing tag 00080018: Invalid value for VR UI: 'ID_00f715288'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.
2025-11-14 20:43:52,394 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data\uploads\ID_00f715288.dcm: applying transform <monai.transforms.croppad.dictionary.SpatialPadd object at 0x000001F0E7C37D50>
2025-11-14 20:43:52,398 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 20:43:52,416 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 20:43:52,418 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 20:43:52,902 - main - ERROR - Pipeline processing failed: SwinUNETR.forward() got an unexpected keyword argument 'sw_overlap'
2025-11-14 20:47:40,022 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 20:47:40,031 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 20:47:40,037 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 20:47:40,047 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 20:47:40,058 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 20:47:40,078 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 20:47:40,079 - main - INFO - MedTech Pipeline initialized
2025-11-14 20:47:40,079 - main - INFO - Initializing pipeline components...
2025-11-14 20:47:40,289 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 20:47:40,290 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 20:47:40,290 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 20:47:40,292 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 20:47:40,293 - main - INFO - Segmentation pipeline initialized
2025-11-14 20:47:40,294 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 20:47:40,298 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 20:47:40,299 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 20:47:40,299 - main - INFO - Vector store initialized
2025-11-14 20:47:40,300 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-11-14 20:47:40,300 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-11-14 20:47:40,301 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-11-14 20:47:40,302 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-11-14 20:47:40,302 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-11-14 20:47:40,302 - main - INFO - Medical LLM initialized
2025-11-14 20:47:40,303 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-14 20:47:40,303 - main - INFO - MCP-FHIR client initialized
2025-11-14 20:47:40,304 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-14 20:47:40,306 - main - INFO - Feedback collector initialized
2025-11-14 20:47:40,306 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-14 20:47:40,306 - main - INFO - Pipeline deployer initialized
2025-11-14 20:47:40,307 - api_server - INFO - Pipeline initialized successfully
2025-11-14 20:49:21,100 - api_server - INFO - Processing uploaded file: ID_00b115bfe.dcm
2025-11-14 20:49:21,102 - main - INFO - Processing medical image: data\uploads\ID_00b115bfe.dcm
2025-11-14 20:49:21,102 - main - INFO - Step 1: Performing segmentation...
2025-11-14 20:49:21,104 - segmentation.segmentation_pipeline - INFO - Processing image: data\uploads\ID_00b115bfe.dcm
2025-11-14 20:49:21,197 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 20:49:21,197 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 20:49:21,211 - pydicom - WARNING - Error while processing tag 00080018: Invalid value for VR UI: 'ID_00b115bfe'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.
2025-11-14 20:49:21,217 - pydicom - WARNING - Error while processing tag 00280030: Values for elements with a VR of 'DS' must be <= 16 characters long, but the float provided requires > 16 characters to be accurately represented. Use a smaller string, set 'config.settings.reading_validation_mode' to 'WARN' to override the length check, or explicitly construct a DS object with 'auto_format' set to True
2025-11-14 20:49:21,360 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data\uploads\ID_00b115bfe.dcm: applying transform <monai.transforms.croppad.dictionary.SpatialPadd object at 0x0000028173084210>
2025-11-14 20:49:21,360 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 20:49:21,371 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 20:49:21,371 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 20:49:21,888 - main - ERROR - Pipeline processing failed: from einops import rearrange (No module named 'einops').

For details about installing the optional dependencies, please visit:
    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies
2025-11-14 20:50:39,059 - api_server - INFO - Shutting down API server...
2025-11-14 20:52:35,036 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 20:52:35,046 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 20:52:35,052 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 20:52:35,053 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 20:52:35,070 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 20:52:35,083 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 20:52:35,083 - main - INFO - MedTech Pipeline initialized
2025-11-14 20:52:35,083 - main - INFO - Initializing pipeline components...
2025-11-14 20:52:35,261 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 20:52:35,273 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 20:52:35,279 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 20:52:35,286 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 20:52:35,288 - main - INFO - Segmentation pipeline initialized
2025-11-14 20:52:35,294 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 20:52:35,299 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 20:52:35,303 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 20:52:35,307 - main - INFO - Vector store initialized
2025-11-14 20:52:35,327 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-11-14 20:52:35,342 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-11-14 20:52:35,346 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-11-14 20:52:35,348 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-11-14 20:52:35,352 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-11-14 20:52:35,354 - main - INFO - Medical LLM initialized
2025-11-14 20:52:35,354 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-14 20:52:35,356 - main - INFO - MCP-FHIR client initialized
2025-11-14 20:52:35,358 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-14 20:52:35,358 - main - INFO - Feedback collector initialized
2025-11-14 20:52:35,363 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-14 20:52:35,363 - main - INFO - Pipeline deployer initialized
2025-11-14 20:52:35,365 - api_server - INFO - Pipeline initialized successfully
2025-11-14 20:52:52,730 - api_server - INFO - Processing uploaded file: ID_00b0e5a9f.dcm
2025-11-14 20:52:52,730 - main - INFO - Processing medical image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 20:52:52,731 - main - INFO - Step 1: Performing segmentation...
2025-11-14 20:52:52,731 - segmentation.segmentation_pipeline - INFO - Processing image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 20:52:52,825 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 20:52:52,826 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 20:52:52,845 - pydicom - WARNING - Error while processing tag 00080018: Invalid value for VR UI: 'ID_00b0e5a9f'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.
2025-11-14 20:52:52,847 - pydicom - WARNING - Error while processing tag 00280030: Values for elements with a VR of 'DS' must be <= 16 characters long, but the float provided requires > 16 characters to be accurately represented. Use a smaller string, set 'config.settings.reading_validation_mode' to 'WARN' to override the length check, or explicitly construct a DS object with 'auto_format' set to True
2025-11-14 20:52:52,990 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data\uploads\ID_00b0e5a9f.dcm: applying transform <monai.transforms.croppad.dictionary.SpatialPadd object at 0x00000239F8A7EA10>
2025-11-14 20:52:52,991 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 20:52:53,005 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 20:52:53,006 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 20:52:55,304 - main - ERROR - Pipeline processing failed: [enforce fail at alloc_cpu.cpp:121] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1936973136 bytes.
2025-11-14 20:57:15,812 - api_server - INFO - Shutting down API server...
2025-11-14 20:57:46,200 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 20:57:46,211 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 20:57:46,221 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 20:57:46,234 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 20:57:46,250 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 20:57:46,273 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 20:57:46,274 - main - INFO - MedTech Pipeline initialized
2025-11-14 20:57:46,274 - main - INFO - Initializing pipeline components...
2025-11-14 20:57:46,608 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 20:57:46,608 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 20:57:46,609 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 20:57:46,611 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 20:57:46,611 - main - INFO - Segmentation pipeline initialized
2025-11-14 20:57:46,613 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 20:57:46,616 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 20:57:46,617 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 20:57:46,617 - main - INFO - Vector store initialized
2025-11-14 20:57:46,618 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-11-14 20:57:46,618 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-11-14 20:57:46,619 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-11-14 20:57:46,619 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-11-14 20:57:46,619 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-11-14 20:57:46,620 - main - INFO - Medical LLM initialized
2025-11-14 20:57:46,620 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-14 20:57:46,621 - main - INFO - MCP-FHIR client initialized
2025-11-14 20:57:46,622 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-14 20:57:46,622 - main - INFO - Feedback collector initialized
2025-11-14 20:57:46,623 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-14 20:57:46,623 - main - INFO - Pipeline deployer initialized
2025-11-14 20:57:46,624 - api_server - INFO - Pipeline initialized successfully
2025-11-14 20:58:00,633 - api_server - INFO - Processing uploaded file: ID_00b0e5a9f.dcm
2025-11-14 20:58:00,633 - main - INFO - Processing medical image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 20:58:00,633 - main - INFO - Step 1: Performing segmentation...
2025-11-14 20:58:00,633 - segmentation.segmentation_pipeline - INFO - Processing image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 20:58:00,698 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 20:58:00,700 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 20:58:00,721 - pydicom - WARNING - Error while processing tag 00080018: Invalid value for VR UI: 'ID_00b0e5a9f'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.
2025-11-14 20:58:00,727 - pydicom - WARNING - Error while processing tag 00280030: Values for elements with a VR of 'DS' must be <= 16 characters long, but the float provided requires > 16 characters to be accurately represented. Use a smaller string, set 'config.settings.reading_validation_mode' to 'WARN' to override the length check, or explicitly construct a DS object with 'auto_format' set to True
2025-11-14 20:58:00,843 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data\uploads\ID_00b0e5a9f.dcm: applying transform <monai.transforms.croppad.dictionary.SpatialPadd object at 0x000001F366DAEBD0>
2025-11-14 20:58:00,844 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 20:58:00,855 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 20:58:00,856 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 20:58:00,880 - main - ERROR - Pipeline processing failed: spatial dimensions [4] of input image (spatial shape: torch.Size([96, 96, 1])) must be divisible by 2**5.
2025-11-14 21:01:51,272 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 21:01:51,280 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 21:01:51,286 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 21:01:51,298 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 21:01:51,311 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 21:01:51,327 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 21:01:51,327 - main - INFO - MedTech Pipeline initialized
2025-11-14 21:01:51,327 - main - INFO - Initializing pipeline components...
2025-11-14 21:01:51,531 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 21:01:51,531 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 21:01:51,532 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 21:01:51,534 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 21:01:51,534 - main - INFO - Segmentation pipeline initialized
2025-11-14 21:01:51,536 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 21:01:51,540 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 21:01:51,540 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 21:01:51,541 - main - INFO - Vector store initialized
2025-11-14 21:01:51,541 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-11-14 21:01:51,541 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-11-14 21:01:51,542 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-11-14 21:01:51,543 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-11-14 21:01:51,543 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-11-14 21:01:51,543 - main - INFO - Medical LLM initialized
2025-11-14 21:01:51,544 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-14 21:01:51,545 - main - INFO - MCP-FHIR client initialized
2025-11-14 21:01:51,546 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-14 21:01:51,547 - main - INFO - Feedback collector initialized
2025-11-14 21:01:51,547 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-14 21:01:51,548 - main - INFO - Pipeline deployer initialized
2025-11-14 21:01:51,548 - api_server - INFO - Pipeline initialized successfully
2025-11-14 21:02:05,516 - api_server - INFO - Processing uploaded file: ID_00b0e5a9f.dcm
2025-11-14 21:02:05,516 - main - INFO - Processing medical image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 21:02:05,517 - main - INFO - Step 1: Performing segmentation...
2025-11-14 21:02:05,517 - segmentation.segmentation_pipeline - INFO - Processing image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 21:02:05,562 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 21:02:05,563 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 21:02:05,574 - pydicom - WARNING - Error while processing tag 00080018: Invalid value for VR UI: 'ID_00b0e5a9f'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.
2025-11-14 21:02:05,576 - pydicom - WARNING - Error while processing tag 00280030: Values for elements with a VR of 'DS' must be <= 16 characters long, but the float provided requires > 16 characters to be accurately represented. Use a smaller string, set 'config.settings.reading_validation_mode' to 'WARN' to override the length check, or explicitly construct a DS object with 'auto_format' set to True
2025-11-14 21:02:05,690 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data\uploads\ID_00b0e5a9f.dcm: applying transform <monai.transforms.croppad.dictionary.SpatialPadd object at 0x000001A02902D150>
2025-11-14 21:02:05,691 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 21:02:05,702 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 21:02:05,702 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 21:02:08,828 - main - ERROR - Pipeline processing failed: [enforce fail at alloc_cpu.cpp:121] data. DefaultCPUAllocator: not enough memory: you tried to allocate 830131344 bytes.
2025-11-14 21:02:34,332 - api_server - INFO - Shutting down API server...
2025-11-14 21:05:51,796 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 21:05:51,804 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 21:05:51,809 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 21:05:51,821 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 21:05:51,826 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 21:05:51,853 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 21:05:51,855 - main - INFO - MedTech Pipeline initialized
2025-11-14 21:05:51,857 - main - INFO - Initializing pipeline components...
2025-11-14 21:05:52,070 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 21:05:52,070 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 21:05:52,071 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 21:05:52,072 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 21:05:52,073 - main - INFO - Segmentation pipeline initialized
2025-11-14 21:05:52,075 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 21:05:52,078 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 21:05:52,079 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 21:05:52,079 - main - INFO - Vector store initialized
2025-11-14 21:05:52,080 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-11-14 21:05:52,080 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-11-14 21:05:52,081 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-11-14 21:05:52,081 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-11-14 21:05:52,082 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-11-14 21:05:52,082 - main - INFO - Medical LLM initialized
2025-11-14 21:05:52,083 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-14 21:05:52,084 - main - INFO - MCP-FHIR client initialized
2025-11-14 21:05:52,085 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-14 21:05:52,085 - main - INFO - Feedback collector initialized
2025-11-14 21:05:52,085 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-14 21:05:52,085 - main - INFO - Pipeline deployer initialized
2025-11-14 21:05:52,086 - api_server - INFO - Pipeline initialized successfully
2025-11-14 21:06:05,138 - api_server - INFO - Processing uploaded file: ID_00b0e5a9f.dcm
2025-11-14 21:06:05,138 - main - INFO - Processing medical image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 21:06:05,138 - main - INFO - Step 1: Performing segmentation...
2025-11-14 21:06:05,140 - segmentation.segmentation_pipeline - INFO - Processing image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 21:06:05,179 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 21:06:05,185 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 21:06:05,197 - pydicom - WARNING - Error while processing tag 00080018: Invalid value for VR UI: 'ID_00b0e5a9f'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.
2025-11-14 21:06:05,197 - pydicom - WARNING - Error while processing tag 00280030: Values for elements with a VR of 'DS' must be <= 16 characters long, but the float provided requires > 16 characters to be accurately represented. Use a smaller string, set 'config.settings.reading_validation_mode' to 'WARN' to override the length check, or explicitly construct a DS object with 'auto_format' set to True
2025-11-14 21:06:05,298 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data\uploads\ID_00b0e5a9f.dcm: applying transform <monai.transforms.croppad.dictionary.SpatialPadd object at 0x000001C02EF13A50>
2025-11-14 21:06:05,298 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 21:06:05,309 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 21:06:05,309 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 21:06:05,398 - segmentation.swin_unetr_model - ERROR - Fallback preprocessing also failed: permute(): duplicate dims are not allowed.
2025-11-14 21:06:05,398 - main - ERROR - Pipeline processing failed: applying transform <monai.transforms.croppad.dictionary.SpatialPadd object at 0x000001C02EF13A50>
2025-11-14 21:08:00,011 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 21:08:00,019 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 21:08:00,027 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 21:08:00,040 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 21:08:00,051 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 21:08:00,073 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 21:08:00,074 - main - INFO - MedTech Pipeline initialized
2025-11-14 21:08:00,075 - main - INFO - Initializing pipeline components...
2025-11-14 21:08:00,322 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 21:08:00,322 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 21:08:00,323 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 21:08:00,324 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 21:08:00,324 - main - INFO - Segmentation pipeline initialized
2025-11-14 21:08:00,326 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 21:08:00,329 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 21:08:00,330 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 21:08:00,330 - main - INFO - Vector store initialized
2025-11-14 21:08:00,331 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-11-14 21:08:00,331 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-11-14 21:08:00,332 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-11-14 21:08:00,332 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-11-14 21:08:00,332 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-11-14 21:08:00,333 - main - INFO - Medical LLM initialized
2025-11-14 21:08:00,333 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-14 21:08:00,334 - main - INFO - MCP-FHIR client initialized
2025-11-14 21:08:00,335 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-14 21:08:00,336 - main - INFO - Feedback collector initialized
2025-11-14 21:08:00,336 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-14 21:08:00,337 - main - INFO - Pipeline deployer initialized
2025-11-14 21:08:00,337 - api_server - INFO - Pipeline initialized successfully
2025-11-14 21:08:13,967 - api_server - INFO - Processing uploaded file: ID_00b0e5a9f.dcm
2025-11-14 21:08:13,967 - main - INFO - Processing medical image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 21:08:13,967 - main - INFO - Step 1: Performing segmentation...
2025-11-14 21:08:13,968 - segmentation.segmentation_pipeline - INFO - Processing image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 21:08:14,016 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 21:08:14,016 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 21:08:14,025 - pydicom - WARNING - Error while processing tag 00080018: Invalid value for VR UI: 'ID_00b0e5a9f'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.
2025-11-14 21:08:14,027 - pydicom - WARNING - Error while processing tag 00280030: Values for elements with a VR of 'DS' must be <= 16 characters long, but the float provided requires > 16 characters to be accurately represented. Use a smaller string, set 'config.settings.reading_validation_mode' to 'WARN' to override the length check, or explicitly construct a DS object with 'auto_format' set to True
2025-11-14 21:08:14,117 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data\uploads\ID_00b0e5a9f.dcm: applying transform <monai.transforms.croppad.dictionary.SpatialPadd object at 0x0000028228213210>
2025-11-14 21:08:14,117 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 21:08:14,126 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 21:08:14,127 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 21:08:14,211 - segmentation.swin_unetr_model - ERROR - Fallback preprocessing also failed: permute(): duplicate dims are not allowed.
2025-11-14 21:08:14,211 - main - ERROR - Pipeline processing failed: applying transform <monai.transforms.croppad.dictionary.SpatialPadd object at 0x0000028228213210>
2025-11-14 21:09:51,473 - api_server - INFO - Shutting down API server...
2025-11-14 21:10:21,974 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 21:10:21,984 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 21:10:21,990 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 21:10:21,999 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 21:10:22,009 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 21:10:22,032 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 21:10:22,033 - main - INFO - MedTech Pipeline initialized
2025-11-14 21:10:22,033 - main - INFO - Initializing pipeline components...
2025-11-14 21:10:22,248 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 21:10:22,249 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 21:10:22,249 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 21:10:22,250 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 21:10:22,250 - main - INFO - Segmentation pipeline initialized
2025-11-14 21:10:22,253 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 21:10:22,255 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 21:10:22,256 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 21:10:22,256 - main - INFO - Vector store initialized
2025-11-14 21:10:22,257 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-11-14 21:10:22,257 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-11-14 21:10:22,258 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-11-14 21:10:22,259 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-11-14 21:10:22,259 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-11-14 21:10:22,259 - main - INFO - Medical LLM initialized
2025-11-14 21:10:22,261 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-14 21:10:22,261 - main - INFO - MCP-FHIR client initialized
2025-11-14 21:10:22,262 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-14 21:10:22,263 - main - INFO - Feedback collector initialized
2025-11-14 21:10:22,263 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-14 21:10:22,263 - main - INFO - Pipeline deployer initialized
2025-11-14 21:10:22,264 - api_server - INFO - Pipeline initialized successfully
2025-11-14 21:10:36,155 - api_server - INFO - Processing uploaded file: ID_00b0e5a9f.dcm
2025-11-14 21:10:36,157 - main - INFO - Processing medical image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 21:10:36,158 - main - INFO - Step 1: Performing segmentation...
2025-11-14 21:10:36,160 - segmentation.segmentation_pipeline - INFO - Processing image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 21:10:36,245 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 21:10:36,245 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 21:10:36,262 - pydicom - WARNING - Error while processing tag 00080018: Invalid value for VR UI: 'ID_00b0e5a9f'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.
2025-11-14 21:10:36,268 - pydicom - WARNING - Error while processing tag 00280030: Values for elements with a VR of 'DS' must be <= 16 characters long, but the float provided requires > 16 characters to be accurately represented. Use a smaller string, set 'config.settings.reading_validation_mode' to 'WARN' to override the length check, or explicitly construct a DS object with 'auto_format' set to True
2025-11-14 21:10:36,423 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data\uploads\ID_00b0e5a9f.dcm: applying transform <monai.transforms.croppad.dictionary.SpatialPadd object at 0x000002E2A7B9BE10>
2025-11-14 21:10:36,424 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 21:10:36,440 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 21:10:36,441 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 21:13:10,976 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 21:13:10,984 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 21:13:10,992 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 21:13:11,000 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 21:13:11,011 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 21:13:11,028 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 21:13:11,028 - main - INFO - MedTech Pipeline initialized
2025-11-14 21:13:11,028 - main - INFO - Initializing pipeline components...
2025-11-14 21:13:11,205 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 21:13:11,206 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 21:13:11,206 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 21:13:11,207 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 21:13:11,208 - main - INFO - Segmentation pipeline initialized
2025-11-14 21:13:11,211 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 21:13:11,214 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 21:13:11,214 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 21:13:11,215 - main - INFO - Vector store initialized
2025-11-14 21:13:11,215 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-11-14 21:13:11,215 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-11-14 21:13:11,216 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-11-14 21:13:11,217 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-11-14 21:13:11,217 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-11-14 21:13:11,217 - main - INFO - Medical LLM initialized
2025-11-14 21:13:11,218 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-14 21:13:11,218 - main - INFO - MCP-FHIR client initialized
2025-11-14 21:13:11,220 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-14 21:13:11,220 - main - INFO - Feedback collector initialized
2025-11-14 21:13:11,221 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-14 21:13:11,221 - main - INFO - Pipeline deployer initialized
2025-11-14 21:13:11,222 - api_server - INFO - Pipeline initialized successfully
2025-11-14 21:13:21,832 - api_server - INFO - Processing uploaded file: ID_00b0e5a9f.dcm
2025-11-14 21:13:21,834 - main - INFO - Processing medical image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 21:13:21,835 - main - INFO - Step 1: Performing segmentation...
2025-11-14 21:13:21,835 - segmentation.segmentation_pipeline - INFO - Processing image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 21:13:21,989 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 21:13:21,992 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 21:13:22,035 - pydicom - WARNING - Error while processing tag 00080018: Invalid value for VR UI: 'ID_00b0e5a9f'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.
2025-11-14 21:13:22,046 - pydicom - WARNING - Error while processing tag 00280030: Values for elements with a VR of 'DS' must be <= 16 characters long, but the float provided requires > 16 characters to be accurately represented. Use a smaller string, set 'config.settings.reading_validation_mode' to 'WARN' to override the length check, or explicitly construct a DS object with 'auto_format' set to True
2025-11-14 21:13:22,276 - main - ERROR - Pipeline processing failed: Sequence must have length 2, got 3.
2025-11-14 21:17:01,929 - api_server - INFO - Shutting down API server...
2025-11-14 21:17:34,600 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 21:17:34,611 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 21:17:34,617 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 21:17:34,625 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 21:17:34,637 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 21:17:34,657 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 21:17:34,658 - main - INFO - MedTech Pipeline initialized
2025-11-14 21:17:34,659 - main - INFO - Initializing pipeline components...
2025-11-14 21:17:34,864 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 21:17:34,864 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 21:17:34,865 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 21:17:34,866 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 21:17:34,866 - main - INFO - Segmentation pipeline initialized
2025-11-14 21:17:34,868 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 21:17:34,872 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 21:17:34,872 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 21:17:34,873 - main - INFO - Vector store initialized
2025-11-14 21:17:34,873 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-11-14 21:17:34,874 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-11-14 21:17:34,874 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-11-14 21:17:34,875 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-11-14 21:17:34,875 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-11-14 21:17:34,875 - main - INFO - Medical LLM initialized
2025-11-14 21:17:34,876 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-14 21:17:34,876 - main - INFO - MCP-FHIR client initialized
2025-11-14 21:17:34,878 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-14 21:17:34,878 - main - INFO - Feedback collector initialized
2025-11-14 21:17:34,880 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-14 21:17:34,880 - main - INFO - Pipeline deployer initialized
2025-11-14 21:17:34,880 - api_server - INFO - Pipeline initialized successfully
2025-11-14 21:17:45,081 - api_server - INFO - Processing uploaded file: ID_00b0e5a9f.dcm
2025-11-14 21:17:45,082 - main - INFO - Processing medical image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 21:17:45,082 - main - INFO - Step 1: Performing segmentation...
2025-11-14 21:17:45,083 - segmentation.segmentation_pipeline - INFO - Processing image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 21:17:45,133 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 21:17:45,133 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 21:17:45,146 - pydicom - WARNING - Error while processing tag 00080018: Invalid value for VR UI: 'ID_00b0e5a9f'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.
2025-11-14 21:17:45,149 - pydicom - WARNING - Error while processing tag 00280030: Values for elements with a VR of 'DS' must be <= 16 characters long, but the float provided requires > 16 characters to be accurately represented. Use a smaller string, set 'config.settings.reading_validation_mode' to 'WARN' to override the length check, or explicitly construct a DS object with 'auto_format' set to True
2025-11-14 21:17:45,242 - main - ERROR - Pipeline processing failed: Sequence must have length 2, got 3.
2025-11-14 21:36:45,079 - api_server - INFO - Initializing MedTech Pipeline...
2025-11-14 21:36:45,087 - main - INFO - Loaded config: segmentation_config.yaml
2025-11-14 21:36:45,094 - main - INFO - Loaded config: vector_store_config.yaml
2025-11-14 21:36:45,105 - main - INFO - Loaded config: llm_config.yaml
2025-11-14 21:36:45,115 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-11-14 21:36:45,129 - main - INFO - Loaded config: deployment_config.yaml
2025-11-14 21:36:45,130 - main - INFO - MedTech Pipeline initialized
2025-11-14 21:36:45,130 - main - INFO - Initializing pipeline components...
2025-11-14 21:36:45,334 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-11-14 21:36:45,334 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 21:36:45,334 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-11-14 21:36:45,336 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-11-14 21:36:45,336 - main - INFO - Segmentation pipeline initialized
2025-11-14 21:36:45,338 - vector_store - INFO - Loading FAISS index from data\faiss_index
2025-11-14 21:36:45,340 - vector_store - INFO - FAISS index loaded from disk
2025-11-14 21:36:45,341 - vector_store - WARNING - Failed to move index to GPU: module 'faiss' has no attribute 'StandardGpuResources'
2025-11-14 21:36:45,341 - main - INFO - Vector store initialized
2025-11-14 21:36:45,341 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-11-14 21:36:45,342 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-11-14 21:36:45,342 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-11-14 21:36:45,342 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-11-14 21:36:45,343 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-11-14 21:36:45,343 - main - INFO - Medical LLM initialized
2025-11-14 21:36:45,344 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-11-14 21:36:45,344 - main - INFO - MCP-FHIR client initialized
2025-11-14 21:36:45,346 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-11-14 21:36:45,346 - main - INFO - Feedback collector initialized
2025-11-14 21:36:45,347 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-11-14 21:36:45,347 - main - INFO - Pipeline deployer initialized
2025-11-14 21:36:45,347 - api_server - INFO - Pipeline initialized successfully
2025-11-14 21:37:13,520 - api_server - INFO - Processing uploaded file: ID_00b0e5a9f.dcm
2025-11-14 21:37:13,521 - main - INFO - Processing medical image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 21:37:13,522 - main - INFO - Step 1: Performing segmentation...
2025-11-14 21:37:13,522 - segmentation.segmentation_pipeline - INFO - Processing image: data\uploads\ID_00b0e5a9f.dcm
2025-11-14 21:37:13,607 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 21:37:13,608 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-11-14 21:37:13,608 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data\uploads\ID_00b0e5a9f.dcm: Use fallback preprocessing for DICOM
2025-11-14 21:37:13,609 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-11-14 21:37:13,622 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-11-14 21:37:13,622 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 01:23:56,966 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 01:23:56,970 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 01:23:56,974 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 01:23:56,979 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 01:23:56,986 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 01:23:56,997 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 01:23:56,997 - main - INFO - MedTech Pipeline initialized
2025-12-11 01:23:56,997 - main - INFO - Initializing pipeline components...
2025-12-11 01:23:57,001 - api_server - ERROR - Failed to initialize pipeline: SwinUNETR.__init__() got an unexpected keyword argument 'patch_size'
2025-12-11 01:24:15,324 - api_server - INFO - Shutting down API server...
2025-12-11 01:29:26,561 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 01:29:26,565 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 01:29:26,569 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 01:29:26,574 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 01:29:26,580 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 01:29:26,591 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 01:29:26,591 - main - INFO - MedTech Pipeline initialized
2025-12-11 01:29:26,591 - main - INFO - Initializing pipeline components...
2025-12-11 01:29:26,595 - api_server - ERROR - Failed to initialize pipeline: SwinUNETR.__init__() missing 1 required positional argument: 'img_size'
2025-12-11 01:29:41,363 - api_server - INFO - Shutting down API server...
2025-12-11 01:30:20,287 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 01:30:20,292 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 01:30:20,296 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 01:30:20,302 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 01:30:20,308 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 01:30:20,318 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 01:30:20,318 - main - INFO - MedTech Pipeline initialized
2025-12-11 01:30:20,318 - main - INFO - Initializing pipeline components...
2025-12-11 01:30:20,444 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-12-11 01:30:20,444 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:30:20,444 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 01:30:20,444 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 01:30:20,444 - main - INFO - Segmentation pipeline initialized
2025-12-11 01:30:20,444 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 01:30:20,446 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 01:30:20,447 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 01:32:00,866 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 01:32:00,871 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 01:32:00,875 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 01:32:00,881 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 01:32:00,888 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 01:32:00,898 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 01:32:00,898 - main - INFO - MedTech Pipeline initialized
2025-12-11 01:32:00,898 - main - INFO - Initializing pipeline components...
2025-12-11 01:32:00,962 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-12-11 01:32:00,962 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:32:00,963 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 01:32:00,963 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 01:32:00,963 - main - INFO - Segmentation pipeline initialized
2025-12-11 01:32:00,963 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 01:32:00,963 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 01:32:00,963 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 01:37:26,676 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 01:37:26,684 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 01:37:26,689 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 01:37:26,701 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 01:37:26,712 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 01:37:26,730 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 01:37:26,731 - main - INFO - MedTech Pipeline initialized
2025-12-11 01:37:26,731 - main - INFO - Initializing pipeline components...
2025-12-11 01:37:26,816 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cpu
2025-12-11 01:37:26,817 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:37:26,817 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 01:37:26,817 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 01:37:26,817 - main - INFO - Segmentation pipeline initialized
2025-12-11 01:37:26,817 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 01:37:26,817 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 01:37:26,818 - main - INFO - Vector store initialized
2025-12-11 01:37:26,818 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 01:37:26,818 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 01:37:26,818 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 01:37:26,818 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 01:37:26,818 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 01:37:26,818 - main - INFO - Medical LLM initialized
2025-12-11 01:37:26,818 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 01:37:26,818 - main - INFO - MCP-FHIR client initialized
2025-12-11 01:37:26,819 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 01:37:26,819 - main - INFO - Feedback collector initialized
2025-12-11 01:37:26,819 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 01:37:26,819 - main - INFO - Pipeline deployer initialized
2025-12-11 01:37:26,819 - api_server - INFO - Pipeline initialized successfully
2025-12-11 01:37:37,617 - api_server - INFO - Processing uploaded file: ID_0bbbdda07.dcm
2025-12-11 01:37:37,617 - main - INFO - Processing medical image: data/uploads/ID_0bbbdda07.dcm
2025-12-11 01:37:37,618 - main - INFO - Step 1: Performing segmentation...
2025-12-11 01:37:37,618 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0bbbdda07.dcm
2025-12-11 01:37:37,630 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 01:37:37,630 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 01:37:37,630 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0bbbdda07.dcm: Use fallback preprocessing for DICOM
2025-12-11 01:37:37,630 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:37:37,634 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 01:37:37,634 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 01:37:50,876 - main - ERROR - Pipeline processing failed: 'SwinUNETR' object has no attribute 'encoder'
2025-12-11 01:38:16,740 - api_server - INFO - Shutting down API server...
2025-12-11 01:40:44,221 - vector_store - INFO - Index moved to GPU
2025-12-11 01:40:44,222 - main - INFO - Vector store initialized
2025-12-11 01:40:44,222 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 01:40:44,222 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 01:40:44,222 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 01:40:44,223 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 01:40:44,223 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 01:40:44,223 - main - INFO - Medical LLM initialized
2025-12-11 01:40:44,223 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 01:40:44,223 - main - INFO - MCP-FHIR client initialized
2025-12-11 01:40:44,223 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 01:40:44,223 - main - INFO - Feedback collector initialized
2025-12-11 01:40:44,224 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 01:40:44,224 - main - INFO - Pipeline deployer initialized
2025-12-11 01:40:44,224 - api_server - INFO - Pipeline initialized successfully
2025-12-11 01:41:59,854 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 01:41:59,858 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 01:41:59,862 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 01:41:59,868 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 01:41:59,874 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 01:41:59,884 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 01:41:59,884 - main - INFO - MedTech Pipeline initialized
2025-12-11 01:41:59,884 - main - INFO - Initializing pipeline components...
2025-12-11 01:42:00,246 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 01:42:00,246 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:42:00,246 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 01:42:00,246 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 01:42:00,246 - main - INFO - Segmentation pipeline initialized
2025-12-11 01:42:00,246 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 01:42:00,246 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 01:42:00,246 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 01:42:01,349 - vector_store - INFO - Index moved to GPU
2025-12-11 01:42:01,349 - main - INFO - Vector store initialized
2025-12-11 01:42:01,349 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 01:42:01,349 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 01:42:01,349 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 01:42:01,349 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 01:42:01,349 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 01:42:01,349 - main - INFO - Medical LLM initialized
2025-12-11 01:42:01,349 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 01:42:01,350 - main - INFO - MCP-FHIR client initialized
2025-12-11 01:42:01,350 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 01:42:01,350 - main - INFO - Feedback collector initialized
2025-12-11 01:42:01,350 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 01:42:01,350 - main - INFO - Pipeline deployer initialized
2025-12-11 01:42:01,350 - api_server - INFO - Pipeline initialized successfully
2025-12-11 01:42:20,497 - api_server - INFO - Processing uploaded file: ID_0b7d6530c.dcm
2025-12-11 01:42:20,497 - main - INFO - Processing medical image: data/uploads/ID_0b7d6530c.dcm
2025-12-11 01:42:20,497 - main - INFO - Step 1: Performing segmentation...
2025-12-11 01:42:20,497 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0b7d6530c.dcm
2025-12-11 01:42:20,505 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 01:42:20,505 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 01:42:20,505 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0b7d6530c.dcm: Use fallback preprocessing for DICOM
2025-12-11 01:42:20,505 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:42:20,510 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 01:42:20,510 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 01:42:24,654 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0b7d6530c_mask.nii.gz
2025-12-11 01:42:24,654 - main - ERROR - Pipeline processing failed: 'list' object has no attribute 'detach'
2025-12-11 01:42:51,837 - api_server - INFO - Shutting down API server...
2025-12-11 01:44:06,103 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 01:44:06,107 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 01:44:06,111 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 01:44:06,117 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 01:44:06,124 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 01:44:06,133 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 01:44:06,134 - main - INFO - MedTech Pipeline initialized
2025-12-11 01:44:06,134 - main - INFO - Initializing pipeline components...
2025-12-11 01:44:06,621 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 01:44:06,621 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:44:06,621 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 01:44:06,621 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 01:44:06,621 - main - INFO - Segmentation pipeline initialized
2025-12-11 01:44:06,621 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 01:44:06,621 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 01:44:06,621 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 01:44:07,873 - vector_store - INFO - Index moved to GPU
2025-12-11 01:44:07,873 - main - INFO - Vector store initialized
2025-12-11 01:44:07,873 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 01:44:07,873 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 01:44:07,873 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 01:44:07,873 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 01:44:07,873 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 01:44:07,874 - main - INFO - Medical LLM initialized
2025-12-11 01:44:07,874 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 01:44:07,874 - main - INFO - MCP-FHIR client initialized
2025-12-11 01:44:07,874 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 01:44:07,874 - main - INFO - Feedback collector initialized
2025-12-11 01:44:07,874 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 01:44:07,874 - main - INFO - Pipeline deployer initialized
2025-12-11 01:44:07,874 - api_server - INFO - Pipeline initialized successfully
2025-12-11 01:44:19,343 - api_server - INFO - Processing uploaded file: ID_0ac3e69bc.dcm
2025-12-11 01:44:19,343 - main - INFO - Processing medical image: data/uploads/ID_0ac3e69bc.dcm
2025-12-11 01:44:19,343 - main - INFO - Step 1: Performing segmentation...
2025-12-11 01:44:19,343 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0ac3e69bc.dcm
2025-12-11 01:44:19,350 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 01:44:19,350 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 01:44:19,350 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0ac3e69bc.dcm: Use fallback preprocessing for DICOM
2025-12-11 01:44:19,350 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:44:19,354 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 01:44:19,354 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 01:44:25,373 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0ac3e69bc_mask.nii.gz
2025-12-11 01:44:25,387 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 01:44:25,428 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0ac3e69bc.dcm
2025-12-11 01:44:25,429 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 01:44:25,429 - vector_store - ERROR - Embedding dimension mismatch: expected 768, got 192
2025-12-11 01:44:25,429 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 01:44:25,429 - vector_store - ERROR - Query embedding dimension mismatch: expected 768, got 192
2025-12-11 01:44:25,430 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 01:44:25,430 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 01:44:31,182 - main - INFO - Step 5: Generating medical report...
2025-12-11 01:44:31,182 - main - INFO - Pipeline processing completed successfully
2025-12-11 01:44:31,191 - api_server - ERROR - Chat error: unsupported format string passed to NoneType.__format__
Traceback (most recent call last):
  File "/home/samba/projects/MedTech-Diagnostic-LLM-Pipeline/api_server.py", line 548, in chat
    context = context_builder.build_context(
  File "/home/samba/projects/MedTech-Diagnostic-LLM-Pipeline/src/utils/context_builder.py", line 42, in build_context
    "segmentation_findings": self._format_segmentation_findings(
  File "/home/samba/projects/MedTech-Diagnostic-LLM-Pipeline/src/utils/context_builder.py", line 85, in _format_segmentation_findings
    findings.append(f"\nMean Dice Score: {metrics['mean_dice']:.3f}")
TypeError: unsupported format string passed to NoneType.__format__
2025-12-11 01:45:27,751 - api_server - INFO - Shutting down API server...
2025-12-11 01:46:20,436 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 01:46:20,440 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 01:46:20,444 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 01:46:20,449 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 01:46:20,455 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 01:46:20,465 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 01:46:20,465 - main - INFO - MedTech Pipeline initialized
2025-12-11 01:46:20,465 - main - INFO - Initializing pipeline components...
2025-12-11 01:46:20,856 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 01:46:20,856 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:46:20,856 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 01:46:20,856 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 01:46:20,856 - main - INFO - Segmentation pipeline initialized
2025-12-11 01:46:20,857 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 01:46:20,857 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 01:46:20,857 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 01:46:22,459 - vector_store - INFO - Index moved to GPU
2025-12-11 01:46:22,460 - main - INFO - Vector store initialized
2025-12-11 01:46:22,460 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 01:46:22,460 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 01:46:22,460 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 01:46:22,460 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 01:46:22,460 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 01:46:22,460 - main - INFO - Medical LLM initialized
2025-12-11 01:46:22,460 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 01:46:22,460 - main - INFO - MCP-FHIR client initialized
2025-12-11 01:46:22,460 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 01:46:22,460 - main - INFO - Feedback collector initialized
2025-12-11 01:46:22,460 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 01:46:22,460 - main - INFO - Pipeline deployer initialized
2025-12-11 01:46:22,461 - api_server - INFO - Pipeline initialized successfully
2025-12-11 01:46:51,557 - api_server - INFO - Processing uploaded file: ID_2aa1cd67b.dcm
2025-12-11 01:46:51,557 - main - INFO - Processing medical image: data/uploads/ID_2aa1cd67b.dcm
2025-12-11 01:46:51,557 - main - INFO - Step 1: Performing segmentation...
2025-12-11 01:46:51,557 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_2aa1cd67b.dcm
2025-12-11 01:46:51,563 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 01:46:51,563 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 01:46:51,563 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_2aa1cd67b.dcm: Use fallback preprocessing for DICOM
2025-12-11 01:46:51,563 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:46:51,567 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 01:46:51,568 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 01:46:57,427 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_2aa1cd67b_mask.nii.gz
2025-12-11 01:46:57,444 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 01:46:57,483 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_2aa1cd67b.dcm
2025-12-11 01:46:57,484 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 01:46:57,484 - vector_store - ERROR - Failed to add embeddings: 
2025-12-11 01:46:57,484 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 01:46:57,484 - vector_store - ERROR - Search failed: 
2025-12-11 01:46:57,484 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 01:46:57,484 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 01:47:03,265 - main - INFO - Step 5: Generating medical report...
2025-12-11 01:47:03,265 - main - INFO - Pipeline processing completed successfully
2025-12-11 01:50:07,124 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 01:50:07,129 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 01:50:07,133 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 01:50:07,138 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 01:50:07,144 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 01:50:07,155 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 01:50:07,155 - main - INFO - MedTech Pipeline initialized
2025-12-11 01:50:07,155 - main - INFO - Initializing pipeline components...
2025-12-11 01:50:07,374 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 01:50:07,374 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:50:07,374 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 01:50:07,374 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 01:50:07,374 - main - INFO - Segmentation pipeline initialized
2025-12-11 01:50:07,374 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 01:50:07,375 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 01:50:07,375 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 01:50:08,065 - vector_store - INFO - Index moved to GPU
2025-12-11 01:50:08,065 - main - INFO - Vector store initialized
2025-12-11 01:50:08,065 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 01:50:08,065 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 01:50:08,065 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 01:50:08,065 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 01:50:08,065 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 01:50:08,066 - main - INFO - Medical LLM initialized
2025-12-11 01:50:08,066 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 01:50:08,066 - main - INFO - MCP-FHIR client initialized
2025-12-11 01:50:08,066 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 01:50:08,066 - main - INFO - Feedback collector initialized
2025-12-11 01:50:08,066 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 01:50:08,066 - main - INFO - Pipeline deployer initialized
2025-12-11 01:50:08,066 - api_server - INFO - Pipeline initialized successfully
2025-12-11 01:50:08,067 - api_server - INFO - Shutting down API server...
2025-12-11 01:50:41,773 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 01:50:41,778 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 01:50:41,782 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 01:50:41,787 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 01:50:41,795 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 01:50:41,807 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 01:50:41,807 - main - INFO - MedTech Pipeline initialized
2025-12-11 01:50:41,807 - main - INFO - Initializing pipeline components...
2025-12-11 01:50:42,131 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 01:50:42,131 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:50:42,131 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 01:50:42,131 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 01:50:42,131 - main - INFO - Segmentation pipeline initialized
2025-12-11 01:50:42,131 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 01:50:42,131 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 01:50:42,131 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 01:50:43,202 - vector_store - INFO - Index moved to GPU
2025-12-11 01:50:43,202 - main - INFO - Vector store initialized
2025-12-11 01:50:43,202 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 01:50:43,202 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 01:50:43,202 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 01:50:43,202 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 01:50:43,202 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 01:50:43,202 - main - INFO - Medical LLM initialized
2025-12-11 01:50:43,203 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 01:50:43,203 - main - INFO - MCP-FHIR client initialized
2025-12-11 01:50:43,203 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 01:50:43,203 - main - INFO - Feedback collector initialized
2025-12-11 01:50:43,203 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 01:50:43,203 - main - INFO - Pipeline deployer initialized
2025-12-11 01:50:43,203 - api_server - INFO - Pipeline initialized successfully
2025-12-11 01:50:51,464 - api_server - INFO - Processing uploaded file: ID_0aeb72cba.dcm
2025-12-11 01:50:51,464 - main - INFO - Processing medical image: data/uploads/ID_0aeb72cba.dcm
2025-12-11 01:50:51,464 - main - INFO - Step 1: Performing segmentation...
2025-12-11 01:50:51,464 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0aeb72cba.dcm
2025-12-11 01:50:51,469 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 01:50:51,469 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 01:50:51,470 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0aeb72cba.dcm: Use fallback preprocessing for DICOM
2025-12-11 01:50:51,470 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:50:51,473 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 01:50:51,473 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 01:50:57,236 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0aeb72cba_mask.nii.gz
2025-12-11 01:50:57,248 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 01:50:57,277 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0aeb72cba.dcm
2025-12-11 01:50:57,277 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 01:50:57,278 - vector_store - ERROR - Failed to add embeddings: 
2025-12-11 01:50:57,279 - vector_store - ERROR - Traceback (most recent call last):
  File "/home/samba/projects/MedTech-Diagnostic-LLM-Pipeline/vector_store.py", line 181, in add_embeddings
    self.index.add(embeddings)
  File "/home/samba/miniconda3/envs/medai/lib/python3.10/site-packages/faiss/__init__.py", line 214, in replacement_add
    assert d == self.d
AssertionError

2025-12-11 01:50:57,279 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 01:50:57,279 - vector_store - ERROR - Search failed: 
2025-12-11 01:50:57,279 - vector_store - ERROR - Traceback (most recent call last):
  File "/home/samba/projects/MedTech-Diagnostic-LLM-Pipeline/vector_store.py", line 243, in search_with_metadata
    distances, indices = index_to_use.search(q, k)
  File "/home/samba/miniconda3/envs/medai/lib/python3.10/site-packages/faiss/__init__.py", line 308, in replacement_search
    assert d == self.d
AssertionError

2025-12-11 01:50:57,279 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 01:50:57,279 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 01:51:03,153 - main - INFO - Step 5: Generating medical report...
2025-12-11 01:51:03,154 - main - INFO - Pipeline processing completed successfully
2025-12-11 01:51:49,654 - api_server - INFO - Shutting down API server...
2025-12-11 01:54:48,446 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 01:54:48,451 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 01:54:48,454 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 01:54:48,461 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 01:54:48,467 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 01:54:48,478 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 01:54:48,478 - main - INFO - MedTech Pipeline initialized
2025-12-11 01:54:48,478 - main - INFO - Initializing pipeline components...
2025-12-11 01:54:48,832 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 01:54:48,832 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:54:48,832 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 01:54:48,833 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 01:54:48,833 - main - INFO - Segmentation pipeline initialized
2025-12-11 01:54:48,833 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 01:54:48,833 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 01:54:48,833 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 01:54:50,064 - vector_store - INFO - Index moved to GPU
2025-12-11 01:54:50,065 - main - INFO - Vector store initialized
2025-12-11 01:54:50,065 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 01:54:50,065 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 01:54:50,065 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 01:54:50,065 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 01:54:50,065 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 01:54:50,065 - main - INFO - Medical LLM initialized
2025-12-11 01:54:50,065 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 01:54:50,065 - main - INFO - MCP-FHIR client initialized
2025-12-11 01:54:50,065 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 01:54:50,065 - main - INFO - Feedback collector initialized
2025-12-11 01:54:50,065 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 01:54:50,065 - main - INFO - Pipeline deployer initialized
2025-12-11 01:54:50,066 - api_server - INFO - Pipeline initialized successfully
2025-12-11 01:54:57,313 - api_server - INFO - Processing uploaded file: ID_0ac3e69bc.dcm
2025-12-11 01:54:57,314 - main - INFO - Processing medical image: data/uploads/ID_0ac3e69bc.dcm
2025-12-11 01:54:57,314 - main - INFO - Step 1: Performing segmentation...
2025-12-11 01:54:57,314 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0ac3e69bc.dcm
2025-12-11 01:54:57,320 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 01:54:57,320 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 01:54:57,320 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0ac3e69bc.dcm: Use fallback preprocessing for DICOM
2025-12-11 01:54:57,320 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:54:57,324 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 01:54:57,325 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 01:55:02,040 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0ac3e69bc_mask.nii.gz
2025-12-11 01:55:02,056 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 01:55:02,089 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0ac3e69bc.dcm
2025-12-11 01:55:02,090 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 01:55:02,090 - vector_store - ERROR - Failed to add embeddings: 
2025-12-11 01:55:02,090 - vector_store - ERROR - Traceback (most recent call last):
  File "/home/samba/projects/MedTech-Diagnostic-LLM-Pipeline/vector_store.py", line 181, in add_embeddings
    self.index.add(embeddings)
  File "/home/samba/miniconda3/envs/medai/lib/python3.10/site-packages/faiss/__init__.py", line 214, in replacement_add
    assert d == self.d
AssertionError

2025-12-11 01:55:02,091 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 01:55:02,091 - vector_store - ERROR - Search failed: 
2025-12-11 01:55:02,091 - vector_store - ERROR - Traceback (most recent call last):
  File "/home/samba/projects/MedTech-Diagnostic-LLM-Pipeline/vector_store.py", line 243, in search_with_metadata
    distances, indices = index_to_use.search(q, k)
  File "/home/samba/miniconda3/envs/medai/lib/python3.10/site-packages/faiss/__init__.py", line 308, in replacement_search
    assert d == self.d
AssertionError

2025-12-11 01:55:02,091 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 01:55:02,091 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 01:55:07,882 - main - INFO - Step 5: Generating medical report...
2025-12-11 01:55:07,882 - main - INFO - Pipeline processing completed successfully
2025-12-11 01:56:05,416 - api_server - INFO - Shutting down API server...
2025-12-11 01:57:09,785 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 01:57:09,789 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 01:57:09,793 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 01:57:09,799 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 01:57:09,805 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 01:57:09,816 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 01:57:09,816 - main - INFO - MedTech Pipeline initialized
2025-12-11 01:57:09,816 - main - INFO - Initializing pipeline components...
2025-12-11 01:57:10,111 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 01:57:10,111 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:57:10,111 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 01:57:10,111 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 01:57:10,111 - main - INFO - Segmentation pipeline initialized
2025-12-11 01:57:10,111 - vector_store - INFO - Building new FAISS index from config
2025-12-11 01:57:10,113 - vector_store - INFO - Created IndexIVFFlat with nlist=100
2025-12-11 01:57:10,113 - vector_store - INFO - IndexIVF requires training. It will be trained on first add_embeddings batch.
2025-12-11 01:57:10,114 - vector_store - INFO - Saved new FAISS index to data/faiss_index
2025-12-11 01:57:10,114 - main - INFO - Vector store initialized
2025-12-11 01:57:10,114 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 01:57:10,114 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 01:57:10,114 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 01:57:10,114 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 01:57:10,114 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 01:57:10,114 - main - INFO - Medical LLM initialized
2025-12-11 01:57:10,114 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 01:57:10,114 - main - INFO - MCP-FHIR client initialized
2025-12-11 01:57:10,114 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 01:57:10,115 - main - INFO - Feedback collector initialized
2025-12-11 01:57:10,115 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 01:57:10,115 - main - INFO - Pipeline deployer initialized
2025-12-11 01:57:10,115 - api_server - INFO - Pipeline initialized successfully
2025-12-11 01:57:54,516 - api_server - INFO - Processing uploaded file: ID_0aeb72cba.dcm
2025-12-11 01:57:54,516 - main - INFO - Processing medical image: data/uploads/ID_0aeb72cba.dcm
2025-12-11 01:57:54,517 - main - INFO - Step 1: Performing segmentation...
2025-12-11 01:57:54,517 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0aeb72cba.dcm
2025-12-11 01:57:54,522 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 01:57:54,522 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 01:57:54,522 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0aeb72cba.dcm: Use fallback preprocessing for DICOM
2025-12-11 01:57:54,523 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 01:57:54,527 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 01:57:54,527 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 01:57:58,661 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0aeb72cba_mask.nii.gz
2025-12-11 01:57:58,678 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 01:57:58,718 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0aeb72cba.dcm
2025-12-11 01:57:58,718 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 01:57:58,719 - vector_store - INFO - Training IVF index on provided embeddings
2025-12-11 01:57:58,721 - vector_store - ERROR - Failed to add embeddings: Error in void faiss::Clustering::train_encoded(faiss::Clustering::idx_t, const uint8_t*, const faiss::Index*, faiss::Index&, const float*) at /project/faiss/faiss/Clustering.cpp:283: Error: 'nx >= k' failed: Number of training points (1) should be at least as large as number of clusters (100)
2025-12-11 01:57:58,723 - vector_store - ERROR - Traceback (most recent call last):
  File "/home/samba/projects/MedTech-Diagnostic-LLM-Pipeline/vector_store.py", line 180, in add_embeddings
    self.index.train(embeddings)
  File "/home/samba/miniconda3/envs/medai/lib/python3.10/site-packages/faiss/__init__.py", line 280, in replacement_train
    self.train_c(n, swig_ptr(x))
  File "/home/samba/miniconda3/envs/medai/lib/python3.10/site-packages/faiss/swigfaiss.py", line 5104, in train
    return _swigfaiss.IndexIVF_train(self, n, x)
RuntimeError: Error in void faiss::Clustering::train_encoded(faiss::Clustering::idx_t, const uint8_t*, const faiss::Index*, faiss::Index&, const float*) at /project/faiss/faiss/Clustering.cpp:283: Error: 'nx >= k' failed: Number of training points (1) should be at least as large as number of clusters (100)

2025-12-11 01:57:58,723 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 01:57:58,724 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 01:57:58,724 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 01:58:27,624 - mcp_fhir.mcp_fhir_client - WARNING - FHIR request failed (attempt 1): HTTPSConnectionPool(host='hapi.fhir.org', port=443): Max retries exceeded with url: /baseR4/Patient/unknown (Caused by ConnectTimeoutError(<HTTPSConnection(host='hapi.fhir.org', port=443) at 0x7f1f6def6440>, 'Connection to hapi.fhir.org timed out. (connect timeout=30)'))
2025-12-11 01:58:33,061 - main - INFO - Step 5: Generating medical report...
2025-12-11 01:58:33,061 - main - INFO - Pipeline processing completed successfully
2025-12-11 02:00:15,715 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 02:00:15,726 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 02:00:15,734 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 02:00:15,746 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 02:00:15,759 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 02:00:15,779 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 02:00:15,779 - main - INFO - MedTech Pipeline initialized
2025-12-11 02:00:15,779 - main - INFO - Initializing pipeline components...
2025-12-11 02:00:16,544 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 02:00:16,544 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 02:00:16,544 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 02:00:16,544 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 02:00:16,544 - main - INFO - Segmentation pipeline initialized
2025-12-11 02:00:16,545 - vector_store - INFO - Building new FAISS index from config
2025-12-11 02:00:16,545 - vector_store - INFO - Created IndexFlatL2
2025-12-11 02:00:16,546 - vector_store - INFO - Saved new FAISS index to data/faiss_index
2025-12-11 02:00:16,547 - main - INFO - Vector store initialized
2025-12-11 02:00:16,547 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 02:00:16,547 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 02:00:16,548 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 02:00:16,548 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 02:00:16,548 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 02:00:16,548 - main - INFO - Medical LLM initialized
2025-12-11 02:00:16,549 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 02:00:16,549 - main - INFO - MCP-FHIR client initialized
2025-12-11 02:00:16,550 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 02:00:16,550 - main - INFO - Feedback collector initialized
2025-12-11 02:00:16,550 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 02:00:16,550 - main - INFO - Pipeline deployer initialized
2025-12-11 02:00:16,550 - api_server - INFO - Pipeline initialized successfully
2025-12-11 02:00:36,328 - api_server - INFO - Processing uploaded file: ID_0ac3e69bc.dcm
2025-12-11 02:00:36,328 - main - INFO - Processing medical image: data/uploads/ID_0ac3e69bc.dcm
2025-12-11 02:00:36,328 - main - INFO - Step 1: Performing segmentation...
2025-12-11 02:00:36,328 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0ac3e69bc.dcm
2025-12-11 02:00:36,343 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 02:00:36,343 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 02:00:36,344 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0ac3e69bc.dcm: Use fallback preprocessing for DICOM
2025-12-11 02:00:36,344 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 02:00:36,354 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 02:00:36,354 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 02:00:42,685 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0ac3e69bc_mask.nii.gz
2025-12-11 02:00:42,721 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 02:00:42,793 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0ac3e69bc.dcm
2025-12-11 02:00:42,794 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 02:00:42,796 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 02:00:42,796 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 02:00:45,088 - vector_store - INFO - Index moved to GPU
2025-12-11 02:00:45,089 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 02:00:45,423 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 02:00:45,424 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 02:00:51,185 - main - INFO - Step 5: Generating medical report...
2025-12-11 02:00:51,186 - main - INFO - Pipeline processing completed successfully
2025-12-11 02:01:02,984 - api_server - INFO - Shutting down API server...
2025-12-11 10:41:26,045 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 10:41:26,050 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 10:41:26,054 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 10:41:26,060 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 10:41:26,066 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 10:41:26,078 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 10:41:26,078 - main - INFO - MedTech Pipeline initialized
2025-12-11 10:41:26,078 - main - INFO - Initializing pipeline components...
2025-12-11 10:41:26,847 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 10:41:26,847 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 10:41:26,847 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 10:41:26,847 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 10:41:26,847 - main - INFO - Segmentation pipeline initialized
2025-12-11 10:41:26,847 - vector_store - INFO - Loaded metadata with 1 records
2025-12-11 10:41:26,847 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 10:41:26,849 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 10:41:26,851 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 10:41:28,848 - vector_store - INFO - Index moved to GPU
2025-12-11 10:41:28,848 - main - INFO - Vector store initialized
2025-12-11 10:41:28,848 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 10:41:28,848 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 10:41:28,848 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 10:41:28,848 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 10:41:28,848 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 10:41:28,848 - main - INFO - Medical LLM initialized
2025-12-11 10:41:28,848 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 10:41:28,849 - main - INFO - MCP-FHIR client initialized
2025-12-11 10:41:28,849 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 10:41:28,849 - main - INFO - Feedback collector initialized
2025-12-11 10:41:28,849 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 10:41:28,849 - main - INFO - Pipeline deployer initialized
2025-12-11 10:41:28,849 - api_server - INFO - Pipeline initialized successfully
2025-12-11 10:55:29,475 - api_server - INFO - Shutting down API server...
2025-12-11 10:56:11,048 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 10:56:11,053 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 10:56:11,057 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 10:56:11,063 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 10:56:11,069 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 10:56:11,080 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 10:56:11,080 - main - INFO - MedTech Pipeline initialized
2025-12-11 10:56:11,080 - main - INFO - Initializing pipeline components...
2025-12-11 10:56:11,363 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 10:56:11,364 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 10:56:11,364 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 10:56:11,364 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 10:56:11,364 - main - INFO - Segmentation pipeline initialized
2025-12-11 10:56:11,364 - vector_store - INFO - Loaded metadata with 1 records
2025-12-11 10:56:11,364 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 10:56:11,364 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 10:56:11,364 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 10:56:12,782 - vector_store - INFO - Index moved to GPU
2025-12-11 10:56:12,783 - main - INFO - Vector store initialized
2025-12-11 10:56:12,783 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 10:56:12,783 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 10:56:12,783 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 10:56:12,783 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 10:56:12,783 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 10:56:12,783 - main - INFO - Medical LLM initialized
2025-12-11 10:56:12,784 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 10:56:12,784 - main - INFO - MCP-FHIR client initialized
2025-12-11 10:56:12,784 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 10:56:12,784 - main - INFO - Feedback collector initialized
2025-12-11 10:56:12,784 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 10:56:12,784 - main - INFO - Pipeline deployer initialized
2025-12-11 10:56:12,784 - api_server - INFO - Pipeline initialized successfully
2025-12-11 10:56:54,278 - api_server - INFO - Processing uploaded file: ID_0ab3c2234.dcm
2025-12-11 10:56:54,279 - main - INFO - Processing medical image: data/uploads/ID_0ab3c2234.dcm
2025-12-11 10:56:54,279 - main - INFO - Step 1: Performing segmentation...
2025-12-11 10:56:54,279 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0ab3c2234.dcm
2025-12-11 10:56:54,290 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 10:56:54,290 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 10:56:54,290 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0ab3c2234.dcm: Use fallback preprocessing for DICOM
2025-12-11 10:56:54,290 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 10:56:54,294 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 10:56:54,294 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 10:57:00,490 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0ab3c2234_mask.nii.gz
2025-12-11 10:57:00,514 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 10:57:00,557 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0ab3c2234.dcm
2025-12-11 10:57:00,557 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 10:57:00,559 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 10:57:00,560 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 10:57:01,501 - vector_store - INFO - Index moved to GPU
2025-12-11 10:57:01,502 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 10:57:01,504 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 10:57:01,504 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 10:57:07,037 - main - INFO - Step 5: Generating medical report...
2025-12-11 10:57:07,037 - main - INFO - Pipeline processing completed successfully
2025-12-11 10:59:22,430 - api_server - INFO - Processing uploaded file: ._spleen_45.nii.gz
2025-12-11 10:59:22,430 - main - INFO - Processing medical image: data/uploads/._spleen_45.nii.gz
2025-12-11 10:59:22,430 - main - INFO - Step 1: Performing segmentation...
2025-12-11 10:59:22,430 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/._spleen_45.nii.gz
2025-12-11 10:59:22,431 - segmentation.preprocessing - ERROR - Failed to load NIfTI file data/uploads/._spleen_45.nii.gz: File data/uploads/._spleen_45.nii.gz is not a gzip file
2025-12-11 10:59:22,431 - segmentation.preprocessing - ERROR - Failed to load image data/uploads/._spleen_45.nii.gz: File data/uploads/._spleen_45.nii.gz is not a gzip file
2025-12-11 10:59:22,431 - main - ERROR - Pipeline processing failed: File data/uploads/._spleen_45.nii.gz is not a gzip file
2025-12-11 10:59:38,420 - api_server - INFO - Processing uploaded file: spleen_19.nii.gz
2025-12-11 10:59:38,420 - main - INFO - Processing medical image: data/uploads/spleen_19.nii.gz
2025-12-11 10:59:38,420 - main - INFO - Step 1: Performing segmentation...
2025-12-11 10:59:38,420 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/spleen_19.nii.gz
2025-12-11 10:59:38,644 - segmentation.preprocessing - INFO - Loaded NIfTI image: (512, 512, 51)
2025-12-11 11:00:13,674 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/spleen_19.nii_mask.nii.gz
2025-12-11 11:00:44,245 - segmentation.preprocessing - INFO - Loaded NIfTI image: (512, 512, 51)
2025-12-11 11:00:43,797 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/spleen_19.nii.gz
2025-12-11 11:00:43,798 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 11:00:43,799 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 11:00:43,799 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 11:00:44,114 - vector_store - INFO - Index moved to GPU
2025-12-11 11:00:44,115 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 11:00:44,116 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 11:00:44,117 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 11:00:49,722 - main - INFO - Step 5: Generating medical report...
2025-12-11 11:00:49,722 - main - INFO - Pipeline processing completed successfully
2025-12-11 11:06:42,109 - api_server - INFO - Shutting down API server...
2025-12-11 11:07:06,690 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 11:07:06,694 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 11:07:06,698 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 11:07:06,705 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 11:07:06,711 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 11:07:06,721 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 11:07:06,721 - main - INFO - MedTech Pipeline initialized
2025-12-11 11:07:06,721 - main - INFO - Initializing pipeline components...
2025-12-11 11:07:07,115 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 11:07:07,115 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 11:07:07,115 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 11:07:07,115 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 11:07:07,115 - main - INFO - Segmentation pipeline initialized
2025-12-11 11:07:07,115 - vector_store - INFO - Loaded metadata with 3 records
2025-12-11 11:07:07,115 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 11:07:07,115 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 11:07:07,116 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 11:07:09,060 - vector_store - INFO - Index moved to GPU
2025-12-11 11:07:09,060 - main - INFO - Vector store initialized
2025-12-11 11:07:09,060 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 11:07:09,060 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 11:07:09,060 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 11:07:09,060 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 11:07:09,060 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 11:07:09,060 - main - INFO - Medical LLM initialized
2025-12-11 11:07:09,060 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 11:07:09,060 - main - INFO - MCP-FHIR client initialized
2025-12-11 11:07:09,061 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 11:07:09,061 - main - INFO - Feedback collector initialized
2025-12-11 11:07:09,061 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 11:07:09,061 - main - INFO - Pipeline deployer initialized
2025-12-11 11:07:09,061 - api_server - INFO - Pipeline initialized successfully
2025-12-11 11:07:50,875 - api_server - INFO - Processing uploaded file: spleen_19.nii.gz
2025-12-11 11:07:50,875 - main - INFO - Processing medical image: data/uploads/spleen_19.nii.gz
2025-12-11 11:07:50,875 - main - INFO - Step 1: Performing segmentation...
2025-12-11 11:07:50,875 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/spleen_19.nii.gz
2025-12-11 11:07:51,105 - segmentation.preprocessing - INFO - Loaded NIfTI image: (512, 512, 51)
2025-12-11 11:08:47,228 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/spleen_19.nii_mask.nii.gz
2025-12-11 11:08:47,567 - segmentation.preprocessing - INFO - Loaded NIfTI image: (512, 512, 51)
2025-12-11 11:08:48,623 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/spleen_19.nii.gz
2025-12-11 11:08:48,624 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 11:08:48,625 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 11:08:48,625 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 11:08:49,009 - vector_store - INFO - Index moved to GPU
2025-12-11 11:08:49,009 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 11:08:49,011 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 11:08:49,011 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 11:08:54,630 - main - INFO - Step 5: Generating medical report...
2025-12-11 11:08:54,631 - main - INFO - Pipeline processing completed successfully
2025-12-11 11:11:19,091 - api_server - INFO - Shutting down API server...
2025-12-11 11:11:32,992 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 11:11:32,998 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 11:11:33,002 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 11:11:33,008 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 11:11:33,014 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 11:11:33,025 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 11:11:33,025 - main - INFO - MedTech Pipeline initialized
2025-12-11 11:11:33,025 - main - INFO - Initializing pipeline components...
2025-12-11 11:11:33,347 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 11:11:33,347 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 11:11:33,347 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 11:11:33,347 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 11:11:33,347 - main - INFO - Segmentation pipeline initialized
2025-12-11 11:11:33,348 - vector_store - INFO - Loaded metadata with 4 records
2025-12-11 11:11:33,348 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 11:11:33,348 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 11:11:33,348 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 11:11:34,658 - vector_store - INFO - Index moved to GPU
2025-12-11 11:11:34,658 - main - INFO - Vector store initialized
2025-12-11 11:11:34,658 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 11:11:34,658 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 11:11:34,658 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 11:11:34,658 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 11:11:34,658 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 11:11:34,658 - main - INFO - Medical LLM initialized
2025-12-11 11:11:34,658 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 11:11:34,658 - main - INFO - MCP-FHIR client initialized
2025-12-11 11:11:34,658 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 11:11:34,659 - main - INFO - Feedback collector initialized
2025-12-11 11:11:34,659 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 11:11:34,659 - main - INFO - Pipeline deployer initialized
2025-12-11 11:11:34,659 - api_server - INFO - Pipeline initialized successfully
2025-12-11 11:12:00,642 - api_server - INFO - Processing uploaded file: spleen_19.nii.gz
2025-12-11 11:12:00,642 - main - INFO - Processing medical image: data/uploads/spleen_19.nii.gz
2025-12-11 11:12:00,642 - main - INFO - Step 1: Performing segmentation...
2025-12-11 11:12:00,643 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/spleen_19.nii.gz
2025-12-11 11:12:00,859 - segmentation.preprocessing - INFO - Loaded NIfTI image: (512, 512, 51)
2025-12-11 11:12:56,787 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/spleen_19.nii_mask.nii.gz
2025-12-11 11:12:57,122 - segmentation.preprocessing - INFO - Loaded NIfTI image: (512, 512, 51)
2025-12-11 11:12:58,255 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/spleen_19.nii.gz
2025-12-11 11:12:58,256 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 11:12:58,257 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 11:12:58,257 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 11:12:58,674 - vector_store - INFO - Index moved to GPU
2025-12-11 11:12:58,674 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 11:12:58,675 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 11:12:58,675 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 11:13:04,214 - main - INFO - Step 5: Generating medical report...
2025-12-11 11:13:04,215 - main - INFO - Pipeline processing completed successfully
2025-12-11 11:13:55,914 - api_server - INFO - Processing uploaded file: ID_0ba83217f.dcm
2025-12-11 11:13:55,914 - main - INFO - Processing medical image: data/uploads/ID_0ba83217f.dcm
2025-12-11 11:13:55,914 - main - INFO - Step 1: Performing segmentation...
2025-12-11 11:13:55,914 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0ba83217f.dcm
2025-12-11 11:13:55,924 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 11:13:55,924 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 11:13:55,924 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0ba83217f.dcm: Use fallback preprocessing for DICOM
2025-12-11 11:13:55,924 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 11:13:55,928 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 11:13:55,929 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 11:14:03,887 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0ba83217f_mask.nii.gz
2025-12-11 11:14:07,331 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 11:14:07,369 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0ba83217f.dcm
2025-12-11 11:14:07,370 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 11:14:07,371 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 11:14:07,371 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 11:14:08,131 - vector_store - INFO - Index moved to GPU
2025-12-11 11:14:08,132 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 11:14:08,133 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 11:14:08,133 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 11:14:13,689 - main - INFO - Step 5: Generating medical report...
2025-12-11 11:14:13,690 - main - INFO - Pipeline processing completed successfully
2025-12-11 11:29:57,351 - api_server - INFO - Shutting down API server...
2025-12-11 11:31:23,582 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 11:31:23,587 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 11:31:23,590 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 11:31:23,596 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 11:31:23,602 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 11:31:23,612 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 11:31:23,612 - main - INFO - MedTech Pipeline initialized
2025-12-11 11:31:23,612 - main - INFO - Initializing pipeline components...
2025-12-11 11:31:23,922 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 11:31:23,922 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 11:31:23,922 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 11:31:23,922 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 11:31:23,922 - main - INFO - Segmentation pipeline initialized
2025-12-11 11:31:23,922 - vector_store - INFO - Loaded metadata with 6 records
2025-12-11 11:31:23,922 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 11:31:23,923 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 11:31:23,923 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 11:31:25,026 - vector_store - INFO - Index moved to GPU
2025-12-11 11:31:25,026 - main - INFO - Vector store initialized
2025-12-11 11:31:25,026 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 11:31:25,026 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 11:31:25,026 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 11:31:25,026 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 11:31:25,026 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 11:31:25,026 - main - INFO - Medical LLM initialized
2025-12-11 11:31:25,026 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 11:31:25,027 - main - INFO - MCP-FHIR client initialized
2025-12-11 11:31:25,027 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 11:31:25,027 - main - INFO - Feedback collector initialized
2025-12-11 11:31:25,027 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 11:31:25,027 - main - INFO - Pipeline deployer initialized
2025-12-11 11:31:25,027 - api_server - INFO - Pipeline initialized successfully
2025-12-11 11:31:24,588 - llm.medical_llm - ERROR - Inference API streaming error: 
2025-12-11 11:31:24,589 - llm.medical_llm - WARNING - Falling back to local model if available...
2025-12-11 11:33:29,829 - api_server - INFO - Shutting down API server...
2025-12-11 11:33:40,813 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 11:33:40,818 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 11:33:40,822 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 11:33:40,827 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 11:33:40,834 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 11:33:40,845 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 11:33:40,845 - main - INFO - MedTech Pipeline initialized
2025-12-11 11:33:40,845 - main - INFO - Initializing pipeline components...
2025-12-11 11:33:41,291 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 11:33:41,291 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 11:33:41,291 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 11:33:41,291 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 11:33:41,291 - main - INFO - Segmentation pipeline initialized
2025-12-11 11:33:41,292 - vector_store - INFO - Loaded metadata with 6 records
2025-12-11 11:33:41,292 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 11:33:41,292 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 11:33:41,292 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 11:33:42,935 - vector_store - INFO - Index moved to GPU
2025-12-11 11:33:42,935 - main - INFO - Vector store initialized
2025-12-11 11:33:42,935 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 11:33:42,935 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 11:33:42,935 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 11:33:42,935 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 11:33:42,936 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 11:33:42,936 - main - INFO - Medical LLM initialized
2025-12-11 11:33:42,936 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 11:33:42,936 - main - INFO - MCP-FHIR client initialized
2025-12-11 11:33:42,936 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 11:33:42,936 - main - INFO - Feedback collector initialized
2025-12-11 11:33:42,936 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 11:33:42,936 - main - INFO - Pipeline deployer initialized
2025-12-11 11:33:42,936 - api_server - INFO - Pipeline initialized successfully
2025-12-11 11:33:58,662 - llm.medical_llm - ERROR - Inference API streaming error: StopIteration()
2025-12-11 11:33:58,663 - llm.medical_llm - WARNING - Falling back to local model if available...
2025-12-11 11:33:58,663 - llm.medical_llm - WARNING - Models unavailable, serving simulated stream.
2025-12-11 11:56:51,062 - api_server - INFO - Shutting down API server...
2025-12-11 12:00:18,864 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 12:00:18,868 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 12:00:18,872 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 12:00:18,878 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 12:00:18,884 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 12:00:18,893 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 12:00:18,894 - main - INFO - MedTech Pipeline initialized
2025-12-11 12:00:18,894 - main - INFO - Initializing pipeline components...
2025-12-11 12:00:19,192 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 12:00:19,192 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 12:00:19,192 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 12:00:19,192 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 12:00:19,192 - main - INFO - Segmentation pipeline initialized
2025-12-11 12:00:19,192 - vector_store - INFO - Loaded metadata with 6 records
2025-12-11 12:00:19,192 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 12:00:19,193 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 12:00:19,193 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 12:00:20,782 - vector_store - INFO - Index moved to GPU
2025-12-11 12:00:20,782 - main - INFO - Vector store initialized
2025-12-11 12:00:20,782 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biomistral
2025-12-11 12:00:20,782 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: BioMistral/BioMistral-7B
2025-12-11 12:00:27,021 - llm.medical_llm - INFO - Using BitsAndBytesConfig for 4-bit quantization
2025-12-11 12:15:51,531 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-11 12:15:51,552 - llm.medical_llm - ERROR - Failed to initialize model: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. 
2025-12-11 12:15:51,552 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-11 12:15:51,557 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Local)
2025-12-11 12:15:51,557 - main - INFO - Medical LLM initialized
2025-12-11 12:15:51,557 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 12:15:51,557 - main - INFO - MCP-FHIR client initialized
2025-12-11 12:15:51,558 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 12:15:51,558 - main - INFO - Feedback collector initialized
2025-12-11 12:15:51,558 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 12:15:51,558 - main - INFO - Pipeline deployer initialized
2025-12-11 12:15:51,558 - api_server - INFO - Pipeline initialized successfully
2025-12-11 12:22:21,754 - api_server - INFO - Processing uploaded file: ID_0a50c0cc7.dcm
2025-12-11 12:22:21,754 - main - INFO - Processing medical image: data/uploads/ID_0a50c0cc7.dcm
2025-12-11 12:22:21,755 - main - INFO - Step 1: Performing segmentation...
2025-12-11 12:22:21,755 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0a50c0cc7.dcm
2025-12-11 12:22:21,764 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 12:22:21,764 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 12:22:21,764 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0a50c0cc7.dcm: Use fallback preprocessing for DICOM
2025-12-11 12:22:21,764 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 12:22:21,768 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 12:22:21,768 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 12:22:28,784 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0a50c0cc7_mask.nii.gz
2025-12-11 12:22:28,799 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 12:22:28,834 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0a50c0cc7.dcm
2025-12-11 12:22:28,835 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 12:22:28,838 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 12:22:28,838 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 12:22:29,882 - vector_store - INFO - Index moved to GPU
2025-12-11 12:22:29,882 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 12:22:29,885 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 12:22:29,885 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 12:22:34,178 - main - INFO - Step 5: Generating medical report...
2025-12-11 12:22:34,179 - main - INFO - Pipeline processing completed successfully
2025-12-11 12:23:26,716 - api_server - INFO - Shutting down API server...
2025-12-11 12:24:54,824 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 12:24:54,829 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 12:24:54,833 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 12:24:54,839 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 12:24:54,845 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 12:24:54,855 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 12:24:54,855 - main - INFO - MedTech Pipeline initialized
2025-12-11 12:24:54,855 - main - INFO - Initializing pipeline components...
2025-12-11 12:24:55,220 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 12:24:55,221 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 12:24:55,221 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 12:24:55,221 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 12:24:55,221 - main - INFO - Segmentation pipeline initialized
2025-12-11 12:24:55,222 - vector_store - INFO - Loaded metadata with 7 records
2025-12-11 12:24:55,222 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 12:24:55,222 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 12:24:55,222 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 12:24:56,692 - vector_store - INFO - Index moved to GPU
2025-12-11 12:24:56,692 - main - INFO - Vector store initialized
2025-12-11 12:24:56,692 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biomistral
2025-12-11 12:24:56,692 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: BioMistral/BioMistral-7B
2025-12-11 12:24:57,219 - llm.medical_llm - INFO - Using BitsAndBytesConfig for 4-bit quantization
2025-12-11 12:24:58,466 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-11 12:24:58,485 - llm.medical_llm - ERROR - Failed to initialize model: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. 
2025-12-11 12:24:58,485 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-11 12:24:58,490 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Local)
2025-12-11 12:24:58,491 - main - INFO - Medical LLM initialized
2025-12-11 12:24:58,491 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 12:24:58,491 - main - INFO - MCP-FHIR client initialized
2025-12-11 12:24:58,491 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 12:24:58,491 - main - INFO - Feedback collector initialized
2025-12-11 12:24:58,491 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 12:24:58,492 - main - INFO - Pipeline deployer initialized
2025-12-11 12:24:58,492 - api_server - INFO - Pipeline initialized successfully
2025-12-11 12:25:12,776 - api_server - INFO - Processing uploaded file: ID_0aeb72cba.dcm
2025-12-11 12:25:12,776 - main - INFO - Processing medical image: data/uploads/ID_0aeb72cba.dcm
2025-12-11 12:25:12,776 - main - INFO - Step 1: Performing segmentation...
2025-12-11 12:25:12,777 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0aeb72cba.dcm
2025-12-11 12:25:12,782 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 12:25:12,782 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 12:25:12,782 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0aeb72cba.dcm: Use fallback preprocessing for DICOM
2025-12-11 12:25:12,782 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 12:25:12,785 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 12:25:12,785 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 12:25:19,082 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0aeb72cba_mask.nii.gz
2025-12-11 12:25:19,107 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 12:25:19,162 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0aeb72cba.dcm
2025-12-11 12:25:19,163 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 12:25:19,164 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 12:25:19,164 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 12:25:19,594 - vector_store - INFO - Index moved to GPU
2025-12-11 12:25:19,594 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 12:25:19,595 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 12:25:19,595 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 12:25:25,226 - main - INFO - Step 5: Generating medical report...
2025-12-11 12:25:25,227 - main - INFO - Pipeline processing completed successfully
2025-12-11 12:31:19,670 - api_server - INFO - Shutting down API server...
2025-12-11 12:33:17,264 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 12:33:17,268 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 12:33:17,272 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 12:33:17,278 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 12:33:17,283 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 12:33:17,294 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 12:33:17,294 - main - INFO - MedTech Pipeline initialized
2025-12-11 12:33:17,294 - main - INFO - Initializing pipeline components...
2025-12-11 12:33:17,790 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 12:33:17,790 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 12:33:17,790 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 12:33:17,790 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 12:33:17,790 - main - INFO - Segmentation pipeline initialized
2025-12-11 12:33:17,790 - vector_store - INFO - Loaded metadata with 8 records
2025-12-11 12:33:17,791 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 12:33:17,791 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 12:33:17,791 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 12:33:19,263 - vector_store - INFO - Index moved to GPU
2025-12-11 12:33:19,263 - main - INFO - Vector store initialized
2025-12-11 12:33:19,263 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biomistral
2025-12-11 12:33:19,263 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: microsoft/BioGPT-Large
2025-12-11 12:33:23,333 - llm.medical_llm - ERROR - Failed to initialize model: 
 requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.

2025-12-11 12:33:23,333 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-11 12:33:23,333 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Local)
2025-12-11 12:33:23,333 - main - INFO - Medical LLM initialized
2025-12-11 12:33:23,333 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 12:33:23,333 - main - INFO - MCP-FHIR client initialized
2025-12-11 12:33:23,333 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 12:33:23,333 - main - INFO - Feedback collector initialized
2025-12-11 12:33:23,333 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 12:33:23,333 - main - INFO - Pipeline deployer initialized
2025-12-11 12:33:23,333 - api_server - INFO - Pipeline initialized successfully
2025-12-11 12:33:58,337 - api_server - INFO - Processing uploaded file: ID_0ab3c2234.dcm
2025-12-11 12:33:58,337 - main - INFO - Processing medical image: data/uploads/ID_0ab3c2234.dcm
2025-12-11 12:33:58,337 - main - INFO - Step 1: Performing segmentation...
2025-12-11 12:33:58,337 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0ab3c2234.dcm
2025-12-11 12:33:58,343 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 12:33:58,344 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 12:33:58,344 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0ab3c2234.dcm: Use fallback preprocessing for DICOM
2025-12-11 12:33:58,344 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 12:33:58,348 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 12:33:58,348 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 12:34:04,585 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0ab3c2234_mask.nii.gz
2025-12-11 12:34:04,604 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 12:34:04,642 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0ab3c2234.dcm
2025-12-11 12:34:04,643 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 12:34:04,644 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 12:34:04,644 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 12:34:05,217 - vector_store - INFO - Index moved to GPU
2025-12-11 12:34:05,217 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 12:34:05,218 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 12:34:05,218 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 12:34:10,474 - main - INFO - Step 5: Generating medical report...
2025-12-11 12:34:10,474 - main - INFO - Pipeline processing completed successfully
2025-12-11 12:35:18,949 - api_server - INFO - Shutting down API server...
2025-12-11 12:35:36,531 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 12:35:36,536 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 12:35:36,540 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 12:35:36,547 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 12:35:36,555 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 12:35:36,565 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 12:35:36,566 - main - INFO - MedTech Pipeline initialized
2025-12-11 12:35:36,566 - main - INFO - Initializing pipeline components...
2025-12-11 12:35:36,940 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 12:35:36,941 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 12:35:36,941 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 12:35:36,941 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 12:35:36,941 - main - INFO - Segmentation pipeline initialized
2025-12-11 12:35:36,942 - vector_store - INFO - Loaded metadata with 9 records
2025-12-11 12:35:36,943 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 12:35:36,943 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 12:35:36,943 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 12:35:38,317 - vector_store - INFO - Index moved to GPU
2025-12-11 12:35:38,318 - main - INFO - Vector store initialized
2025-12-11 12:35:38,318 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biomistral
2025-12-11 12:35:38,318 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: microsoft/BioGPT-Large
2025-12-11 12:35:38,817 - llm.medical_llm - ERROR - Failed to initialize model: 
 requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.

2025-12-11 12:35:38,817 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-11 12:35:38,817 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Local)
2025-12-11 12:35:38,817 - main - INFO - Medical LLM initialized
2025-12-11 12:35:38,818 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 12:35:38,818 - main - INFO - MCP-FHIR client initialized
2025-12-11 12:35:38,818 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 12:35:38,818 - main - INFO - Feedback collector initialized
2025-12-11 12:35:38,818 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 12:35:38,818 - main - INFO - Pipeline deployer initialized
2025-12-11 12:35:38,818 - api_server - INFO - Pipeline initialized successfully
2025-12-11 12:35:55,457 - api_server - INFO - Shutting down API server...
2025-12-11 12:36:25,990 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 12:36:25,995 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 12:36:25,999 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 12:36:26,005 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 12:36:26,015 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 12:36:26,029 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 12:36:26,029 - main - INFO - MedTech Pipeline initialized
2025-12-11 12:36:26,030 - main - INFO - Initializing pipeline components...
2025-12-11 12:36:26,437 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 12:36:26,437 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 12:36:26,437 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 12:36:26,437 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 12:36:26,437 - main - INFO - Segmentation pipeline initialized
2025-12-11 12:36:26,438 - vector_store - INFO - Loaded metadata with 9 records
2025-12-11 12:36:26,438 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 12:36:26,438 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 12:36:26,438 - vector_store - INFO - Moving FAISS index to GPU 0
2025-12-11 12:36:27,680 - vector_store - INFO - Index moved to GPU
2025-12-11 12:36:27,680 - main - INFO - Vector store initialized
2025-12-11 12:36:27,680 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biomistral
2025-12-11 12:36:27,680 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: microsoft/BioGPT-Large
2025-12-11 12:36:28,037 - llm.medical_llm - ERROR - Failed to initialize model: You need to install sacremoses to use BioGptTokenizer. See https://pypi.org/project/sacremoses/ for installation.
2025-12-11 12:36:28,037 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-11 12:36:28,037 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Local)
2025-12-11 12:36:28,037 - main - INFO - Medical LLM initialized
2025-12-11 12:36:28,037 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 12:36:28,037 - main - INFO - MCP-FHIR client initialized
2025-12-11 12:36:28,037 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 12:36:28,037 - main - INFO - Feedback collector initialized
2025-12-11 12:36:28,037 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 12:36:28,038 - main - INFO - Pipeline deployer initialized
2025-12-11 12:36:28,038 - api_server - INFO - Pipeline initialized successfully
2025-12-11 12:36:43,626 - api_server - INFO - Shutting down API server...
2025-12-11 12:37:21,265 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 12:37:21,270 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 12:37:21,273 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 12:37:21,279 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 12:37:21,285 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 12:37:21,295 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 12:37:21,295 - main - INFO - MedTech Pipeline initialized
2025-12-11 12:37:21,295 - main - INFO - Initializing pipeline components...
2025-12-11 12:37:21,581 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 12:37:21,581 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 12:37:21,582 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 12:37:21,582 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 12:37:21,582 - main - INFO - Segmentation pipeline initialized
2025-12-11 12:37:21,582 - vector_store - INFO - Loaded metadata with 9 records
2025-12-11 12:37:21,582 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 12:37:21,582 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 12:37:21,582 - main - INFO - Vector store initialized
2025-12-11 12:37:21,582 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biomistral
2025-12-11 12:37:21,582 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: microsoft/BioGPT-Large
2025-12-11 12:37:22,151 - llm.medical_llm - INFO - Using BitsAndBytesConfig for 4-bit quantization
2025-12-11 12:42:31,002 - llm.medical_llm - ERROR - Failed to initialize model: BioGptForCausalLM does not support `device_map='auto'`. To implement support, the model class needs to implement the `_no_split_modules` attribute.
2025-12-11 12:42:31,002 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-11 12:42:31,006 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Local)
2025-12-11 12:42:31,006 - main - INFO - Medical LLM initialized
2025-12-11 12:42:31,006 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 12:42:31,007 - main - INFO - MCP-FHIR client initialized
2025-12-11 12:42:31,007 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 12:42:31,007 - main - INFO - Feedback collector initialized
2025-12-11 12:42:31,007 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 12:42:31,007 - main - INFO - Pipeline deployer initialized
2025-12-11 12:42:31,007 - api_server - INFO - Pipeline initialized successfully
2025-12-11 12:48:38,748 - api_server - INFO - Processing uploaded file: ID_0b27bd5c2.dcm
2025-12-11 12:48:38,749 - main - INFO - Processing medical image: data/uploads/ID_0b27bd5c2.dcm
2025-12-11 12:48:38,749 - main - INFO - Step 1: Performing segmentation...
2025-12-11 12:48:38,749 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0b27bd5c2.dcm
2025-12-11 12:48:38,758 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 12:48:38,759 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 12:48:38,759 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0b27bd5c2.dcm: Use fallback preprocessing for DICOM
2025-12-11 12:48:38,759 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 12:48:38,763 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 12:48:38,763 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 12:48:43,616 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0b27bd5c2_mask.nii.gz
2025-12-11 12:48:43,630 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 12:48:43,671 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0b27bd5c2.dcm
2025-12-11 12:48:43,672 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 12:48:43,673 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 12:48:43,673 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 12:48:43,674 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 12:48:43,674 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 12:48:48,994 - main - INFO - Step 5: Generating medical report...
2025-12-11 12:48:48,995 - main - INFO - Pipeline processing completed successfully
2025-12-11 12:49:27,357 - api_server - INFO - Shutting down API server...
2025-12-11 13:49:49,559 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 13:49:49,581 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 13:49:49,600 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 13:49:49,624 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 13:49:49,640 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 13:49:49,659 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 13:49:49,659 - main - INFO - MedTech Pipeline initialized
2025-12-11 13:49:49,659 - main - INFO - Initializing pipeline components...
2025-12-11 13:49:50,735 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 13:49:50,736 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 13:49:50,736 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 13:49:50,736 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 13:49:50,736 - main - INFO - Segmentation pipeline initialized
2025-12-11 13:49:50,736 - vector_store - INFO - Loaded metadata with 10 records
2025-12-11 13:49:50,737 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 13:49:50,737 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 13:49:50,737 - main - INFO - Vector store initialized
2025-12-11 13:49:50,737 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 13:49:50,738 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 13:49:50,738 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 13:49:50,738 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 13:49:50,738 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 13:49:50,738 - main - INFO - Medical LLM initialized
2025-12-11 13:49:50,739 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 13:49:50,739 - main - INFO - MCP-FHIR client initialized
2025-12-11 13:49:50,739 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 13:49:50,739 - main - INFO - Feedback collector initialized
2025-12-11 13:49:50,739 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 13:49:50,740 - main - INFO - Pipeline deployer initialized
2025-12-11 13:49:50,740 - api_server - INFO - Pipeline initialized successfully
2025-12-11 13:50:22,297 - api_server - INFO - Processing uploaded file: ID_1e316385c.dcm
2025-12-11 13:50:22,298 - main - INFO - Processing medical image: data/uploads/ID_1e316385c.dcm
2025-12-11 13:50:22,298 - main - INFO - Step 1: Performing segmentation...
2025-12-11 13:50:22,298 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_1e316385c.dcm
2025-12-11 13:50:22,333 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 13:50:22,333 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 13:50:22,334 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_1e316385c.dcm: Use fallback preprocessing for DICOM
2025-12-11 13:50:22,334 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 13:50:22,347 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 13:50:22,348 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 13:50:30,258 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_1e316385c_mask.nii.gz
2025-12-11 13:50:30,317 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 13:50:30,401 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_1e316385c.dcm
2025-12-11 13:50:30,402 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 13:50:30,405 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 13:50:30,406 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 13:50:30,406 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 13:50:30,406 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 13:50:36,355 - main - INFO - Step 5: Generating medical report...
2025-12-11 13:50:36,356 - main - INFO - Pipeline processing completed successfully
2025-12-11 13:51:17,074 - llm.medical_llm - ERROR - Inference API streaming error: StopIteration()
2025-12-11 13:51:17,075 - llm.medical_llm - WARNING - Falling back to local model if available...
2025-12-11 13:51:17,075 - llm.medical_llm - WARNING - Models unavailable, serving simulated stream.
2025-12-11 13:51:38,887 - llm.medical_llm - ERROR - Inference API streaming error: StopIteration()
2025-12-11 13:51:38,887 - llm.medical_llm - WARNING - Falling back to local model if available...
2025-12-11 13:51:38,887 - llm.medical_llm - WARNING - Models unavailable, serving simulated stream.
2025-12-11 13:52:38,411 - api_server - INFO - Shutting down API server...
2025-12-11 13:52:52,913 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 13:52:52,922 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 13:52:52,929 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 13:52:52,941 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 13:52:52,953 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 13:52:52,972 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 13:52:52,972 - main - INFO - MedTech Pipeline initialized
2025-12-11 13:52:52,972 - main - INFO - Initializing pipeline components...
2025-12-11 13:52:53,673 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 13:52:53,673 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 13:52:53,673 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 13:52:53,673 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 13:52:53,674 - main - INFO - Segmentation pipeline initialized
2025-12-11 13:52:53,674 - vector_store - INFO - Loaded metadata with 11 records
2025-12-11 13:52:53,674 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 13:52:53,674 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 13:52:53,675 - main - INFO - Vector store initialized
2025-12-11 13:52:53,675 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 13:52:53,675 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 13:52:53,675 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 13:52:53,675 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 13:52:53,675 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 13:52:53,675 - main - INFO - Medical LLM initialized
2025-12-11 13:52:53,676 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 13:52:53,676 - main - INFO - MCP-FHIR client initialized
2025-12-11 13:52:53,676 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 13:52:53,676 - main - INFO - Feedback collector initialized
2025-12-11 13:52:53,676 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 13:52:53,676 - main - INFO - Pipeline deployer initialized
2025-12-11 13:52:53,676 - api_server - INFO - Pipeline initialized successfully
2025-12-11 13:53:39,651 - api_server - INFO - Processing uploaded file: ID_2d34ad929.dcm
2025-12-11 13:53:39,652 - main - INFO - Processing medical image: data/uploads/ID_2d34ad929.dcm
2025-12-11 13:53:39,652 - main - INFO - Step 1: Performing segmentation...
2025-12-11 13:53:39,653 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_2d34ad929.dcm
2025-12-11 13:53:39,686 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 13:53:39,687 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 13:53:39,688 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_2d34ad929.dcm: Use fallback preprocessing for DICOM
2025-12-11 13:53:39,688 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 13:53:39,706 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 13:53:39,707 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 13:53:47,503 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_2d34ad929_mask.nii.gz
2025-12-11 13:53:47,545 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 13:53:47,628 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_2d34ad929.dcm
2025-12-11 13:53:47,629 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 13:53:47,631 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 13:53:47,631 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 13:53:47,632 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 13:53:47,632 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 13:53:52,335 - main - INFO - Step 5: Generating medical report...
2025-12-11 13:53:52,336 - main - INFO - Pipeline processing completed successfully
2025-12-11 13:55:05,192 - llm.medical_llm - ERROR - Inference API error: StopIteration()
2025-12-11 13:55:05,192 - llm.medical_llm - WARNING - Falling back to local model if available...
2025-12-11 13:55:05,193 - llm.medical_llm - WARNING - Models unavailable, serving simulated stream.
2025-12-11 13:58:27,208 - api_server - INFO - Shutting down API server...
2025-12-11 13:58:41,928 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 13:58:41,941 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 13:58:41,950 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 13:58:41,966 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 13:58:41,979 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 13:58:42,003 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 13:58:42,003 - main - INFO - MedTech Pipeline initialized
2025-12-11 13:58:42,003 - main - INFO - Initializing pipeline components...
2025-12-11 13:58:42,807 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 13:58:42,807 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 13:58:42,807 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 13:58:42,808 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 13:58:42,808 - main - INFO - Segmentation pipeline initialized
2025-12-11 13:58:42,808 - vector_store - INFO - Loaded metadata with 12 records
2025-12-11 13:58:42,808 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 13:58:42,808 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 13:58:42,809 - main - INFO - Vector store initialized
2025-12-11 13:58:42,809 - llm.medical_llm - INFO - Configuration: use_inference_api=True, model_type=biomistral
2025-12-11 13:58:42,809 - llm.medical_llm - INFO - [OK] HuggingFace token found (length: 37, starts with: hf_MZYA...)
2025-12-11 13:58:42,809 - llm.medical_llm - INFO - Inference API client initialized for model: BioMistral/BioMistral-7B
2025-12-11 13:58:42,809 - llm.medical_llm - INFO - Using remote inference - no local model download required
2025-12-11 13:58:42,809 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Inference API)
2025-12-11 13:58:42,809 - main - INFO - Medical LLM initialized
2025-12-11 13:58:42,810 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 13:58:42,810 - main - INFO - MCP-FHIR client initialized
2025-12-11 13:58:42,810 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 13:58:42,810 - main - INFO - Feedback collector initialized
2025-12-11 13:58:42,810 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 13:58:42,810 - main - INFO - Pipeline deployer initialized
2025-12-11 13:58:42,810 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:02:07,699 - api_server - INFO - Shutting down API server...
2025-12-11 14:02:36,476 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:02:36,489 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:02:36,500 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:02:36,516 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:02:36,533 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:02:36,558 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:02:36,558 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:02:36,558 - main - INFO - Initializing pipeline components...
2025-12-11 14:02:37,542 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:02:37,542 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:02:37,542 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:02:37,543 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:02:37,543 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:02:37,544 - vector_store - INFO - Loaded metadata with 12 records
2025-12-11 14:02:37,544 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:02:37,544 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:02:37,544 - main - INFO - Vector store initialized
2025-12-11 14:02:37,545 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biomistral
2025-12-11 14:02:37,545 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: BioMistral/BioMistral-7B
2025-12-11 14:02:38,121 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BioMistral/BioMistral-7B/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:02:38,176 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BioMistral/BioMistral-7B/9a11e1ffa817c211cbb52ee1fb312dc6b61b40a5/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:02:38,280 - llm.medical_llm - INFO - Using BitsAndBytesConfig for 4-bit quantization
2025-12-11 14:02:38,535 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BioMistral/BioMistral-7B/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:02:38,584 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BioMistral/BioMistral-7B/9a11e1ffa817c211cbb52ee1fb312dc6b61b40a5/config.json "HTTP/1.1 200 OK"
2025-12-11 14:02:38,653 - llm.medical_llm - ERROR - Failed to initialize model: Can't load the model for 'BioMistral/BioMistral-7B'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'BioMistral/BioMistral-7B' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.
2025-12-11 14:02:38,653 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-11 14:02:38,663 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Local)
2025-12-11 14:02:38,663 - main - INFO - Medical LLM initialized
2025-12-11 14:02:38,664 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:02:38,664 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:02:38,664 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:02:38,664 - main - INFO - Feedback collector initialized
2025-12-11 14:02:38,664 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:02:38,665 - main - INFO - Pipeline deployer initialized
2025-12-11 14:02:38,665 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:02:44,231 - api_server - INFO - Shutting down API server...
2025-12-11 14:03:46,339 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:03:46,349 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:03:46,356 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:03:46,367 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:03:46,378 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:03:46,396 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:03:46,397 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:03:46,397 - main - INFO - Initializing pipeline components...
2025-12-11 14:03:47,081 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:03:47,081 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:03:47,081 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:03:47,082 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:03:47,082 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:03:47,082 - vector_store - INFO - Loaded metadata with 12 records
2025-12-11 14:03:47,083 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:03:47,083 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:03:47,083 - main - INFO - Vector store initialized
2025-12-11 14:03:47,083 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biomistral
2025-12-11 14:03:47,083 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: microsoft/BioGPT
2025-12-11 14:03:46,172 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/BioGPT/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:46,398 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/biogpt/resolve/main/tokenizer_config.json "HTTP/1.1 404 Not Found"
2025-12-11 14:03:47,072 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/BioGPT/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:47,390 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/biogpt/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:47,645 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/microsoft/biogpt/eb0d815e95434dc9e3b78f464e52b899bee7d923/config.json "HTTP/1.1 200 OK"
2025-12-11 14:03:48,125 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/microsoft/biogpt/eb0d815e95434dc9e3b78f464e52b899bee7d923/config.json "HTTP/1.1 200 OK"
2025-12-11 14:03:48,393 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/BioGPT/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:48,650 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/biogpt/resolve/main/tokenizer_config.json "HTTP/1.1 404 Not Found"
2025-12-11 14:03:48,902 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/BioGPT/resolve/main/vocab.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:49,125 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/biogpt/resolve/main/vocab.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:49,369 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/microsoft/biogpt/eb0d815e95434dc9e3b78f464e52b899bee7d923/vocab.json "HTTP/1.1 200 OK"
2025-12-11 14:03:49,775 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/microsoft/biogpt/eb0d815e95434dc9e3b78f464e52b899bee7d923/vocab.json "HTTP/1.1 200 OK"
2025-12-11 14:03:50,408 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/BioGPT/resolve/main/merges.txt "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:50,807 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/biogpt/resolve/main/merges.txt "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:51,315 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/microsoft/biogpt/eb0d815e95434dc9e3b78f464e52b899bee7d923/merges.txt "HTTP/1.1 200 OK"
2025-12-11 14:03:51,623 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/microsoft/biogpt/eb0d815e95434dc9e3b78f464e52b899bee7d923/merges.txt "HTTP/1.1 200 OK"
2025-12-11 14:03:52,031 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/BioGPT/resolve/main/added_tokens.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:52,295 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/biogpt/resolve/main/added_tokens.json "HTTP/1.1 404 Not Found"
2025-12-11 14:03:52,545 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/BioGPT/resolve/main/special_tokens_map.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:52,955 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/biogpt/resolve/main/special_tokens_map.json "HTTP/1.1 404 Not Found"
2025-12-11 14:03:53,264 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/BioGPT/resolve/main/tokenizer.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:54,082 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/biogpt/resolve/main/tokenizer.json "HTTP/1.1 404 Not Found"
2025-12-11 14:03:54,474 - llm.medical_llm - INFO - Using BitsAndBytesConfig for 4-bit quantization
2025-12-11 14:03:54,742 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/BioGPT/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:55,005 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/biogpt/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:55,035 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/microsoft/biogpt/eb0d815e95434dc9e3b78f464e52b899bee7d923/config.json "HTTP/1.1 200 OK"
2025-12-11 14:03:55,311 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/BioGPT/resolve/main/model.safetensors "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:55,620 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/biogpt/resolve/main/model.safetensors "HTTP/1.1 404 Not Found"
2025-12-11 14:03:55,869 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/BioGPT/resolve/main/model.safetensors.index.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:56,133 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/biogpt/resolve/main/model.safetensors.index.json "HTTP/1.1 404 Not Found"
2025-12-11 14:03:56,562 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/BioGPT/resolve/main/pytorch_model.bin "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:03:57,002 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/microsoft/biogpt/resolve/main/pytorch_model.bin "HTTP/1.1 302 Found"
2025-12-11 14:03:57,284 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/microsoft/biogpt/xet-read-token/eb0d815e95434dc9e3b78f464e52b899bee7d923 "HTTP/1.1 200 OK"
2025-12-11 14:04:22,982 - llm.medical_llm - ERROR - Failed to initialize model: Can't load the model for 'microsoft/BioGPT'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'microsoft/BioGPT' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.
2025-12-11 14:04:22,982 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-11 14:04:22,989 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Local)
2025-12-11 14:04:22,989 - main - INFO - Medical LLM initialized
2025-12-11 14:04:22,990 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:04:22,990 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:04:22,991 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:04:22,991 - main - INFO - Feedback collector initialized
2025-12-11 14:04:22,991 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:04:22,991 - main - INFO - Pipeline deployer initialized
2025-12-11 14:04:22,992 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:05:16,844 - api_server - INFO - Shutting down API server...
2025-12-11 14:05:42,444 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:05:42,455 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:05:42,466 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:05:42,478 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:05:42,490 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:05:42,508 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:05:42,509 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:05:42,509 - main - INFO - Initializing pipeline components...
2025-12-11 14:05:43,758 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:05:43,759 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:05:43,759 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:05:43,760 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:05:43,760 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:05:43,762 - vector_store - INFO - Loaded metadata with 12 records
2025-12-11 14:05:43,762 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:05:43,762 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:05:43,763 - main - INFO - Vector store initialized
2025-12-11 14:05:43,763 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biomistral
2025-12-11 14:05:43,763 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: google/flan-t5-large
2025-12-11 14:05:44,192 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/flan-t5-large/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:05:44,488 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/flan-t5-large/0613663d0d48ea86ba8cb3d7a44f0f65dc596a2a/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:05:44,763 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/google/flan-t5-large/0613663d0d48ea86ba8cb3d7a44f0f65dc596a2a/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:05:45,035 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/flan-t5-large/resolve/main/spiece.model "HTTP/1.1 302 Found"
2025-12-11 14:05:45,310 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/google/flan-t5-large/xet-read-token/0613663d0d48ea86ba8cb3d7a44f0f65dc596a2a "HTTP/1.1 200 OK"
2025-12-11 14:05:47,492 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/flan-t5-large/resolve/main/tokenizer.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:05:47,722 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/flan-t5-large/0613663d0d48ea86ba8cb3d7a44f0f65dc596a2a/tokenizer.json "HTTP/1.1 200 OK"
2025-12-11 14:05:47,961 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/google/flan-t5-large/0613663d0d48ea86ba8cb3d7a44f0f65dc596a2a/tokenizer.json "HTTP/1.1 200 OK"
2025-12-11 14:05:48,340 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/flan-t5-large/resolve/main/added_tokens.json "HTTP/1.1 404 Not Found"
2025-12-11 14:05:48,606 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/flan-t5-large/resolve/main/special_tokens_map.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:05:48,876 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/flan-t5-large/0613663d0d48ea86ba8cb3d7a44f0f65dc596a2a/special_tokens_map.json "HTTP/1.1 200 OK"
2025-12-11 14:05:49,184 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/google/flan-t5-large/0613663d0d48ea86ba8cb3d7a44f0f65dc596a2a/special_tokens_map.json "HTTP/1.1 200 OK"
2025-12-11 14:05:49,402 - llm.medical_llm - INFO - Using BitsAndBytesConfig for 4-bit quantization
2025-12-11 14:05:49,776 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/flan-t5-large/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:05:50,003 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/google/flan-t5-large/0613663d0d48ea86ba8cb3d7a44f0f65dc596a2a/config.json "HTTP/1.1 200 OK"
2025-12-11 14:05:50,300 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/resolve-cache/models/google/flan-t5-large/0613663d0d48ea86ba8cb3d7a44f0f65dc596a2a/config.json "HTTP/1.1 200 OK"
2025-12-11 14:05:50,351 - llm.medical_llm - ERROR - Failed to initialize model: Unrecognized configuration class <class 'transformers.models.t5.configuration_t5.T5Config'> for this kind of AutoModel: AutoModelForCausalLM.
Model type should be one of BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, CamembertConfig, LlamaConfig, CodeGenConfig, CohereConfig, CpmAntConfig, CTRLConfig, Data2VecTextConfig, DbrxConfig, ElectraConfig, ErnieConfig, FalconConfig, FalconMambaConfig, FuyuConfig, GemmaConfig, Gemma2Config, GitConfig, GlmConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, GraniteConfig, GraniteMoeConfig, JambaConfig, JetMoeConfig, LlamaConfig, MambaConfig, Mamba2Config, MarianConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig, MllamaConfig, MoshiConfig, MptConfig, MusicgenConfig, MusicgenMelodyConfig, MvpConfig, NemotronConfig, OlmoConfig, OlmoeConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PersimmonConfig, PhiConfig, Phi3Config, PhimoeConfig, PLBartConfig, ProphetNetConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, RecurrentGemmaConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, RwkvConfig, Speech2Text2Config, StableLmConfig, Starcoder2Config, TransfoXLConfig, TrOCRConfig, WhisperConfig, XGLMConfig, XLMConfig, XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, ZambaConfig.
2025-12-11 14:05:50,351 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-11 14:05:50,375 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Local)
2025-12-11 14:05:50,375 - main - INFO - Medical LLM initialized
2025-12-11 14:05:50,376 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:05:50,376 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:05:50,376 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:05:50,376 - main - INFO - Feedback collector initialized
2025-12-11 14:05:50,377 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:05:50,377 - main - INFO - Pipeline deployer initialized
2025-12-11 14:05:50,377 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:06:49,382 - api_server - INFO - Shutting down API server...
2025-12-11 14:07:09,732 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:07:09,743 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:07:09,751 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:07:09,764 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:07:09,776 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:07:09,795 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:07:09,795 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:07:09,795 - main - INFO - Initializing pipeline components...
2025-12-11 14:07:10,502 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:07:10,503 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:07:10,503 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:07:10,503 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:07:10,503 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:07:10,505 - vector_store - INFO - Loaded metadata with 12 records
2025-12-11 14:07:10,505 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:07:10,506 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:07:10,506 - main - INFO - Vector store initialized
2025-12-11 14:07:10,506 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biomistral
2025-12-11 14:07:10,506 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: BioMistral/BioMistral-7B
2025-12-11 14:07:10,970 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BioMistral/BioMistral-7B/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:07:10,996 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BioMistral/BioMistral-7B/9a11e1ffa817c211cbb52ee1fb312dc6b61b40a5/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:07:11,097 - llm.medical_llm - INFO - Using BitsAndBytesConfig for 4-bit quantization
2025-12-11 14:07:11,386 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BioMistral/BioMistral-7B/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2025-12-11 14:07:11,399 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BioMistral/BioMistral-7B/9a11e1ffa817c211cbb52ee1fb312dc6b61b40a5/config.json "HTTP/1.1 200 OK"
2025-12-11 14:07:11,443 - llm.medical_llm - ERROR - Failed to initialize model: Can't load the model for 'BioMistral/BioMistral-7B'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'BioMistral/BioMistral-7B' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.
2025-12-11 14:07:11,444 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-11 14:07:11,452 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Local)
2025-12-11 14:07:11,453 - main - INFO - Medical LLM initialized
2025-12-11 14:07:11,453 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:07:11,453 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:07:11,454 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:07:11,454 - main - INFO - Feedback collector initialized
2025-12-11 14:07:11,454 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:07:11,455 - main - INFO - Pipeline deployer initialized
2025-12-11 14:07:11,455 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:08:20,937 - api_server - INFO - Shutting down API server...
2025-12-11 14:08:30,697 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:08:30,704 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:08:30,710 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:08:30,717 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:08:30,724 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:08:30,734 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:08:30,734 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:08:30,734 - main - INFO - Initializing pipeline components...
2025-12-11 14:08:31,038 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:08:31,038 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:08:31,038 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:08:31,038 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:08:31,038 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:08:31,038 - vector_store - INFO - Loaded metadata with 12 records
2025-12-11 14:08:31,039 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:08:31,039 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:08:31,039 - main - INFO - Vector store initialized
2025-12-11 14:08:31,039 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=gpt2
2025-12-11 14:08:31,039 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: gpt2-medium
2025-12-11 14:08:31,399 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:08:31,658 - httpx - INFO - HTTP Request: GET https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:08:31,894 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-11 14:08:32,150 - httpx - INFO - HTTP Request: GET https://huggingface.co/gpt2-medium/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-11 14:08:32,412 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/vocab.json "HTTP/1.1 200 OK"
2025-12-11 14:08:32,699 - httpx - INFO - HTTP Request: GET https://huggingface.co/gpt2-medium/resolve/main/vocab.json "HTTP/1.1 200 OK"
2025-12-11 14:08:33,603 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/merges.txt "HTTP/1.1 200 OK"
2025-12-11 14:08:33,870 - httpx - INFO - HTTP Request: GET https://huggingface.co/gpt2-medium/resolve/main/merges.txt "HTTP/1.1 200 OK"
2025-12-11 14:08:34,173 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/tokenizer.json "HTTP/1.1 200 OK"
2025-12-11 14:08:34,446 - httpx - INFO - HTTP Request: GET https://huggingface.co/gpt2-medium/resolve/main/tokenizer.json "HTTP/1.1 200 OK"
2025-12-11 14:08:35,515 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/added_tokens.json "HTTP/1.1 404 Not Found"
2025-12-11 14:08:35,802 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/special_tokens_map.json "HTTP/1.1 404 Not Found"
2025-12-11 14:08:36,216 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-11 14:08:36,643 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/model.safetensors "HTTP/1.1 302 Found"
2025-12-11 14:08:36,874 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/openai-community/gpt2-medium/xet-read-token/6dcaa7a952f72f9298047fd5137cd6e4f05f41da "HTTP/1.1 200 OK"
2025-12-11 14:10:23,422 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-11 14:10:24,617 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/generation_config.json "HTTP/1.1 200 OK"
2025-12-11 14:10:24,865 - httpx - INFO - HTTP Request: GET https://huggingface.co/gpt2-medium/resolve/main/generation_config.json "HTTP/1.1 200 OK"
2025-12-11 14:10:24,899 - llm.medical_llm - INFO - Medical LLM initialized: gpt2 (mode: Local)
2025-12-11 14:10:24,900 - main - INFO - Medical LLM initialized
2025-12-11 14:10:24,900 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:10:24,900 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:10:24,900 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:10:24,900 - main - INFO - Feedback collector initialized
2025-12-11 14:10:24,900 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:10:24,900 - main - INFO - Pipeline deployer initialized
2025-12-11 14:10:24,901 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:12:50,363 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:12:50,368 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:12:50,372 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:12:50,379 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:12:50,385 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:12:50,395 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:12:50,395 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:12:50,395 - main - INFO - Initializing pipeline components...
2025-12-11 14:12:50,938 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:12:50,939 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:12:50,939 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:12:50,939 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:12:50,939 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:12:50,939 - vector_store - INFO - Loaded metadata with 12 records
2025-12-11 14:12:50,939 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:12:50,939 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:12:50,939 - main - INFO - Vector store initialized
2025-12-11 14:12:50,939 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=gpt2
2025-12-11 14:12:50,939 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: gpt2-medium
2025-12-11 14:12:51,310 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:12:51,718 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-11 14:12:51,868 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-11 14:12:53,372 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/generation_config.json "HTTP/1.1 200 OK"
2025-12-11 14:12:53,393 - llm.medical_llm - INFO - Medical LLM initialized: gpt2 (mode: Local)
2025-12-11 14:12:53,393 - main - INFO - Medical LLM initialized
2025-12-11 14:12:53,394 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:12:53,394 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:12:53,394 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:12:53,394 - main - INFO - Feedback collector initialized
2025-12-11 14:12:53,394 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:12:53,394 - main - INFO - Pipeline deployer initialized
2025-12-11 14:12:53,394 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:13:27,578 - api_server - INFO - Processing uploaded file: ID_0ab3c2234.dcm
2025-12-11 14:13:27,578 - main - INFO - Processing medical image: data/uploads/ID_0ab3c2234.dcm
2025-12-11 14:13:27,578 - main - INFO - Step 1: Performing segmentation...
2025-12-11 14:13:27,579 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0ab3c2234.dcm
2025-12-11 14:13:27,587 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:13:27,587 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:13:27,588 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0ab3c2234.dcm: Use fallback preprocessing for DICOM
2025-12-11 14:13:27,588 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:13:27,594 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:13:27,594 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:13:36,846 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0ab3c2234_mask.nii.gz
2025-12-11 14:13:36,877 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 14:13:36,913 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0ab3c2234.dcm
2025-12-11 14:13:36,913 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 14:13:36,914 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 14:13:36,914 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 14:13:36,914 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 14:13:36,914 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 14:13:41,140 - main - INFO - Step 5: Generating medical report...
2025-12-11 14:13:41,141 - llm.medical_llm - ERROR - Failed to generate report: local variable 'gen_config' referenced before assignment
2025-12-11 14:13:41,141 - main - INFO - Pipeline processing completed successfully
2025-12-11 14:14:03,442 - api_server - ERROR - Streaming error: local variable 'gen_config' referenced before assignment
2025-12-11 14:15:25,458 - api_server - INFO - Shutting down API server...
2025-12-11 14:15:40,472 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:15:40,483 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:15:40,491 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:15:40,505 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:15:40,521 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:15:40,543 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:15:40,543 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:15:40,543 - main - INFO - Initializing pipeline components...
2025-12-11 14:15:41,235 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:15:41,235 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:15:41,236 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:15:41,237 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:15:41,237 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:15:41,238 - vector_store - INFO - Loaded metadata with 13 records
2025-12-11 14:15:41,239 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:15:41,240 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:15:41,240 - main - INFO - Vector store initialized
2025-12-11 14:15:41,241 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=gpt2
2025-12-11 14:15:41,241 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: gpt2-medium
2025-12-11 14:15:41,680 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:15:42,229 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-11 14:15:42,361 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-11 14:15:43,414 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/generation_config.json "HTTP/1.1 200 OK"
2025-12-11 14:15:43,463 - llm.medical_llm - INFO - Medical LLM initialized: gpt2 (mode: Local)
2025-12-11 14:15:43,463 - main - INFO - Medical LLM initialized
2025-12-11 14:15:43,464 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:15:43,464 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:15:43,465 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:15:43,465 - main - INFO - Feedback collector initialized
2025-12-11 14:15:43,465 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:15:43,465 - main - INFO - Pipeline deployer initialized
2025-12-11 14:15:43,465 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:16:24,204 - api_server - INFO - Processing uploaded file: ID_0b27bd5c2.dcm
2025-12-11 14:16:24,204 - main - INFO - Processing medical image: data/uploads/ID_0b27bd5c2.dcm
2025-12-11 14:16:24,204 - main - INFO - Step 1: Performing segmentation...
2025-12-11 14:16:24,205 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0b27bd5c2.dcm
2025-12-11 14:16:24,212 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:16:24,213 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:16:24,213 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0b27bd5c2.dcm: Use fallback preprocessing for DICOM
2025-12-11 14:16:24,213 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:16:24,217 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:16:24,217 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:16:31,725 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0b27bd5c2_mask.nii.gz
2025-12-11 14:16:31,751 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 14:16:31,790 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0b27bd5c2.dcm
2025-12-11 14:16:31,790 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 14:16:31,791 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 14:16:31,791 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 14:16:31,792 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 14:16:31,792 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 14:16:37,343 - main - INFO - Step 5: Generating medical report...
2025-12-11 14:16:37,344 - llm.medical_llm - ERROR - Failed to generate report: local variable 'gen_config' referenced before assignment
2025-12-11 14:16:37,345 - main - INFO - Pipeline processing completed successfully
2025-12-11 14:18:21,539 - api_server - INFO - Shutting down API server...
2025-12-11 14:18:29,469 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:18:29,476 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:18:29,481 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:18:29,489 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:18:29,496 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:18:29,506 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:18:29,506 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:18:29,506 - main - INFO - Initializing pipeline components...
2025-12-11 14:18:29,860 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:18:29,861 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:18:29,861 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:18:29,861 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:18:29,861 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:18:29,861 - vector_store - INFO - Loaded metadata with 14 records
2025-12-11 14:18:29,861 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:18:29,861 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:18:29,861 - main - INFO - Vector store initialized
2025-12-11 14:18:29,861 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=gpt2
2025-12-11 14:18:29,861 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: gpt2-medium
2025-12-11 14:18:30,201 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:18:30,569 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-11 14:18:30,642 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-11 14:18:32,063 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/generation_config.json "HTTP/1.1 200 OK"
2025-12-11 14:18:32,088 - llm.medical_llm - INFO - Medical LLM initialized: gpt2 (mode: Local)
2025-12-11 14:18:32,088 - main - INFO - Medical LLM initialized
2025-12-11 14:18:32,088 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:18:32,088 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:18:32,089 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:18:32,089 - main - INFO - Feedback collector initialized
2025-12-11 14:18:32,089 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:18:32,089 - main - INFO - Pipeline deployer initialized
2025-12-11 14:18:32,089 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:20:26,571 - api_server - INFO - Processing uploaded file: ID_4fba288a2.dcm
2025-12-11 14:20:26,572 - main - INFO - Processing medical image: data/uploads/ID_4fba288a2.dcm
2025-12-11 14:20:26,572 - main - INFO - Step 1: Performing segmentation...
2025-12-11 14:20:26,572 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_4fba288a2.dcm
2025-12-11 14:20:26,582 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:20:26,582 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:20:26,582 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_4fba288a2.dcm: Use fallback preprocessing for DICOM
2025-12-11 14:20:26,582 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:20:26,588 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:20:26,588 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:20:33,846 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_4fba288a2_mask.nii.gz
2025-12-11 14:20:33,865 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 14:20:33,902 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_4fba288a2.dcm
2025-12-11 14:20:33,903 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 14:20:33,904 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 14:20:33,904 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 14:20:33,904 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 14:20:33,904 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 14:20:39,476 - main - INFO - Step 5: Generating medical report...
2025-12-11 14:20:39,476 - llm.medical_llm - ERROR - Failed to generate report: local variable 'gen_config' referenced before assignment
2025-12-11 14:20:39,476 - main - INFO - Pipeline processing completed successfully
2025-12-11 14:26:02,012 - api_server - INFO - Shutting down API server...
2025-12-11 14:26:39,800 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:26:39,806 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:26:39,810 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:26:39,817 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:26:39,823 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:26:39,833 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:26:39,834 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:26:39,834 - main - INFO - Initializing pipeline components...
2025-12-11 14:26:40,133 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:26:40,133 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:26:40,133 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:26:40,133 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:26:40,133 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:26:40,133 - vector_store - INFO - Loaded metadata with 15 records
2025-12-11 14:26:40,133 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:26:40,134 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:26:40,134 - main - INFO - Vector store initialized
2025-12-11 14:26:40,134 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=gpt2
2025-12-11 14:26:40,134 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: gpt2-medium
2025-12-11 14:26:40,480 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:26:40,833 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-11 14:26:40,966 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-11 14:26:42,378 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/generation_config.json "HTTP/1.1 200 OK"
2025-12-11 14:26:42,398 - llm.medical_llm - INFO - Medical LLM initialized: gpt2 (mode: Local)
2025-12-11 14:26:42,399 - main - INFO - Medical LLM initialized
2025-12-11 14:26:42,399 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:26:42,399 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:26:42,399 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:26:42,399 - main - INFO - Feedback collector initialized
2025-12-11 14:26:42,399 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:26:42,399 - main - INFO - Pipeline deployer initialized
2025-12-11 14:26:42,399 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:27:19,753 - api_server - INFO - Processing uploaded file: ID_3bc436100.dcm
2025-12-11 14:27:19,754 - main - INFO - Processing medical image: data/uploads/ID_3bc436100.dcm
2025-12-11 14:27:19,754 - main - INFO - Step 1: Performing segmentation...
2025-12-11 14:27:19,754 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_3bc436100.dcm
2025-12-11 14:27:19,772 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:27:19,773 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:27:19,773 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_3bc436100.dcm: Use fallback preprocessing for DICOM
2025-12-11 14:27:19,773 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:27:19,786 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:27:19,786 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:27:27,516 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_3bc436100_mask.nii.gz
2025-12-11 14:27:27,535 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 14:27:27,575 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_3bc436100.dcm
2025-12-11 14:27:27,575 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 14:27:27,576 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 14:27:27,576 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 14:27:27,577 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 14:27:27,577 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 14:27:33,007 - main - INFO - Step 5: Generating medical report...
2025-12-11 14:27:33,007 - llm.medical_llm - ERROR - Failed to generate report: local variable 'gen_config' referenced before assignment
2025-12-11 14:27:33,008 - main - INFO - Pipeline processing completed successfully
2025-12-11 14:28:51,014 - api_server - INFO - Shutting down API server...
2025-12-11 14:28:58,408 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:28:58,414 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:28:58,418 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:28:58,427 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:28:58,434 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:28:58,445 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:28:58,445 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:28:58,445 - main - INFO - Initializing pipeline components...
2025-12-11 14:28:58,733 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:28:58,733 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:28:58,733 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:28:58,733 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:28:58,734 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:28:58,734 - vector_store - INFO - Loaded metadata with 16 records
2025-12-11 14:28:58,734 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:28:58,734 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:28:58,734 - main - INFO - Vector store initialized
2025-12-11 14:28:58,734 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=gpt2
2025-12-11 14:28:58,734 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: gpt2-medium
2025-12-11 14:28:59,025 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:28:59,371 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-11 14:28:59,468 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-11 14:29:00,714 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/generation_config.json "HTTP/1.1 200 OK"
2025-12-11 14:29:00,734 - llm.medical_llm - INFO - Medical LLM initialized: gpt2 (mode: Local)
2025-12-11 14:29:00,734 - main - INFO - Medical LLM initialized
2025-12-11 14:29:00,734 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:29:00,735 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:29:00,735 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:29:00,735 - main - INFO - Feedback collector initialized
2025-12-11 14:29:00,735 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:29:00,735 - main - INFO - Pipeline deployer initialized
2025-12-11 14:29:00,735 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:29:32,947 - api_server - INFO - Processing uploaded file: ID_0ac3e69bc.dcm
2025-12-11 14:29:32,948 - main - INFO - Processing medical image: data/uploads/ID_0ac3e69bc.dcm
2025-12-11 14:29:32,948 - main - INFO - Step 1: Performing segmentation...
2025-12-11 14:29:32,948 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0ac3e69bc.dcm
2025-12-11 14:29:32,958 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:29:32,959 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:29:32,959 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0ac3e69bc.dcm: Use fallback preprocessing for DICOM
2025-12-11 14:29:32,959 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:29:32,964 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:29:32,964 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:29:38,981 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0ac3e69bc_mask.nii.gz
2025-12-11 14:29:38,997 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 14:29:39,030 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0ac3e69bc.dcm
2025-12-11 14:29:39,031 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 14:29:39,032 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 14:29:39,032 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 14:29:39,032 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 14:29:39,032 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 14:29:44,593 - main - INFO - Step 5: Generating medical report...
2025-12-11 14:29:48,676 - main - INFO - Pipeline processing completed successfully
2025-12-11 14:31:32,711 - api_server - INFO - Shutting down API server...
2025-12-11 14:31:40,202 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:31:40,208 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:31:40,211 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:31:40,218 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:31:40,225 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:31:40,235 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:31:40,236 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:31:40,236 - main - INFO - Initializing pipeline components...
2025-12-11 14:31:40,521 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:31:40,521 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:31:40,521 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:31:40,522 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:31:40,522 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:31:40,522 - vector_store - INFO - Loaded metadata with 17 records
2025-12-11 14:31:40,522 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:31:40,522 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:31:40,522 - main - INFO - Vector store initialized
2025-12-11 14:31:40,522 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=gpt2
2025-12-11 14:31:40,522 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: gpt2-medium
2025-12-11 14:31:40,946 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:31:41,274 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-11 14:31:41,473 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-11 14:31:41,189 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/generation_config.json "HTTP/1.1 200 OK"
2025-12-11 14:31:41,209 - llm.medical_llm - INFO - Medical LLM initialized: gpt2 (mode: Local)
2025-12-11 14:31:41,209 - main - INFO - Medical LLM initialized
2025-12-11 14:31:41,210 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:31:41,210 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:31:41,210 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:31:41,210 - main - INFO - Feedback collector initialized
2025-12-11 14:31:41,210 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:31:41,210 - main - INFO - Pipeline deployer initialized
2025-12-11 14:31:41,210 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:32:05,852 - api_server - INFO - Shutting down API server...
2025-12-11 14:32:43,623 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:32:43,628 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:32:43,632 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:32:43,638 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:32:43,644 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:32:43,654 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:32:43,654 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:32:43,654 - main - INFO - Initializing pipeline components...
2025-12-11 14:32:43,993 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:32:43,993 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:32:43,993 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:32:43,993 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:32:43,993 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:32:43,993 - vector_store - INFO - Loaded metadata with 17 records
2025-12-11 14:32:43,994 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:32:43,994 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:32:43,994 - main - INFO - Vector store initialized
2025-12-11 14:32:43,994 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=gpt2
2025-12-11 14:32:43,994 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: gpt2-medium
2025-12-11 14:32:44,337 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:32:44,705 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-11 14:32:44,808 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-11 14:32:45,831 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/generation_config.json "HTTP/1.1 200 OK"
2025-12-11 14:32:45,848 - llm.medical_llm - INFO - Medical LLM initialized: gpt2 (mode: Local)
2025-12-11 14:32:45,848 - main - INFO - Medical LLM initialized
2025-12-11 14:32:45,849 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:32:45,849 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:32:45,849 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:32:45,849 - main - INFO - Feedback collector initialized
2025-12-11 14:32:45,849 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:32:45,849 - main - INFO - Pipeline deployer initialized
2025-12-11 14:32:45,849 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:32:57,426 - llm.medical_llm - WARNING - Generated text too short: ''
2025-12-11 14:33:29,014 - api_server - INFO - Shutting down API server...
2025-12-11 14:33:36,429 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:33:36,435 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:33:36,439 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:33:36,445 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:33:36,451 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:33:36,462 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:33:36,462 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:33:36,462 - main - INFO - Initializing pipeline components...
2025-12-11 14:33:36,751 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:33:36,751 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:33:36,751 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:33:36,751 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:33:36,751 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:33:36,751 - vector_store - INFO - Loaded metadata with 17 records
2025-12-11 14:33:36,751 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:33:36,751 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:33:36,751 - main - INFO - Vector store initialized
2025-12-11 14:33:36,751 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=gpt2
2025-12-11 14:33:36,752 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: gpt2-medium
2025-12-11 14:33:37,166 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:33:37,536 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-11 14:33:37,605 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-11 14:33:38,671 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/generation_config.json "HTTP/1.1 200 OK"
2025-12-11 14:33:38,692 - llm.medical_llm - INFO - Medical LLM initialized: gpt2 (mode: Local)
2025-12-11 14:33:38,692 - main - INFO - Medical LLM initialized
2025-12-11 14:33:38,693 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:33:38,693 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:33:38,693 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:33:38,693 - main - INFO - Feedback collector initialized
2025-12-11 14:33:38,693 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:33:38,693 - main - INFO - Pipeline deployer initialized
2025-12-11 14:33:38,693 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:34:13,031 - api_server - INFO - Processing uploaded file: ID_0b0a1315d.dcm
2025-12-11 14:34:13,031 - main - INFO - Processing medical image: data/uploads/ID_0b0a1315d.dcm
2025-12-11 14:34:13,031 - main - INFO - Step 1: Performing segmentation...
2025-12-11 14:34:13,031 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0b0a1315d.dcm
2025-12-11 14:34:13,054 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:34:13,055 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:34:13,055 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0b0a1315d.dcm: Use fallback preprocessing for DICOM
2025-12-11 14:34:13,055 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:34:13,060 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:34:13,060 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:34:19,782 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0b0a1315d_mask.nii.gz
2025-12-11 14:34:19,812 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 14:34:19,863 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0b0a1315d.dcm
2025-12-11 14:34:19,863 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 14:34:19,864 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 14:34:19,865 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 14:34:19,865 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 14:34:19,865 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 14:34:25,120 - main - INFO - Step 5: Generating medical report...
2025-12-11 14:34:25,408 - main - INFO - Pipeline processing completed successfully
2025-12-11 14:37:46,494 - api_server - INFO - Processing uploaded file: ID_0b27bd5c2.dcm
2025-12-11 14:37:46,494 - main - INFO - Processing medical image: data/uploads/ID_0b27bd5c2.dcm
2025-12-11 14:37:46,494 - main - INFO - Step 1: Performing segmentation...
2025-12-11 14:37:46,494 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0b27bd5c2.dcm
2025-12-11 14:37:46,500 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:37:46,500 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:37:46,500 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0b27bd5c2.dcm: Use fallback preprocessing for DICOM
2025-12-11 14:37:46,500 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:37:46,504 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:37:46,505 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:37:50,130 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0b27bd5c2_mask.nii.gz
2025-12-11 14:37:52,479 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 14:37:52,516 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0b27bd5c2.dcm
2025-12-11 14:37:52,516 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 14:37:52,518 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 14:37:52,518 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 14:37:52,518 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 14:37:52,518 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 14:37:57,799 - main - INFO - Step 5: Generating medical report...
2025-12-11 14:38:03,670 - main - INFO - Pipeline processing completed successfully
2025-12-11 14:39:11,491 - api_server - INFO - Shutting down API server...
2025-12-11 14:39:18,999 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:39:19,005 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:39:19,009 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:39:19,015 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:39:19,021 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:39:19,032 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:39:19,032 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:39:19,032 - main - INFO - Initializing pipeline components...
2025-12-11 14:39:19,359 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:39:19,360 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:39:19,360 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:39:19,360 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:39:19,360 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:39:19,360 - vector_store - INFO - Loaded metadata with 19 records
2025-12-11 14:39:19,360 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:39:19,361 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:39:19,361 - main - INFO - Vector store initialized
2025-12-11 14:39:19,361 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=gpt2
2025-12-11 14:39:19,361 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: gpt2-medium
2025-12-11 14:39:19,684 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:39:20,035 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-11 14:39:20,099 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-11 14:39:21,264 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/generation_config.json "HTTP/1.1 200 OK"
2025-12-11 14:39:21,301 - llm.medical_llm - INFO - Medical LLM initialized: gpt2 (mode: Local)
2025-12-11 14:39:21,302 - main - INFO - Medical LLM initialized
2025-12-11 14:39:21,302 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:39:21,302 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:39:21,302 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:39:21,302 - main - INFO - Feedback collector initialized
2025-12-11 14:39:21,302 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:39:21,302 - main - INFO - Pipeline deployer initialized
2025-12-11 14:39:21,302 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:40:01,277 - api_server - INFO - Shutting down API server...
2025-12-11 14:41:24,733 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:41:24,738 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:41:24,741 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:41:24,748 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:41:24,755 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:41:24,765 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:41:24,766 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:41:24,766 - main - INFO - Initializing pipeline components...
2025-12-11 14:41:25,080 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:41:25,080 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:41:25,080 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:41:25,080 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:41:25,080 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:41:25,080 - vector_store - INFO - Loaded metadata with 19 records
2025-12-11 14:41:25,080 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:41:25,081 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:41:25,081 - main - INFO - Vector store initialized
2025-12-11 14:41:25,081 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=gpt2
2025-12-11 14:41:25,081 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: gpt2-medium
2025-12-11 14:41:25,364 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:41:25,739 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-11 14:41:25,861 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-11 14:41:26,870 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/generation_config.json "HTTP/1.1 200 OK"
2025-12-11 14:41:26,905 - llm.medical_llm - INFO - Medical LLM initialized: gpt2 (mode: Local)
2025-12-11 14:41:26,905 - main - INFO - Medical LLM initialized
2025-12-11 14:41:26,906 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:41:26,906 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:41:26,906 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:41:26,907 - main - INFO - Feedback collector initialized
2025-12-11 14:41:26,907 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:41:26,907 - main - INFO - Pipeline deployer initialized
2025-12-11 14:41:26,907 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:41:43,616 - llm.medical_llm - INFO - Started streaming generation thread
2025-12-11 14:41:44,322 - llm.medical_llm - INFO - Streaming completed, generated 4 tokens
2025-12-11 14:42:47,637 - api_server - INFO - Processing uploaded file: ID_0b7d6530c.dcm
2025-12-11 14:42:47,638 - main - INFO - Processing medical image: data/uploads/ID_0b7d6530c.dcm
2025-12-11 14:42:47,638 - main - INFO - Step 1: Performing segmentation...
2025-12-11 14:42:47,639 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0b7d6530c.dcm
2025-12-11 14:42:47,650 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:42:47,650 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:42:47,650 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0b7d6530c.dcm: Use fallback preprocessing for DICOM
2025-12-11 14:42:47,651 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:42:47,661 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:42:47,661 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:42:53,314 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0b7d6530c_mask.nii.gz
2025-12-11 14:42:53,333 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 14:42:53,375 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0b7d6530c.dcm
2025-12-11 14:42:53,375 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 14:42:53,376 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 14:42:53,376 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 14:42:53,376 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 14:42:53,377 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 14:43:02,316 - main - INFO - Step 5: Generating medical report...
2025-12-11 14:43:02,556 - llm.medical_llm - WARNING - Generated text too short: ''
2025-12-11 14:43:02,556 - main - INFO - Pipeline processing completed successfully
2025-12-11 14:43:12,689 - api_server - INFO - Shutting down API server...
2025-12-11 14:43:20,581 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-11 14:43:20,587 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-11 14:43:20,591 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-11 14:43:20,598 - main - INFO - Loaded config: llm_config.yaml
2025-12-11 14:43:20,604 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-11 14:43:20,614 - main - INFO - Loaded config: deployment_config.yaml
2025-12-11 14:43:20,615 - main - INFO - MedTech Pipeline initialized
2025-12-11 14:43:20,615 - main - INFO - Initializing pipeline components...
2025-12-11 14:43:20,936 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-11 14:43:20,936 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:43:20,936 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-11 14:43:20,936 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-11 14:43:20,936 - main - INFO - Segmentation pipeline initialized
2025-12-11 14:43:20,936 - vector_store - INFO - Loaded metadata with 20 records
2025-12-11 14:43:20,936 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-11 14:43:20,937 - vector_store - INFO - FAISS index loaded from disk
2025-12-11 14:43:20,937 - main - INFO - Vector store initialized
2025-12-11 14:43:20,937 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=gpt2
2025-12-11 14:43:20,937 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: gpt2-medium
2025-12-11 14:43:21,247 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-11 14:43:21,602 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-11 14:43:21,679 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-11 14:43:22,984 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/gpt2-medium/resolve/main/generation_config.json "HTTP/1.1 200 OK"
2025-12-11 14:43:23,003 - llm.medical_llm - INFO - Medical LLM initialized: gpt2 (mode: Local)
2025-12-11 14:43:23,003 - main - INFO - Medical LLM initialized
2025-12-11 14:43:23,003 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-11 14:43:23,004 - main - INFO - MCP-FHIR client initialized
2025-12-11 14:43:23,004 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-11 14:43:23,004 - main - INFO - Feedback collector initialized
2025-12-11 14:43:23,004 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-11 14:43:23,004 - main - INFO - Pipeline deployer initialized
2025-12-11 14:43:23,004 - api_server - INFO - Pipeline initialized successfully
2025-12-11 14:43:45,825 - llm.medical_llm - INFO - Prompt length: 37 characters
2025-12-11 14:43:45,837 - llm.medical_llm - INFO - Started streaming generation thread
2025-12-11 14:43:49,460 - llm.medical_llm - INFO - Streaming completed, generated 176 tokens: ' This form of respiratory disease, caused by bacteria called Streptococcus pyogenes (also known as strep throat), can be extremely difficult to treat. It has been estimated that one in five Americans '
2025-12-11 14:44:23,878 - api_server - INFO - Processing uploaded file: ID_0b2da875a.dcm
2025-12-11 14:44:23,879 - main - INFO - Processing medical image: data/uploads/ID_0b2da875a.dcm
2025-12-11 14:44:23,879 - main - INFO - Step 1: Performing segmentation...
2025-12-11 14:44:23,879 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0b2da875a.dcm
2025-12-11 14:44:23,893 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:44:23,893 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:44:23,893 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0b2da875a.dcm: Use fallback preprocessing for DICOM
2025-12-11 14:44:23,894 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:44:23,899 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:44:23,899 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:44:30,791 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0b2da875a_mask.nii.gz
2025-12-11 14:44:30,809 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 14:44:30,844 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0b2da875a.dcm
2025-12-11 14:44:30,845 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 14:44:30,847 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 14:44:30,847 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 14:44:30,847 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 14:44:30,847 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 14:44:34,717 - main - INFO - Step 5: Generating medical report...
2025-12-11 14:44:38,968 - main - INFO - Pipeline processing completed successfully
2025-12-11 14:44:53,931 - llm.medical_llm - INFO - Prompt length: 36 characters
2025-12-11 14:44:53,937 - llm.medical_llm - INFO - Started streaming generation thread
2025-12-11 14:44:58,920 - llm.medical_llm - INFO - Streaming completed, generated 257 tokens: ' This was a simple, but important step in the discovery process. While scanning and finding candidates it helps to have some experience with using Windows Explorer or other applications before attempt'
2025-12-11 14:45:05,775 - llm.medical_llm - INFO - Prompt length: 41 characters
2025-12-11 14:45:05,778 - llm.medical_llm - INFO - Started streaming generation thread
2025-12-11 14:45:09,533 - llm.medical_llm - INFO - Streaming completed, generated 185 tokens: ' In this case, I was surprised to discover that no information about how many animals were killed and whose organs they came from appeared in the report. While it's clear there are issues of transpare'
2025-12-11 14:46:24,406 - api_server - INFO - Processing uploaded file: ID_0ba83217f.dcm
2025-12-11 14:46:24,407 - main - INFO - Processing medical image: data/uploads/ID_0ba83217f.dcm
2025-12-11 14:46:24,408 - main - INFO - Step 1: Performing segmentation...
2025-12-11 14:46:24,408 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0ba83217f.dcm
2025-12-11 14:46:24,437 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:46:24,437 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:46:24,439 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0ba83217f.dcm: Use fallback preprocessing for DICOM
2025-12-11 14:46:24,439 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:46:24,455 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:46:24,456 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:46:31,561 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0ba83217f_mask.nii.gz
2025-12-11 14:46:34,486 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 14:46:34,545 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0ba83217f.dcm
2025-12-11 14:46:34,546 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 14:46:34,548 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 14:46:34,548 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 14:46:34,549 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 14:46:34,549 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 14:46:39,155 - main - INFO - Step 5: Generating medical report...
2025-12-11 14:46:39,307 - llm.medical_llm - WARNING - Generated text too short: ''
2025-12-11 14:46:39,309 - main - INFO - Pipeline processing completed successfully
2025-12-11 14:48:53,409 - api_server - INFO - Processing uploaded file: ID_0a4674064.dcm
2025-12-11 14:48:53,410 - main - INFO - Processing medical image: data/uploads/ID_0a4674064.dcm
2025-12-11 14:48:53,411 - main - INFO - Step 1: Performing segmentation...
2025-12-11 14:48:53,411 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0a4674064.dcm
2025-12-11 14:48:53,433 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:48:53,433 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:48:53,433 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0a4674064.dcm: Use fallback preprocessing for DICOM
2025-12-11 14:48:53,434 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:48:53,446 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:48:53,447 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:49:00,519 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0a4674064_mask.nii.gz
2025-12-11 14:49:04,411 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 14:49:04,565 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0a4674064.dcm
2025-12-11 14:49:04,567 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 14:49:04,570 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 14:49:04,571 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 14:49:04,571 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 14:49:04,572 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 14:49:10,242 - main - INFO - Step 5: Generating medical report...
2025-12-11 14:49:10,402 - llm.medical_llm - WARNING - Generated text too short: ''
2025-12-11 14:49:10,403 - main - INFO - Pipeline processing completed successfully
2025-12-11 14:54:33,206 - api_server - INFO - Processing uploaded file: ID_0ab3c2234.dcm
2025-12-11 14:54:33,207 - main - INFO - Processing medical image: data/uploads/ID_0ab3c2234.dcm
2025-12-11 14:54:33,207 - main - INFO - Step 1: Performing segmentation...
2025-12-11 14:54:33,207 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0ab3c2234.dcm
2025-12-11 14:54:33,227 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:54:33,228 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:54:33,228 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0ab3c2234.dcm: Use fallback preprocessing for DICOM
2025-12-11 14:54:33,229 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-11 14:54:33,247 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-11 14:54:33,248 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-11 14:54:37,813 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0ab3c2234_mask.nii.gz
2025-12-11 14:54:41,545 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-11 14:54:41,639 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0ab3c2234.dcm
2025-12-11 14:54:41,640 - main - INFO - Step 2: Indexing embeddings...
2025-12-11 14:54:41,644 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-11 14:54:41,645 - main - INFO - Step 3: Retrieving similar cases...
2025-12-11 14:54:41,645 - main - INFO - Step 4: Retrieving clinical context...
2025-12-11 14:54:41,645 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-11 14:54:47,017 - main - INFO - Step 5: Generating medical report...
2025-12-11 14:54:47,379 - main - INFO - Pipeline processing completed successfully
2025-12-11 15:00:54,675 - api_server - INFO - Shutting down API server...
2025-12-12 00:30:27,854 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 00:30:27,864 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 00:30:27,871 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 00:30:27,885 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 00:30:27,897 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 00:30:27,917 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 00:30:27,917 - main - INFO - MedTech Pipeline initialized
2025-12-12 00:30:27,918 - main - INFO - Initializing pipeline components...
2025-12-12 00:30:29,144 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 00:30:29,144 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 00:30:29,145 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 00:30:29,145 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 00:30:29,145 - main - INFO - Segmentation pipeline initialized
2025-12-12 00:30:29,146 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 00:30:29,146 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 00:30:29,151 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 00:30:29,152 - main - INFO - Vector store initialized
2025-12-12 00:30:29,152 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biomistral
2025-12-12 00:30:29,153 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: BioMistral/BioMistral-7B
2025-12-12 00:30:29,650 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BioMistral/BioMistral-7B/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2025-12-12 00:30:29,673 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BioMistral/BioMistral-7B/9a11e1ffa817c211cbb52ee1fb312dc6b61b40a5/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-12 00:30:29,805 - llm.medical_llm - INFO - Using BitsAndBytesConfig for 4-bit quantization
2025-12-12 00:30:30,065 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/BioMistral/BioMistral-7B/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2025-12-12 00:30:30,088 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/BioMistral/BioMistral-7B/9a11e1ffa817c211cbb52ee1fb312dc6b61b40a5/config.json "HTTP/1.1 200 OK"
2025-12-12 00:30:30,218 - llm.medical_llm - ERROR - Failed to initialize model: Can't load the model for 'BioMistral/BioMistral-7B'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'BioMistral/BioMistral-7B' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.
2025-12-12 00:30:30,218 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-12 00:30:30,225 - llm.medical_llm - INFO - Medical LLM initialized: biomistral (mode: Local)
2025-12-12 00:30:30,226 - main - INFO - Medical LLM initialized
2025-12-12 00:30:30,226 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 00:30:30,226 - main - INFO - MCP-FHIR client initialized
2025-12-12 00:30:30,226 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 00:30:30,226 - main - INFO - Feedback collector initialized
2025-12-12 00:30:30,226 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 00:30:30,226 - main - INFO - Pipeline deployer initialized
2025-12-12 00:30:30,227 - api_server - INFO - Pipeline initialized successfully
2025-12-12 00:30:53,338 - api_server - INFO - Shutting down API server...
2025-12-12 00:44:21,796 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 00:44:21,806 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 00:44:21,813 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 00:44:21,828 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 00:44:21,840 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 00:44:21,862 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 00:44:21,863 - main - INFO - MedTech Pipeline initialized
2025-12-12 00:44:21,863 - main - INFO - Initializing pipeline components...
2025-12-12 00:44:22,654 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 00:44:22,654 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 00:44:22,655 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 00:44:22,655 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 00:44:22,655 - main - INFO - Segmentation pipeline initialized
2025-12-12 00:44:22,656 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 00:44:22,656 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 00:44:22,657 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 00:44:22,657 - main - INFO - Vector store initialized
2025-12-12 00:44:22,657 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=medgemma
2025-12-12 00:44:22,657 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: google/medgemma-2b
2025-12-12 00:44:23,025 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/medgemma-2b/resolve/main/tokenizer_config.json "HTTP/1.1 404 Not Found"
2025-12-12 00:44:23,026 - llm.medical_llm - ERROR - Failed to initialize model: google/medgemma-2b is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-12-12 00:44:23,027 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-12 00:44:23,027 - llm.medical_llm - INFO - Medical LLM initialized: medgemma (mode: Local)
2025-12-12 00:44:23,027 - main - INFO - Medical LLM initialized
2025-12-12 00:44:23,027 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 00:44:23,028 - main - INFO - MCP-FHIR client initialized
2025-12-12 00:44:23,028 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 00:44:23,028 - main - INFO - Feedback collector initialized
2025-12-12 00:44:23,028 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 00:44:23,028 - main - INFO - Pipeline deployer initialized
2025-12-12 00:44:23,028 - api_server - INFO - Pipeline initialized successfully
2025-12-12 00:59:02,823 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 00:59:02,834 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 00:59:02,841 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 00:59:02,856 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 00:59:02,867 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 00:59:02,885 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 00:59:02,885 - main - INFO - MedTech Pipeline initialized
2025-12-12 00:59:02,885 - main - INFO - Initializing pipeline components...
2025-12-12 00:59:03,930 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 00:59:03,930 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 00:59:03,930 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 00:59:03,930 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 00:59:03,930 - main - INFO - Segmentation pipeline initialized
2025-12-12 00:59:03,931 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 00:59:03,931 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 00:59:03,936 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 00:59:03,936 - main - INFO - Vector store initialized
2025-12-12 00:59:03,936 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=medgemma
2025-12-12 00:59:03,936 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: google/medgemma-2b
2025-12-12 00:59:04,394 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/medgemma-2b/resolve/main/tokenizer_config.json "HTTP/1.1 404 Not Found"
2025-12-12 00:59:04,394 - llm.medical_llm - ERROR - Failed to initialize model: google/medgemma-2b is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-12-12 00:59:04,395 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-12 00:59:04,395 - llm.medical_llm - INFO - Medical LLM initialized: medgemma (mode: Local)
2025-12-12 00:59:04,395 - main - INFO - Medical LLM initialized
2025-12-12 00:59:04,395 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 00:59:04,395 - main - INFO - MCP-FHIR client initialized
2025-12-12 00:59:04,395 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 00:59:04,395 - main - INFO - Feedback collector initialized
2025-12-12 00:59:04,396 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 00:59:04,396 - main - INFO - Pipeline deployer initialized
2025-12-12 00:59:04,396 - api_server - INFO - Pipeline initialized successfully
2025-12-12 00:59:22,728 - llm.medical_llm - INFO - Prompt length: 61 characters
2025-12-12 01:00:00,658 - api_server - INFO - Shutting down API server...
2025-12-12 01:03:38,341 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 01:03:38,346 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 01:03:38,350 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 01:03:38,357 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 01:03:38,363 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 01:03:38,372 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 01:03:38,372 - main - INFO - MedTech Pipeline initialized
2025-12-12 01:03:38,372 - main - INFO - Initializing pipeline components...
2025-12-12 01:03:38,688 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 01:03:38,689 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:03:38,689 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 01:03:38,689 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 01:03:38,689 - main - INFO - Segmentation pipeline initialized
2025-12-12 01:03:38,689 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 01:03:38,689 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 01:03:38,689 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 01:03:38,689 - main - INFO - Vector store initialized
2025-12-12 01:03:38,689 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=medgemma
2025-12-12 01:03:38,689 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: google/medgemma-4b-it
2025-12-12 01:03:38,983 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/medgemma-4b-it/resolve/main/tokenizer_config.json "HTTP/1.1 403 Forbidden"
2025-12-12 01:03:39,209 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/medgemma-4b-it/resolve/main/config.json "HTTP/1.1 403 Forbidden"
2025-12-12 01:03:39,211 - llm.medical_llm - ERROR - Failed to initialize model: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/google/medgemma-4b-it.
403 Client Error. (Request ID: Root=1-693b1c92-18cc01b93c5ce7466a7d5136;c570a92f-49bd-4e4e-8d9f-751526adc575)

Cannot access gated repo for url https://huggingface.co/google/medgemma-4b-it/resolve/main/config.json.
Access to model google/medgemma-4b-it is restricted and you are not in the authorized list. Visit https://huggingface.co/google/medgemma-4b-it to ask for access.
2025-12-12 01:03:39,211 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-12 01:03:39,211 - llm.medical_llm - INFO - Medical LLM initialized: medgemma (mode: Local)
2025-12-12 01:03:39,211 - main - INFO - Medical LLM initialized
2025-12-12 01:03:39,211 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 01:03:39,212 - main - INFO - MCP-FHIR client initialized
2025-12-12 01:03:39,212 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 01:03:39,212 - main - INFO - Feedback collector initialized
2025-12-12 01:03:39,212 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 01:03:39,212 - main - INFO - Pipeline deployer initialized
2025-12-12 01:03:39,212 - api_server - INFO - Pipeline initialized successfully
2025-12-12 01:08:26,973 - api_server - INFO - Shutting down API server...
2025-12-12 01:08:41,095 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 01:08:41,101 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 01:08:41,105 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 01:08:41,112 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 01:08:41,118 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 01:08:41,128 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 01:08:41,128 - main - INFO - MedTech Pipeline initialized
2025-12-12 01:08:41,128 - main - INFO - Initializing pipeline components...
2025-12-12 01:08:41,371 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 01:08:41,371 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:08:41,371 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 01:08:41,371 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 01:08:41,372 - main - INFO - Segmentation pipeline initialized
2025-12-12 01:08:41,372 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 01:08:41,372 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 01:08:41,372 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 01:08:41,372 - main - INFO - Vector store initialized
2025-12-12 01:08:41,372 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=medgemma
2025-12-12 01:08:41,372 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: google/medgemma-4b-it
2025-12-12 01:08:41,659 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/medgemma-4b-it/resolve/main/tokenizer_config.json "HTTP/1.1 403 Forbidden"
2025-12-12 01:08:41,885 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/medgemma-4b-it/resolve/main/config.json "HTTP/1.1 403 Forbidden"
2025-12-12 01:08:41,886 - llm.medical_llm - ERROR - Failed to initialize model: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/google/medgemma-4b-it.
403 Client Error. (Request ID: Root=1-693b1dc1-1ae98eb62240957813085992;e65ee2f0-fd09-482d-948b-dddff8a189f4)

Cannot access gated repo for url https://huggingface.co/google/medgemma-4b-it/resolve/main/config.json.
Access to model google/medgemma-4b-it is restricted and you are not in the authorized list. Visit https://huggingface.co/google/medgemma-4b-it to ask for access.
2025-12-12 01:08:41,886 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-12 01:08:41,886 - llm.medical_llm - INFO - Medical LLM initialized: medgemma (mode: Local)
2025-12-12 01:08:41,886 - main - INFO - Medical LLM initialized
2025-12-12 01:08:41,886 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 01:08:41,886 - main - INFO - MCP-FHIR client initialized
2025-12-12 01:08:41,886 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 01:08:41,886 - main - INFO - Feedback collector initialized
2025-12-12 01:08:41,886 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 01:08:41,886 - main - INFO - Pipeline deployer initialized
2025-12-12 01:08:41,886 - api_server - INFO - Pipeline initialized successfully
2025-12-12 01:11:07,115 - api_server - INFO - Shutting down API server...
2025-12-12 01:11:26,961 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 01:11:26,966 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 01:11:26,970 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 01:11:26,977 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 01:11:26,983 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 01:11:26,993 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 01:11:26,993 - main - INFO - MedTech Pipeline initialized
2025-12-12 01:11:26,993 - main - INFO - Initializing pipeline components...
2025-12-12 01:11:27,342 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 01:11:27,343 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:11:27,343 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 01:11:27,343 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 01:11:27,343 - main - INFO - Segmentation pipeline initialized
2025-12-12 01:11:27,343 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 01:11:27,343 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 01:11:27,343 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 01:11:27,343 - main - INFO - Vector store initialized
2025-12-12 01:11:27,343 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=medgemma
2025-12-12 01:11:27,344 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: google/medgemma-4b-it
2025-12-12 01:11:27,643 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/medgemma-4b-it/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-12 01:11:27,882 - httpx - INFO - HTTP Request: GET https://huggingface.co/google/medgemma-4b-it/resolve/main/tokenizer_config.json "HTTP/1.1 200 OK"
2025-12-12 01:11:28,933 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/medgemma-4b-it/resolve/main/tokenizer.model "HTTP/1.1 302 Found"
2025-12-12 01:11:29,183 - httpx - INFO - HTTP Request: GET https://huggingface.co/api/models/google/medgemma-4b-it/xet-read-token/290cda5eeccbee130f987c4ad74a59ae6f196408 "HTTP/1.1 200 OK"
2025-12-12 01:11:30,770 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/medgemma-4b-it/resolve/main/tokenizer.json "HTTP/1.1 302 Found"
2025-12-12 01:11:32,219 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/medgemma-4b-it/resolve/main/added_tokens.json "HTTP/1.1 200 OK"
2025-12-12 01:11:32,440 - httpx - INFO - HTTP Request: GET https://huggingface.co/google/medgemma-4b-it/resolve/main/added_tokens.json "HTTP/1.1 200 OK"
2025-12-12 01:11:32,780 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/medgemma-4b-it/resolve/main/special_tokens_map.json "HTTP/1.1 200 OK"
2025-12-12 01:11:33,002 - httpx - INFO - HTTP Request: GET https://huggingface.co/google/medgemma-4b-it/resolve/main/special_tokens_map.json "HTTP/1.1 200 OK"
2025-12-12 01:11:34,333 - llm.medical_llm - INFO - Using BitsAndBytesConfig for 4-bit quantization
2025-12-12 01:11:34,557 - httpx - INFO - HTTP Request: HEAD https://huggingface.co/google/medgemma-4b-it/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-12 01:11:34,797 - httpx - INFO - HTTP Request: GET https://huggingface.co/google/medgemma-4b-it/resolve/main/config.json "HTTP/1.1 200 OK"
2025-12-12 01:11:34,800 - llm.medical_llm - ERROR - Failed to initialize model: The checkpoint you are trying to load has model type `gemma3` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.
2025-12-12 01:11:34,800 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-12 01:11:34,956 - llm.medical_llm - INFO - Medical LLM initialized: medgemma (mode: Local)
2025-12-12 01:11:34,957 - main - INFO - Medical LLM initialized
2025-12-12 01:11:34,957 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 01:11:34,957 - main - INFO - MCP-FHIR client initialized
2025-12-12 01:11:34,957 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 01:11:34,957 - main - INFO - Feedback collector initialized
2025-12-12 01:11:34,957 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 01:11:34,957 - main - INFO - Pipeline deployer initialized
2025-12-12 01:11:34,957 - api_server - INFO - Pipeline initialized successfully
2025-12-12 01:12:55,502 - api_server - INFO - Shutting down API server...
2025-12-12 01:14:56,686 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 01:14:56,691 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 01:14:56,695 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 01:14:56,702 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 01:14:56,707 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 01:14:56,717 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 01:14:56,717 - main - INFO - MedTech Pipeline initialized
2025-12-12 01:14:56,717 - main - INFO - Initializing pipeline components...
2025-12-12 01:14:57,144 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 01:14:57,145 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:14:57,145 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 01:14:57,145 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 01:14:57,145 - main - INFO - Segmentation pipeline initialized
2025-12-12 01:14:57,145 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 01:14:57,145 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 01:14:57,145 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 01:14:57,145 - main - INFO - Vector store initialized
2025-12-12 01:14:57,145 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=medgemma
2025-12-12 01:14:57,145 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: google/medgemma-4b-it
2025-12-12 01:14:59,885 - llm.medical_llm - INFO - Using BitsAndBytesConfig for 4-bit quantization
2025-12-12 01:21:48,655 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 01:21:48,661 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 01:21:48,667 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 01:21:48,674 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 01:21:48,680 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 01:21:48,690 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 01:21:48,690 - main - INFO - MedTech Pipeline initialized
2025-12-12 01:21:48,690 - main - INFO - Initializing pipeline components...
2025-12-12 01:21:48,899 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 01:21:48,899 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:21:48,899 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 01:21:48,899 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 01:21:48,899 - main - INFO - Segmentation pipeline initialized
2025-12-12 01:21:48,899 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 01:21:48,899 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 01:21:48,900 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 01:21:48,900 - main - INFO - Vector store initialized
2025-12-12 01:21:48,900 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=medgemma
2025-12-12 01:21:48,900 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: google/gemma-2b-it
2025-12-12 01:21:50,253 - llm.medical_llm - ERROR - Failed to initialize model: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/google/gemma-2b-it.
403 Client Error. (Request ID: Root=1-693b20d5-706e7605280bd7aa6c31e5fc;b4e2a223-7621-4737-b45a-b58a3871672b)

Cannot access gated repo for url https://huggingface.co/google/gemma-2b-it/resolve/main/config.json.
Access to model google/gemma-2b-it is restricted and you are not in the authorized list. Visit https://huggingface.co/google/gemma-2b-it to ask for access.
2025-12-12 01:21:50,253 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-12 01:21:50,253 - llm.medical_llm - INFO - Medical LLM initialized: medgemma (mode: Local)
2025-12-12 01:21:50,253 - main - INFO - Medical LLM initialized
2025-12-12 01:21:50,253 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 01:21:50,253 - main - INFO - MCP-FHIR client initialized
2025-12-12 01:21:50,253 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 01:21:50,253 - main - INFO - Feedback collector initialized
2025-12-12 01:21:50,253 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 01:21:50,253 - main - INFO - Pipeline deployer initialized
2025-12-12 01:21:50,253 - api_server - INFO - Pipeline initialized successfully
2025-12-12 01:22:16,980 - api_server - INFO - Shutting down API server...
2025-12-12 01:22:38,881 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 01:22:38,886 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 01:22:38,890 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 01:22:38,892 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 01:22:38,899 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 01:22:38,909 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 01:22:38,909 - main - INFO - MedTech Pipeline initialized
2025-12-12 01:22:38,909 - main - INFO - Initializing pipeline components...
2025-12-12 01:22:39,138 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 01:22:39,138 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:22:39,139 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 01:22:39,139 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 01:22:39,139 - main - INFO - Segmentation pipeline initialized
2025-12-12 01:22:39,139 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 01:22:39,139 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 01:22:39,139 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 01:22:39,139 - main - INFO - Vector store initialized
2025-12-12 01:22:39,139 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biogpt
2025-12-12 01:22:39,139 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: BioMistral/BioMistral-7B
2025-12-12 01:22:42,197 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-12 01:22:50,307 - llm.medical_llm - ERROR - Failed to initialize model: The current `device_map` had weights offloaded to the disk. Please provide an `offload_folder` for them. Alternatively, make sure you have `safetensors` installed if the model you are using offers the weights in this format.
2025-12-12 01:22:50,308 - llm.medical_llm - WARNING - Using dummy model for testing
2025-12-12 01:22:50,314 - llm.medical_llm - INFO - Medical LLM initialized: biogpt (mode: Local)
2025-12-12 01:22:50,314 - main - INFO - Medical LLM initialized
2025-12-12 01:22:50,315 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 01:22:50,315 - main - INFO - MCP-FHIR client initialized
2025-12-12 01:22:50,315 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 01:22:50,315 - main - INFO - Feedback collector initialized
2025-12-12 01:22:50,315 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 01:22:50,315 - main - INFO - Pipeline deployer initialized
2025-12-12 01:22:50,315 - api_server - INFO - Pipeline initialized successfully
2025-12-12 01:23:54,528 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-12 01:23:55,042 - api_server - INFO - Shutting down API server...
2025-12-12 01:24:03,844 - llm.medical_llm - INFO - Medical LLM initialized: medgemma (mode: Local)
2025-12-12 01:24:03,844 - main - INFO - Medical LLM initialized
2025-12-12 01:24:03,844 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 01:24:03,844 - main - INFO - MCP-FHIR client initialized
2025-12-12 01:24:03,845 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 01:24:03,845 - main - INFO - Feedback collector initialized
2025-12-12 01:24:03,845 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 01:24:03,845 - main - INFO - Pipeline deployer initialized
2025-12-12 01:24:03,845 - api_server - INFO - Pipeline initialized successfully
2025-12-12 01:24:09,839 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 01:24:09,844 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 01:24:09,848 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 01:24:09,850 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 01:24:09,856 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 01:24:09,866 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 01:24:09,866 - main - INFO - MedTech Pipeline initialized
2025-12-12 01:24:09,866 - main - INFO - Initializing pipeline components...
2025-12-12 01:24:10,255 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 01:24:10,255 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:24:10,255 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 01:24:10,255 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 01:24:10,255 - main - INFO - Segmentation pipeline initialized
2025-12-12 01:24:10,255 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 01:24:10,255 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 01:24:10,256 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 01:24:10,256 - main - INFO - Vector store initialized
2025-12-12 01:24:10,256 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biogpt
2025-12-12 01:24:10,256 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: microsoft/biogpt
2025-12-12 01:25:27,402 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-12 01:25:29,137 - llm.medical_llm - INFO - Medical LLM initialized: biogpt (mode: Local)
2025-12-12 01:25:29,138 - main - INFO - Medical LLM initialized
2025-12-12 01:25:29,138 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 01:25:29,138 - main - INFO - MCP-FHIR client initialized
2025-12-12 01:25:29,138 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 01:25:29,138 - main - INFO - Feedback collector initialized
2025-12-12 01:25:29,138 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 01:25:29,138 - main - INFO - Pipeline deployer initialized
2025-12-12 01:25:29,138 - api_server - INFO - Pipeline initialized successfully
2025-12-12 01:25:29,815 - llm.medical_llm - INFO - Prompt length: 61 characters
2025-12-12 01:25:35,937 - llm.medical_llm - INFO - Prompt length: 61 characters
2025-12-12 01:30:00,145 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 01:30:00,150 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 01:30:00,153 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 01:30:00,156 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 01:30:00,161 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 01:30:00,171 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 01:30:00,171 - main - INFO - MedTech Pipeline initialized
2025-12-12 01:30:00,171 - main - INFO - Initializing pipeline components...
2025-12-12 01:30:00,348 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 01:30:00,348 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:30:00,348 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 01:30:00,348 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 01:30:00,348 - main - INFO - Segmentation pipeline initialized
2025-12-12 01:30:00,349 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 01:30:00,349 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 01:30:00,349 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 01:30:00,349 - main - INFO - Vector store initialized
2025-12-12 01:30:00,349 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biogpt
2025-12-12 01:30:00,349 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: microsoft/biogpt
2025-12-12 01:30:02,824 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-12 01:30:04,467 - llm.medical_llm - INFO - Medical LLM initialized: biogpt (mode: Local)
2025-12-12 01:30:04,467 - main - INFO - Medical LLM initialized
2025-12-12 01:30:04,468 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 01:30:04,468 - main - INFO - MCP-FHIR client initialized
2025-12-12 01:30:04,468 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 01:30:04,468 - main - INFO - Feedback collector initialized
2025-12-12 01:30:04,468 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 01:30:04,468 - main - INFO - Pipeline deployer initialized
2025-12-12 01:30:04,468 - api_server - INFO - Pipeline initialized successfully
2025-12-12 01:30:04,469 - api_server - INFO - Shutting down API server...
2025-12-12 01:31:38,873 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 01:31:38,877 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 01:31:38,881 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 01:31:38,883 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 01:31:38,889 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 01:31:38,899 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 01:31:38,899 - main - INFO - MedTech Pipeline initialized
2025-12-12 01:31:38,899 - main - INFO - Initializing pipeline components...
2025-12-12 01:31:39,233 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 01:31:39,233 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:31:39,233 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 01:31:39,233 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 01:31:39,233 - main - INFO - Segmentation pipeline initialized
2025-12-12 01:31:39,233 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 01:31:39,233 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 01:31:39,234 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 01:31:39,234 - main - INFO - Vector store initialized
2025-12-12 01:31:39,234 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biogpt
2025-12-12 01:31:39,234 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: microsoft/biogpt
2025-12-12 01:31:41,797 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-12 01:31:43,349 - llm.medical_llm - INFO - Medical LLM initialized: biogpt (mode: Local)
2025-12-12 01:31:43,350 - main - INFO - Medical LLM initialized
2025-12-12 01:31:43,350 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 01:31:43,350 - main - INFO - MCP-FHIR client initialized
2025-12-12 01:31:43,350 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 01:31:43,350 - main - INFO - Feedback collector initialized
2025-12-12 01:31:43,350 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 01:31:43,350 - main - INFO - Pipeline deployer initialized
2025-12-12 01:31:43,350 - api_server - INFO - Pipeline initialized successfully
2025-12-12 01:32:53,715 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 01:32:53,720 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 01:32:53,723 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 01:32:53,725 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 01:32:53,731 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 01:32:53,741 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 01:32:53,741 - main - INFO - MedTech Pipeline initialized
2025-12-12 01:32:53,741 - main - INFO - Initializing pipeline components...
2025-12-12 01:32:53,947 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 01:32:53,947 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:32:53,947 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 01:32:53,947 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 01:32:53,948 - main - INFO - Segmentation pipeline initialized
2025-12-12 01:32:53,948 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 01:32:53,948 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 01:32:53,948 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 01:32:53,948 - main - INFO - Vector store initialized
2025-12-12 01:32:53,948 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biogpt
2025-12-12 01:32:53,948 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: microsoft/biogpt
2025-12-12 01:32:56,446 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-12 01:32:57,996 - llm.medical_llm - INFO - Medical LLM initialized: biogpt (mode: Local)
2025-12-12 01:32:57,996 - main - INFO - Medical LLM initialized
2025-12-12 01:32:57,997 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 01:32:57,997 - main - INFO - MCP-FHIR client initialized
2025-12-12 01:32:57,997 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 01:32:57,997 - main - INFO - Feedback collector initialized
2025-12-12 01:32:57,997 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 01:32:57,997 - main - INFO - Pipeline deployer initialized
2025-12-12 01:32:57,997 - api_server - INFO - Pipeline initialized successfully
2025-12-12 01:32:57,999 - api_server - INFO - Shutting down API server...
2025-12-12 01:33:31,416 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 01:33:31,421 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 01:33:31,424 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 01:33:31,426 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 01:33:31,432 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 01:33:31,441 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 01:33:31,442 - main - INFO - MedTech Pipeline initialized
2025-12-12 01:33:31,442 - main - INFO - Initializing pipeline components...
2025-12-12 01:33:31,622 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 01:33:31,622 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:33:31,622 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 01:33:31,623 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 01:33:31,623 - main - INFO - Segmentation pipeline initialized
2025-12-12 01:33:31,623 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 01:33:31,623 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 01:33:31,623 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 01:33:31,623 - main - INFO - Vector store initialized
2025-12-12 01:33:31,623 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biogpt
2025-12-12 01:33:31,623 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: microsoft/biogpt
2025-12-12 01:33:34,116 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-12 01:33:35,695 - llm.medical_llm - INFO - Medical LLM initialized: biogpt (mode: Local)
2025-12-12 01:33:35,695 - main - INFO - Medical LLM initialized
2025-12-12 01:33:35,696 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 01:33:35,696 - main - INFO - MCP-FHIR client initialized
2025-12-12 01:33:35,696 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 01:33:35,696 - main - INFO - Feedback collector initialized
2025-12-12 01:33:35,696 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 01:33:35,696 - main - INFO - Pipeline deployer initialized
2025-12-12 01:33:35,696 - api_server - INFO - Pipeline initialized successfully
2025-12-12 01:33:35,697 - api_server - INFO - Shutting down API server...
2025-12-12 01:34:39,779 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 01:34:39,783 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 01:34:39,787 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 01:34:39,789 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 01:34:39,795 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 01:34:39,804 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 01:34:39,804 - main - INFO - MedTech Pipeline initialized
2025-12-12 01:34:39,804 - main - INFO - Initializing pipeline components...
2025-12-12 01:34:40,133 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 01:34:40,133 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:34:40,133 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 01:34:40,133 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 01:34:40,133 - main - INFO - Segmentation pipeline initialized
2025-12-12 01:34:40,133 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 01:34:40,133 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 01:34:40,133 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 01:34:40,133 - main - INFO - Vector store initialized
2025-12-12 01:34:40,134 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biogpt
2025-12-12 01:34:40,134 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: microsoft/biogpt
2025-12-12 01:34:43,090 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-12 01:34:44,496 - llm.medical_llm - INFO - Medical LLM initialized: biogpt (mode: Local)
2025-12-12 01:34:44,496 - main - INFO - Medical LLM initialized
2025-12-12 01:34:44,497 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 01:34:44,497 - main - INFO - MCP-FHIR client initialized
2025-12-12 01:34:44,497 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 01:34:44,497 - main - INFO - Feedback collector initialized
2025-12-12 01:34:44,497 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 01:34:44,497 - main - INFO - Pipeline deployer initialized
2025-12-12 01:34:44,497 - api_server - INFO - Pipeline initialized successfully
2025-12-12 01:34:52,412 - llm.medical_llm - INFO - Prompt length: 61 characters
2025-12-12 01:35:22,212 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 01:35:22,216 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 01:35:22,220 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 01:35:22,222 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 01:35:22,228 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 01:35:22,239 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 01:35:22,239 - main - INFO - MedTech Pipeline initialized
2025-12-12 01:35:22,239 - main - INFO - Initializing pipeline components...
2025-12-12 01:35:22,430 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 01:35:22,430 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:35:22,430 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 01:35:22,430 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 01:35:22,431 - main - INFO - Segmentation pipeline initialized
2025-12-12 01:35:22,431 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 01:35:22,431 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 01:35:22,431 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 01:35:22,431 - main - INFO - Vector store initialized
2025-12-12 01:35:22,431 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biogpt
2025-12-12 01:35:22,431 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: microsoft/biogpt
2025-12-12 01:35:24,993 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-12 01:35:26,546 - llm.medical_llm - INFO - Medical LLM initialized: biogpt (mode: Local)
2025-12-12 01:35:26,546 - main - INFO - Medical LLM initialized
2025-12-12 01:35:26,546 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 01:35:26,546 - main - INFO - MCP-FHIR client initialized
2025-12-12 01:35:26,547 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 01:35:26,547 - main - INFO - Feedback collector initialized
2025-12-12 01:35:26,547 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 01:35:26,547 - main - INFO - Pipeline deployer initialized
2025-12-12 01:35:26,547 - api_server - INFO - Pipeline initialized successfully
2025-12-12 01:35:26,548 - api_server - INFO - Shutting down API server...
2025-12-12 01:36:23,558 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 01:36:23,563 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 01:36:23,566 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 01:36:23,569 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 01:36:23,574 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 01:36:23,584 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 01:36:23,584 - main - INFO - MedTech Pipeline initialized
2025-12-12 01:36:23,584 - main - INFO - Initializing pipeline components...
2025-12-12 01:36:23,894 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 01:36:23,894 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:36:23,894 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 01:36:23,894 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 01:36:23,894 - main - INFO - Segmentation pipeline initialized
2025-12-12 01:36:23,894 - vector_store - INFO - Loaded metadata with 24 records
2025-12-12 01:36:23,895 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 01:36:23,895 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 01:36:23,895 - main - INFO - Vector store initialized
2025-12-12 01:36:23,895 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=biogpt
2025-12-12 01:36:23,895 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: microsoft/biogpt
2025-12-12 01:36:26,353 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-12 01:36:27,510 - llm.medical_llm - INFO - Medical LLM initialized: biogpt (mode: Local)
2025-12-12 01:36:27,511 - main - INFO - Medical LLM initialized
2025-12-12 01:36:27,511 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 01:36:27,511 - main - INFO - MCP-FHIR client initialized
2025-12-12 01:36:27,511 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 01:36:27,511 - main - INFO - Feedback collector initialized
2025-12-12 01:36:27,511 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 01:36:27,511 - main - INFO - Pipeline deployer initialized
2025-12-12 01:36:27,512 - api_server - INFO - Pipeline initialized successfully
2025-12-12 01:36:33,728 - llm.medical_llm - INFO - Prompt length: 61 characters
2025-12-12 01:37:16,228 - api_server - INFO - Processing uploaded file: ID_0beb4899d.dcm
2025-12-12 01:37:16,228 - main - INFO - Processing medical image: data/uploads/ID_0beb4899d.dcm
2025-12-12 01:37:16,228 - main - INFO - Step 1: Performing segmentation...
2025-12-12 01:37:16,228 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0beb4899d.dcm
2025-12-12 01:37:16,238 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-12 01:37:16,238 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-12 01:37:16,238 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0beb4899d.dcm: Use fallback preprocessing for DICOM
2025-12-12 01:37:16,238 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:37:16,242 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-12 01:37:16,242 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-12 01:37:21,952 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0beb4899d_mask.nii.gz
2025-12-12 01:37:21,973 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-12 01:37:22,014 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0beb4899d.dcm
2025-12-12 01:37:22,014 - main - INFO - Step 2: Indexing embeddings...
2025-12-12 01:37:22,017 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-12 01:37:22,017 - main - INFO - Step 3: Retrieving similar cases...
2025-12-12 01:37:22,017 - main - INFO - Step 4: Retrieving clinical context...
2025-12-12 01:37:22,017 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-12 01:37:27,360 - main - INFO - Step 5: Generating medical report...
2025-12-12 01:37:28,159 - main - INFO - Pipeline processing completed successfully
2025-12-12 01:37:43,894 - llm.medical_llm - INFO - Prompt length: 71 characters
2025-12-12 01:37:43,902 - llm.medical_llm - INFO - Started streaming generation thread
2025-12-12 01:37:44,242 - llm.medical_llm - INFO - Streaming completed, generated 18 tokens: 'The most likely diagnosis of the pattern in a neonate should include congenital rubella syndrome.'
2025-12-12 01:38:11,626 - llm.medical_llm - INFO - Prompt length: 34 characters
2025-12-12 01:38:11,632 - llm.medical_llm - INFO - Started streaming generation thread
2025-12-12 01:38:12,658 - llm.medical_llm - INFO - Streaming completed, generated 45 tokens: '"What are the outcomes of a school-based program that provides physical activity opportunities for students?" METHODS: The study included an analysis of data collected by the Physical Activity Opportu'
2025-12-12 01:39:27,452 - api_server - INFO - Shutting down API server...
2025-12-12 01:39:42,638 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 01:39:42,642 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 01:39:42,646 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 01:39:42,648 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 01:39:42,654 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 01:39:42,663 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 01:39:42,663 - main - INFO - MedTech Pipeline initialized
2025-12-12 01:39:42,663 - main - INFO - Initializing pipeline components...
2025-12-12 01:39:42,954 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 01:39:42,954 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 01:39:42,954 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 01:39:42,955 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 01:39:42,955 - main - INFO - Segmentation pipeline initialized
2025-12-12 01:39:42,955 - vector_store - INFO - Loaded metadata with 25 records
2025-12-12 01:39:42,955 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 01:39:42,955 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 01:39:42,955 - main - INFO - Vector store initialized
2025-12-12 01:39:42,955 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=qwen
2025-12-12 01:39:42,955 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: Qwen/Qwen2.5-1.5B-Instruct
2025-12-12 01:43:32,377 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-12 01:43:35,062 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2025-12-12 01:43:35,063 - llm.medical_llm - INFO - Medical LLM initialized: qwen (mode: Local)
2025-12-12 01:43:35,063 - main - INFO - Medical LLM initialized
2025-12-12 01:43:35,063 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 01:43:35,063 - main - INFO - MCP-FHIR client initialized
2025-12-12 01:43:35,063 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 01:43:35,063 - main - INFO - Feedback collector initialized
2025-12-12 01:43:35,063 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 01:43:35,063 - main - INFO - Pipeline deployer initialized
2025-12-12 01:43:35,064 - api_server - INFO - Pipeline initialized successfully
2025-12-12 02:14:49,349 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 02:14:49,358 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 02:14:49,366 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 02:14:49,372 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 02:14:49,386 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 02:14:49,407 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 02:14:49,407 - main - INFO - MedTech Pipeline initialized
2025-12-12 02:14:49,408 - main - INFO - Initializing pipeline components...
2025-12-12 02:14:50,235 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 02:14:50,235 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 02:14:50,235 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 02:14:50,235 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 02:14:50,235 - main - INFO - Segmentation pipeline initialized
2025-12-12 02:14:50,236 - vector_store - INFO - Loaded metadata with 25 records
2025-12-12 02:14:50,236 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 02:14:50,237 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 02:14:50,237 - main - INFO - Vector store initialized
2025-12-12 02:14:50,237 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=qwen
2025-12-12 02:14:50,237 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: Qwen/Qwen2.5-1.5B-Instruct
2025-12-12 02:14:52,030 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-12 02:14:54,924 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2025-12-12 02:14:54,925 - llm.medical_llm - INFO - Medical LLM initialized: qwen (mode: Local)
2025-12-12 02:14:54,926 - main - INFO - Medical LLM initialized
2025-12-12 02:14:54,926 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 02:14:54,927 - main - INFO - MCP-FHIR client initialized
2025-12-12 02:14:54,927 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 02:14:54,927 - main - INFO - Feedback collector initialized
2025-12-12 02:14:54,927 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 02:14:54,927 - main - INFO - Pipeline deployer initialized
2025-12-12 02:14:54,928 - api_server - INFO - Pipeline initialized successfully
2025-12-12 02:14:56,899 - llm.medical_llm - INFO - Prompt length: 61 characters
2025-12-12 07:37:37,943 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 07:37:37,954 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 07:37:37,960 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 07:37:37,965 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 07:37:37,977 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 07:37:37,995 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 07:37:37,995 - main - INFO - MedTech Pipeline initialized
2025-12-12 07:37:37,995 - main - INFO - Initializing pipeline components...
2025-12-12 07:37:39,481 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 07:37:39,481 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 07:37:39,481 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 07:37:39,481 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 07:37:39,481 - main - INFO - Segmentation pipeline initialized
2025-12-12 07:37:39,482 - vector_store - INFO - Loaded metadata with 25 records
2025-12-12 07:37:39,482 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 07:37:39,487 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 07:37:39,487 - main - INFO - Vector store initialized
2025-12-12 07:37:39,487 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=qwen
2025-12-12 07:37:39,487 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: Qwen/Qwen2.5-1.5B-Instruct
2025-12-12 07:37:41,505 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-12 07:37:45,466 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2025-12-12 07:37:45,467 - llm.medical_llm - INFO - Medical LLM initialized: qwen (mode: Local)
2025-12-12 07:37:45,468 - main - INFO - Medical LLM initialized
2025-12-12 07:37:45,468 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 07:37:45,468 - main - INFO - MCP-FHIR client initialized
2025-12-12 07:37:45,469 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 07:37:45,469 - main - INFO - Feedback collector initialized
2025-12-12 07:37:45,469 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 07:37:45,469 - main - INFO - Pipeline deployer initialized
2025-12-12 07:37:45,469 - api_server - INFO - Pipeline initialized successfully
2025-12-12 07:37:56,808 - llm.medical_llm - INFO - Prompt length: 95 characters
2025-12-12 07:42:20,629 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 07:42:20,641 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 07:42:20,650 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 07:42:20,655 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 07:42:20,668 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 07:42:20,687 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 07:42:20,688 - main - INFO - MedTech Pipeline initialized
2025-12-12 07:42:20,688 - main - INFO - Initializing pipeline components...
2025-12-12 07:42:21,395 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 07:42:21,395 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 07:42:21,396 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 07:42:21,396 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 07:42:21,396 - main - INFO - Segmentation pipeline initialized
2025-12-12 07:42:21,396 - vector_store - INFO - Loaded metadata with 25 records
2025-12-12 07:42:21,396 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 07:42:21,397 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 07:42:21,397 - main - INFO - Vector store initialized
2025-12-12 07:42:21,397 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=qwen
2025-12-12 07:42:21,397 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: Qwen/Qwen2.5-1.5B-Instruct
2025-12-12 07:42:23,403 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-12-12 07:42:25,911 - accelerate.big_modeling - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.
2025-12-12 07:42:25,912 - llm.medical_llm - INFO - Medical LLM initialized: qwen (mode: Local)
2025-12-12 07:42:25,912 - main - INFO - Medical LLM initialized
2025-12-12 07:42:25,912 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 07:42:25,912 - main - INFO - MCP-FHIR client initialized
2025-12-12 07:42:25,912 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 07:42:25,913 - main - INFO - Feedback collector initialized
2025-12-12 07:42:25,913 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 07:42:25,913 - main - INFO - Pipeline deployer initialized
2025-12-12 07:42:25,913 - api_server - INFO - Pipeline initialized successfully
2025-12-12 07:42:35,693 - llm.medical_llm - INFO - Prompt length: 306 characters
2025-12-12 07:46:55,808 - api_server - INFO - Initializing MedTech Pipeline...
2025-12-12 07:46:55,813 - main - INFO - Loaded config: segmentation_config.yaml
2025-12-12 07:46:55,816 - main - INFO - Loaded config: vector_store_config.yaml
2025-12-12 07:46:55,819 - main - INFO - Loaded config: llm_config.yaml
2025-12-12 07:46:55,825 - main - INFO - Loaded config: mcp_fhir_config.yaml
2025-12-12 07:46:55,835 - main - INFO - Loaded config: deployment_config.yaml
2025-12-12 07:46:55,836 - main - INFO - MedTech Pipeline initialized
2025-12-12 07:46:55,836 - main - INFO - Initializing pipeline components...
2025-12-12 07:46:56,195 - segmentation.swin_unetr_model - INFO - Swin UNETR model initialized on device: cuda
2025-12-12 07:46:56,195 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 07:46:56,195 - segmentation.postprocessing - INFO - Segmentation postprocessor initialized
2025-12-12 07:46:56,195 - segmentation.segmentation_pipeline - INFO - Segmentation pipeline initialized
2025-12-12 07:46:56,195 - main - INFO - Segmentation pipeline initialized
2025-12-12 07:46:56,196 - vector_store - INFO - Loaded metadata with 25 records
2025-12-12 07:46:56,196 - vector_store - INFO - Loading FAISS index from data/faiss_index
2025-12-12 07:46:56,196 - vector_store - INFO - FAISS index loaded from disk
2025-12-12 07:46:56,197 - main - INFO - Vector store initialized
2025-12-12 07:46:56,197 - llm.medical_llm - INFO - Configuration: use_inference_api=False, model_type=qwen
2025-12-12 07:46:56,197 - llm.medical_llm - INFO - Loading model from Hugging Face Hub: Qwen/Qwen2.5-1.5B-Instruct
2025-12-12 07:46:57,494 - llm.medical_llm - INFO - Using BitsAndBytesConfig for 4-bit quantization
2025-12-12 07:47:00,905 - llm.medical_llm - INFO - Medical LLM initialized: qwen (mode: Local)
2025-12-12 07:47:00,905 - main - INFO - Medical LLM initialized
2025-12-12 07:47:00,906 - mcp_fhir.mcp_fhir_client - INFO - MCP-FHIR client initialized
2025-12-12 07:47:00,906 - main - INFO - MCP-FHIR client initialized
2025-12-12 07:47:00,906 - feedback.feedback_collector - INFO - Feedback collector initialized
2025-12-12 07:47:00,906 - main - INFO - Feedback collector initialized
2025-12-12 07:47:00,906 - deployment.pipeline_deployer - INFO - Pipeline deployer initialized
2025-12-12 07:47:00,906 - main - INFO - Pipeline deployer initialized
2025-12-12 07:47:00,906 - api_server - INFO - Pipeline initialized successfully
2025-12-12 07:47:13,631 - llm.medical_llm - INFO - Prompt length: 306 characters
2025-12-12 07:48:37,095 - api_server - INFO - Processing uploaded file: ID_0b0a1315d.dcm
2025-12-12 07:48:37,095 - main - INFO - Processing medical image: data/uploads/ID_0b0a1315d.dcm
2025-12-12 07:48:37,095 - main - INFO - Step 1: Performing segmentation...
2025-12-12 07:48:37,095 - segmentation.segmentation_pipeline - INFO - Processing image: data/uploads/ID_0b0a1315d.dcm
2025-12-12 07:48:37,105 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-12 07:48:37,105 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-12 07:48:37,105 - segmentation.swin_unetr_model - ERROR - Preprocessing failed for data/uploads/ID_0b0a1315d.dcm: Use fallback preprocessing for DICOM
2025-12-12 07:48:37,105 - segmentation.preprocessing - INFO - Medical image preprocessor initialized
2025-12-12 07:48:37,109 - segmentation.preprocessing - INFO - Converted 2D DICOM to 3D: (1, 1024, 1024)
2025-12-12 07:48:37,109 - segmentation.preprocessing - INFO - Loaded DICOM image: (1, 1024, 1024)
2025-12-12 07:48:41,414 - segmentation.preprocessing - INFO - Saved mask to: data/uploads/ID_0b0a1315d_mask.nii.gz
2025-12-12 07:48:43,989 - segmentation.preprocessing - INFO - Loaded NIfTI image: (1, 1024, 1024)
2025-12-12 07:48:44,025 - segmentation.segmentation_pipeline - INFO - Completed processing: data/uploads/ID_0b0a1315d.dcm
2025-12-12 07:48:44,025 - main - INFO - Step 2: Indexing embeddings...
2025-12-12 07:48:44,027 - vector_store - INFO - Added 1 embeddings to FAISS index
2025-12-12 07:48:44,028 - main - INFO - Step 3: Retrieving similar cases...
2025-12-12 07:48:44,028 - main - INFO - Step 4: Retrieving clinical context...
2025-12-12 07:48:44,028 - mcp_fhir.mcp_fhir_client - INFO - Getting clinical context for patient: unknown
2025-12-12 07:48:48,733 - main - INFO - Step 5: Generating medical report...
2025-12-12 07:49:02,772 - main - INFO - Pipeline processing completed successfully
2025-12-12 07:49:30,572 - llm.medical_llm - INFO - Prompt length: 684 characters
2025-12-12 07:49:30,577 - llm.medical_llm - INFO - Started streaming generation thread
2025-12-12 07:49:47,510 - llm.medical_llm - INFO - Streaming completed, generated 257 tokens: ' The segment contains two structures with class numbers 7 and 8 totaling 3606 mm^3 which are both identified in all 3 detected regions. These structures appear to be consistent throughout the image wi'
2025-12-12 07:51:13,059 - llm.medical_llm - INFO - Prompt length: 305 characters
2025-12-12 07:51:49,444 - llm.medical_llm - INFO - Prompt length: 305 characters
2025-12-12 07:55:22,061 - llm.medical_llm - INFO - Prompt length: 305 characters
